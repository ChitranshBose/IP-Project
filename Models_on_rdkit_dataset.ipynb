{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf73cH1NoTOg",
        "outputId": "20090237-97e8-43d2-b8eb-9c30699a2587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.3-cp310-cp310-manylinux2014_x86_64.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.3\n"
          ]
        }
      ],
      "source": [
        "# installing and importing catboost library\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import metrics as mt\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "CndxMDNKpCW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/rdkit_dataset.csv') # loading the dataset"
      ],
      "metadata": {
        "id": "lu8IOA7jpERb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data # displaying the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "a3zhlzcyphAS",
        "outputId": "b06eccb0-4fd3-4ba8-ff03-20afcd42c91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          MolWt  NumRotatableBonds    TPSA  AUTOCORR2D_1  AUTOCORR2D_2  \\\n",
              "0      1776.113               60.0  701.14     14.729097      0.060103   \n",
              "1      1738.874               57.0  832.01     14.566415      0.044381   \n",
              "2      1677.925               51.0  676.94     14.402321      0.029760   \n",
              "3      1710.150               59.0  667.71     14.676367      0.005836   \n",
              "4      1858.098               53.0  766.93     14.709878      0.005817   \n",
              "...         ...                ...     ...           ...           ...   \n",
              "57230  1640.855               48.0  612.33     14.773368      0.010197   \n",
              "57231  1875.308               57.0  663.32     15.220414      0.032724   \n",
              "57232  1782.131               63.0  852.17     14.643091      0.010002   \n",
              "57233  1794.957               54.0  860.69     14.849205      0.002266   \n",
              "57234  1653.789               54.0  733.72     14.199916      0.016046   \n",
              "\n",
              "       AUTOCORR2D_3  AUTOCORR2D_4  AUTOCORR2D_5  AUTOCORR2D_6  AUTOCORR2D_7  \\\n",
              "0         -2.080788      0.021793     15.138211      1776.113      1649.105   \n",
              "1         -2.170827      0.016357     16.352459      1738.874      1618.922   \n",
              "2         -1.806985      0.016682     16.504202      1677.925      1556.965   \n",
              "3         -1.634398      0.013024     15.364407      1710.150      1577.094   \n",
              "4         -2.152389      0.008452     16.384615      1858.098      1741.170   \n",
              "...             ...           ...           ...           ...           ...   \n",
              "57230     -1.973330      0.019602     15.623932      1640.855      1526.951   \n",
              "57231     -1.771628      0.008432     15.969697      1875.308      1743.260   \n",
              "57232     -1.943594      0.015273     15.480000      1782.131      1641.011   \n",
              "57233     -2.057832      0.016611     17.401575      1794.957      1675.005   \n",
              "57234     -2.049998      0.016359     15.991304      1653.789      1544.925   \n",
              "\n",
              "       ...  AUTOCORR2D_182  AUTOCORR2D_183  AUTOCORR2D_184  AUTOCORR2D_185  \\\n",
              "0      ...             0.0             0.0             0.0             0.0   \n",
              "1      ...             0.0             0.0             0.0             0.0   \n",
              "2      ...             0.0             0.0             0.0             0.0   \n",
              "3      ...             0.0             0.0             0.0             0.0   \n",
              "4      ...             0.0             0.0             0.0             0.0   \n",
              "...    ...             ...             ...             ...             ...   \n",
              "57230  ...             0.0             0.0             0.0             0.0   \n",
              "57231  ...             0.0             0.0             0.0             0.0   \n",
              "57232  ...             0.0             0.0             0.0             0.0   \n",
              "57233  ...             0.0             0.0             0.0             0.0   \n",
              "57234  ...             0.0             0.0             0.0             0.0   \n",
              "\n",
              "       AUTOCORR2D_186  AUTOCORR2D_187  AUTOCORR2D_188  AUTOCORR2D_189  \\\n",
              "0                 0.0             0.0             0.0             0.0   \n",
              "1                 0.0             0.0             0.0             0.0   \n",
              "2                 0.0             0.0             0.0             0.0   \n",
              "3                 0.0             0.0             0.0             0.0   \n",
              "4                 0.0             0.0             0.0             0.0   \n",
              "...               ...             ...             ...             ...   \n",
              "57230             0.0             0.0             0.0             0.0   \n",
              "57231             0.0             0.0             0.0             0.0   \n",
              "57232             0.0             0.0             0.0             0.0   \n",
              "57233             0.0             0.0             0.0             1.0   \n",
              "57234             0.0             0.0             0.0             0.0   \n",
              "\n",
              "            qed  Target  \n",
              "0      0.021793       0  \n",
              "1      0.016357       0  \n",
              "2      0.016682       0  \n",
              "3      0.013024       1  \n",
              "4      0.008452       1  \n",
              "...         ...     ...  \n",
              "57230  0.019602       1  \n",
              "57231  0.008432       0  \n",
              "57232  0.015273       0  \n",
              "57233  0.016611       1  \n",
              "57234  0.016359       1  \n",
              "\n",
              "[57235 rows x 194 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71f1da77-48a8-432a-bf66-6737f74fed3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MolWt</th>\n",
              "      <th>NumRotatableBonds</th>\n",
              "      <th>TPSA</th>\n",
              "      <th>AUTOCORR2D_1</th>\n",
              "      <th>AUTOCORR2D_2</th>\n",
              "      <th>AUTOCORR2D_3</th>\n",
              "      <th>AUTOCORR2D_4</th>\n",
              "      <th>AUTOCORR2D_5</th>\n",
              "      <th>AUTOCORR2D_6</th>\n",
              "      <th>AUTOCORR2D_7</th>\n",
              "      <th>...</th>\n",
              "      <th>AUTOCORR2D_182</th>\n",
              "      <th>AUTOCORR2D_183</th>\n",
              "      <th>AUTOCORR2D_184</th>\n",
              "      <th>AUTOCORR2D_185</th>\n",
              "      <th>AUTOCORR2D_186</th>\n",
              "      <th>AUTOCORR2D_187</th>\n",
              "      <th>AUTOCORR2D_188</th>\n",
              "      <th>AUTOCORR2D_189</th>\n",
              "      <th>qed</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1776.113</td>\n",
              "      <td>60.0</td>\n",
              "      <td>701.14</td>\n",
              "      <td>14.729097</td>\n",
              "      <td>0.060103</td>\n",
              "      <td>-2.080788</td>\n",
              "      <td>0.021793</td>\n",
              "      <td>15.138211</td>\n",
              "      <td>1776.113</td>\n",
              "      <td>1649.105</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021793</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1738.874</td>\n",
              "      <td>57.0</td>\n",
              "      <td>832.01</td>\n",
              "      <td>14.566415</td>\n",
              "      <td>0.044381</td>\n",
              "      <td>-2.170827</td>\n",
              "      <td>0.016357</td>\n",
              "      <td>16.352459</td>\n",
              "      <td>1738.874</td>\n",
              "      <td>1618.922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016357</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1677.925</td>\n",
              "      <td>51.0</td>\n",
              "      <td>676.94</td>\n",
              "      <td>14.402321</td>\n",
              "      <td>0.029760</td>\n",
              "      <td>-1.806985</td>\n",
              "      <td>0.016682</td>\n",
              "      <td>16.504202</td>\n",
              "      <td>1677.925</td>\n",
              "      <td>1556.965</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016682</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1710.150</td>\n",
              "      <td>59.0</td>\n",
              "      <td>667.71</td>\n",
              "      <td>14.676367</td>\n",
              "      <td>0.005836</td>\n",
              "      <td>-1.634398</td>\n",
              "      <td>0.013024</td>\n",
              "      <td>15.364407</td>\n",
              "      <td>1710.150</td>\n",
              "      <td>1577.094</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013024</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1858.098</td>\n",
              "      <td>53.0</td>\n",
              "      <td>766.93</td>\n",
              "      <td>14.709878</td>\n",
              "      <td>0.005817</td>\n",
              "      <td>-2.152389</td>\n",
              "      <td>0.008452</td>\n",
              "      <td>16.384615</td>\n",
              "      <td>1858.098</td>\n",
              "      <td>1741.170</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008452</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57230</th>\n",
              "      <td>1640.855</td>\n",
              "      <td>48.0</td>\n",
              "      <td>612.33</td>\n",
              "      <td>14.773368</td>\n",
              "      <td>0.010197</td>\n",
              "      <td>-1.973330</td>\n",
              "      <td>0.019602</td>\n",
              "      <td>15.623932</td>\n",
              "      <td>1640.855</td>\n",
              "      <td>1526.951</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019602</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57231</th>\n",
              "      <td>1875.308</td>\n",
              "      <td>57.0</td>\n",
              "      <td>663.32</td>\n",
              "      <td>15.220414</td>\n",
              "      <td>0.032724</td>\n",
              "      <td>-1.771628</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>15.969697</td>\n",
              "      <td>1875.308</td>\n",
              "      <td>1743.260</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008432</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57232</th>\n",
              "      <td>1782.131</td>\n",
              "      <td>63.0</td>\n",
              "      <td>852.17</td>\n",
              "      <td>14.643091</td>\n",
              "      <td>0.010002</td>\n",
              "      <td>-1.943594</td>\n",
              "      <td>0.015273</td>\n",
              "      <td>15.480000</td>\n",
              "      <td>1782.131</td>\n",
              "      <td>1641.011</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015273</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57233</th>\n",
              "      <td>1794.957</td>\n",
              "      <td>54.0</td>\n",
              "      <td>860.69</td>\n",
              "      <td>14.849205</td>\n",
              "      <td>0.002266</td>\n",
              "      <td>-2.057832</td>\n",
              "      <td>0.016611</td>\n",
              "      <td>17.401575</td>\n",
              "      <td>1794.957</td>\n",
              "      <td>1675.005</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.016611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57234</th>\n",
              "      <td>1653.789</td>\n",
              "      <td>54.0</td>\n",
              "      <td>733.72</td>\n",
              "      <td>14.199916</td>\n",
              "      <td>0.016046</td>\n",
              "      <td>-2.049998</td>\n",
              "      <td>0.016359</td>\n",
              "      <td>15.991304</td>\n",
              "      <td>1653.789</td>\n",
              "      <td>1544.925</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016359</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57235 rows × 194 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71f1da77-48a8-432a-bf66-6737f74fed3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71f1da77-48a8-432a-bf66-6737f74fed3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71f1da77-48a8-432a-bf66-6737f74fed3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17f4e475-9cfe-49d9-b80a-16aefd4bd748\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17f4e475-9cfe-49d9-b80a-16aefd4bd748')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17f4e475-9cfe-49d9-b80a-16aefd4bd748 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum() # checking if data contains null value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9QW8Umlriu7",
        "outputId": "6f8ee48d-cd9b-4a79-9df7-9125a98fb287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MolWt                3\n",
              "NumRotatableBonds    3\n",
              "TPSA                 3\n",
              "AUTOCORR2D_1         3\n",
              "AUTOCORR2D_2         3\n",
              "                    ..\n",
              "AUTOCORR2D_187       3\n",
              "AUTOCORR2D_188       3\n",
              "AUTOCORR2D_189       3\n",
              "qed                  3\n",
              "Target               0\n",
              "Length: 194, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True) # removing null values"
      ],
      "metadata": {
        "id": "V1Vu3Ev8rqDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum() # checking if data contains null value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EFbT1qQrrRW",
        "outputId": "3d67e062-ab76-4172-a034-9666fae24188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MolWt                0\n",
              "NumRotatableBonds    0\n",
              "TPSA                 0\n",
              "AUTOCORR2D_1         0\n",
              "AUTOCORR2D_2         0\n",
              "                    ..\n",
              "AUTOCORR2D_187       0\n",
              "AUTOCORR2D_188       0\n",
              "AUTOCORR2D_189       0\n",
              "qed                  0\n",
              "Target               0\n",
              "Length: 194, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data\n",
        "sc = MinMaxScaler()\n",
        "data = pd.DataFrame(sc.fit_transform(data))"
      ],
      "metadata": {
        "id": "C9N4FP7ByAb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to calculate evaluation metrices\n",
        "def metric_calculation(y_test,y_pred):\n",
        "  print(\"Accuracy  :  \",mt.accuracy_score(y_test,y_pred))\n",
        "  print(\"Precision :  \",mt.precision_score(y_test,y_pred))\n",
        "  print(\"Recall    :  \",mt.recall_score(y_test,y_pred))\n",
        "  print(\"F1-score  :  \",mt.f1_score(y_test,y_pred))\n",
        "  print(\"Confusion matrix      : \\n \",mt.confusion_matrix(y_test,y_pred))\n",
        "  print(\"Classification report : \\n\",mt.classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "Caflh28SpmlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting dataset to features and target\n",
        "x = data.iloc[:,:-1]\n",
        "y = data.iloc[:,-1]"
      ],
      "metadata": {
        "id": "e1GcEXJZqUx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1) # splitting dataset to train and test"
      ],
      "metadata": {
        "id": "H7hGmwMYqSTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML**"
      ],
      "metadata": {
        "id": "4osuph7Qm8we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the objects of classifiers\n",
        "rf = RandomForestClassifier()\n",
        "mlp = MLPClassifier()\n",
        "sgd = SGDClassifier()\n",
        "svc = SVC()\n",
        "lr = LogisticRegression()\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "cat = CatBoostClassifier( iterations=100, depth=14, learning_rate=0.1,verbose=False)\n",
        "bgc_rf = BaggingClassifier(estimator=rf, n_estimators=20, random_state=0)\n",
        "hist_gbc = HistGradientBoostingClassifier()\n",
        "ada = AdaBoostClassifier(base_estimator=rf, n_estimators=10, learning_rate = 0.1)\n",
        "lgbm = LGBMClassifier(random_state=5)"
      ],
      "metadata": {
        "id": "el76wnWPqL6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf.fit(x_train,y_train)\n",
        "y_pred = rf.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA0A9pM-qSr3",
        "outputId": "3825acc7-0c8f-4556-c3f4-e7f331ac01c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.7360512521840419\n",
            "Precision :   0.7297462176671548\n",
            "Recall    :   0.7207760906242469\n",
            "F1-score  :   0.7252334182126835\n",
            "Confusion matrix      : \n",
            "  [[6657 2215]\n",
            " [2317 5981]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.75      0.75      8872\n",
            "         1.0       0.73      0.72      0.73      8298\n",
            "\n",
            "    accuracy                           0.74     17170\n",
            "   macro avg       0.74      0.74      0.74     17170\n",
            "weighted avg       0.74      0.74      0.74     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP classifier\n",
        "mlp.fit(x_train,y_train)\n",
        "y_pred = mlp.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARL9psDh1RaW",
        "outputId": "84baa1de-ac1b-410b-c80d-fe7c0962dea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6734420500873617\n",
            "Precision :   0.6460119370591427\n",
            "Recall    :   0.7174017835623042\n",
            "F1-score  :   0.6798378347513276\n",
            "Confusion matrix      : \n",
            "  [[5610 3262]\n",
            " [2345 5953]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.63      0.67      8872\n",
            "         1.0       0.65      0.72      0.68      8298\n",
            "\n",
            "    accuracy                           0.67     17170\n",
            "   macro avg       0.68      0.67      0.67     17170\n",
            "weighted avg       0.68      0.67      0.67     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD Classifier\n",
        "sgd.fit(x_train,y_train)\n",
        "y_pred = sgd.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rhOA1Eww6J4",
        "outputId": "16c60f77-cfff-4024-bda3-12a728c23380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6470588235294118\n",
            "Precision :   0.639179104477612\n",
            "Recall    :   0.6193058568329718\n",
            "F1-score  :   0.6290855673889093\n",
            "Confusion matrix      : \n",
            "  [[5971 2901]\n",
            " [3159 5139]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.67      0.66      8872\n",
            "         1.0       0.64      0.62      0.63      8298\n",
            "\n",
            "    accuracy                           0.65     17170\n",
            "   macro avg       0.65      0.65      0.65     17170\n",
            "weighted avg       0.65      0.65      0.65     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine\n",
        "svc.fit(x_train,y_train)\n",
        "y_pred = svc.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXxPI72O55mp",
        "outputId": "c049b14a-2a8f-43ca-8fe4-983c92b63195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.666045428072219\n",
            "Precision :   0.650293083235639\n",
            "Recall    :   0.6684743311641359\n",
            "F1-score  :   0.6592583788923224\n",
            "Confusion matrix      : \n",
            "  [[5889 2983]\n",
            " [2751 5547]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.66      0.67      8872\n",
            "         1.0       0.65      0.67      0.66      8298\n",
            "\n",
            "    accuracy                           0.67     17170\n",
            "   macro avg       0.67      0.67      0.67     17170\n",
            "weighted avg       0.67      0.67      0.67     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "lr.fit(x_train,y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhtJCOsy57rL",
        "outputId": "49624847-a82e-4728-e2bc-ba5ca12160ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6458357600465929\n",
            "Precision :   0.638892369377271\n",
            "Recall    :   0.6144854181730538\n",
            "F1-score  :   0.6264512562196695\n",
            "Confusion matrix      : \n",
            "  [[5990 2882]\n",
            " [3199 5099]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.68      0.66      8872\n",
            "         1.0       0.64      0.61      0.63      8298\n",
            "\n",
            "    accuracy                           0.65     17170\n",
            "   macro avg       0.65      0.64      0.64     17170\n",
            "weighted avg       0.65      0.65      0.65     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K Nearest Neighbour\n",
        "for k in range(1, 10,2):\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(x_train,y_train)\n",
        "  y_pred = knn.predict(x_test)\n",
        "  print(\"k = \", k)\n",
        "  metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGTVCXYu-LPF",
        "outputId": "378c42fd-ff10-4548-bead-8628721869c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k =  1\n",
            "Accuracy  :   0.6791496796738498\n",
            "Precision :   0.660934795152914\n",
            "Recall    :   0.6901663051337672\n",
            "F1-score  :   0.6752343335494901\n",
            "Confusion matrix      : \n",
            "  [[5934 2938]\n",
            " [2571 5727]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.67      0.68      8872\n",
            "         1.0       0.66      0.69      0.68      8298\n",
            "\n",
            "    accuracy                           0.68     17170\n",
            "   macro avg       0.68      0.68      0.68     17170\n",
            "weighted avg       0.68      0.68      0.68     17170\n",
            "\n",
            "k =  3\n",
            "Accuracy  :   0.6587652882935352\n",
            "Precision :   0.642116303461135\n",
            "Recall    :   0.6640154254037117\n",
            "F1-score  :   0.6528822797559096\n",
            "Confusion matrix      : \n",
            "  [[5801 3071]\n",
            " [2788 5510]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.68      0.65      0.66      8872\n",
            "         1.0       0.64      0.66      0.65      8298\n",
            "\n",
            "    accuracy                           0.66     17170\n",
            "   macro avg       0.66      0.66      0.66     17170\n",
            "weighted avg       0.66      0.66      0.66     17170\n",
            "\n",
            "k =  5\n",
            "Accuracy  :   0.6514851485148515\n",
            "Precision :   0.635480093676815\n",
            "Recall    :   0.6540130151843818\n",
            "F1-score  :   0.6446133745100369\n",
            "Confusion matrix      : \n",
            "  [[5759 3113]\n",
            " [2871 5427]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.65      0.66      8872\n",
            "         1.0       0.64      0.65      0.64      8298\n",
            "\n",
            "    accuracy                           0.65     17170\n",
            "   macro avg       0.65      0.65      0.65     17170\n",
            "weighted avg       0.65      0.65      0.65     17170\n",
            "\n",
            "k =  7\n",
            "Accuracy  :   0.6499708794408853\n",
            "Precision :   0.6348420556341349\n",
            "Recall    :   0.6490720655579658\n",
            "F1-score  :   0.6418782028363724\n",
            "Confusion matrix      : \n",
            "  [[5774 3098]\n",
            " [2912 5386]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.65      0.66      8872\n",
            "         1.0       0.63      0.65      0.64      8298\n",
            "\n",
            "    accuracy                           0.65     17170\n",
            "   macro avg       0.65      0.65      0.65     17170\n",
            "weighted avg       0.65      0.65      0.65     17170\n",
            "\n",
            "k =  9\n",
            "Accuracy  :   0.6489225393127548\n",
            "Precision :   0.6340023612750886\n",
            "Recall    :   0.6471438900939985\n",
            "F1-score  :   0.6405057251908398\n",
            "Confusion matrix      : \n",
            "  [[5772 3100]\n",
            " [2928 5370]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.65      0.66      8872\n",
            "         1.0       0.63      0.65      0.64      8298\n",
            "\n",
            "    accuracy                           0.65     17170\n",
            "   macro avg       0.65      0.65      0.65     17170\n",
            "weighted avg       0.65      0.65      0.65     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Catboost Classifier\n",
        "cat.fit(x_train,y_train)\n",
        "y_pred = cat.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO5hOa2K-R5L",
        "outputId": "d3c2b6bc-31cc-470c-cf1a-33b08bce11c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.728246942341293\n",
            "Precision :   0.7178502879078695\n",
            "Recall    :   0.7211376235237407\n",
            "F1-score  :   0.7194902007935554\n",
            "Confusion matrix      : \n",
            "  [[6520 2352]\n",
            " [2314 5984]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.73      0.74      8872\n",
            "         1.0       0.72      0.72      0.72      8298\n",
            "\n",
            "    accuracy                           0.73     17170\n",
            "   macro avg       0.73      0.73      0.73     17170\n",
            "weighted avg       0.73      0.73      0.73     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging Classifier\n",
        "bgc_rf.fit(x_train,y_train)\n",
        "y_pred = bgc_rf.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvUNehgFAAEY",
        "outputId": "bd26518a-defc-44b4-d235-adf8bc929f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.7336633663366336\n",
            "Precision :   0.7174547577349679\n",
            "Recall    :   0.7405398891299109\n",
            "F1-score  :   0.7288145644310028\n",
            "Confusion matrix      : \n",
            "  [[6452 2420]\n",
            " [2153 6145]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.73      0.74      8872\n",
            "         1.0       0.72      0.74      0.73      8298\n",
            "\n",
            "    accuracy                           0.73     17170\n",
            "   macro avg       0.73      0.73      0.73     17170\n",
            "weighted avg       0.73      0.73      0.73     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_gbc.fit(x_train,y_train)\n",
        "y_pred = hist_gbc.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aJSk3DOdW-F",
        "outputId": "237041ce-ba7e-4efe-8a0d-539e58c5de86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6825859056493885\n",
            "Precision :   0.6650057937427578\n",
            "Recall    :   0.6916124367317426\n",
            "F1-score  :   0.6780482041587901\n",
            "Confusion matrix      : \n",
            "  [[5981 2891]\n",
            " [2559 5739]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.67      0.69      8872\n",
            "         1.0       0.67      0.69      0.68      8298\n",
            "\n",
            "    accuracy                           0.68     17170\n",
            "   macro avg       0.68      0.68      0.68     17170\n",
            "weighted avg       0.68      0.68      0.68     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaboost Classifier\n",
        "ada.fit(x_train,y_train)\n",
        "y_pred = ada.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7lZ9IFMjYDH",
        "outputId": "f5aa4aca-d96e-405d-d181-a02672431d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.7410017472335468\n",
            "Precision :   0.7294173716192065\n",
            "Recall    :   0.737768136900458\n",
            "F1-score  :   0.7335689892756577\n",
            "Confusion matrix      : \n",
            "  [[6601 2271]\n",
            " [2176 6122]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.74      0.75      8872\n",
            "         1.0       0.73      0.74      0.73      8298\n",
            "\n",
            "    accuracy                           0.74     17170\n",
            "   macro avg       0.74      0.74      0.74     17170\n",
            "weighted avg       0.74      0.74      0.74     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LGBM\n",
        "lgbm.fit(x_train,y_train)\n",
        "y_pred = lgbm.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzAImyNWlPoV",
        "outputId": "0ac1adda-1451-4b17-8ab6-576edbe9789a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 18934, number of negative: 21128\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036570 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21824\n",
            "[LightGBM] [Info] Number of data points in the train set: 40062, number of used features: 139\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.472617 -> initscore=-0.109640\n",
            "[LightGBM] [Info] Start training from score -0.109640\n",
            "Accuracy  :   0.6885264997087944\n",
            "Precision :   0.6714318921431892\n",
            "Recall    :   0.6961918534586647\n",
            "F1-score  :   0.6835877410957283\n",
            "Confusion matrix      : \n",
            "  [[6045 2827]\n",
            " [2521 5777]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.68      0.69      8872\n",
            "         1.0       0.67      0.70      0.68      8298\n",
            "\n",
            "    accuracy                           0.69     17170\n",
            "   macro avg       0.69      0.69      0.69     17170\n",
            "weighted avg       0.69      0.69      0.69     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL"
      ],
      "metadata": {
        "id": "k6tIpBZ3mxJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries for DL\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn import decomposition as decom\n",
        "from keras.metrics import Precision, Recall\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "kIABmAwjlTum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting dataset into train, validation and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "IOpupEZPpldB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create DL Model\n",
        "def create_dl_model(x_train):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256, input_shape=(x_train.shape[1],), activation='relu'))\n",
        "  model.add(Dense(128, activation='tanh'))\n",
        "  model.add(Dense(64, activation='tanh'))\n",
        "  model.add(Dense(32, activation='tanh'))\n",
        "  model.add(Dense(16, activation='tanh'))\n",
        "  model.add(Dense(8, activation='tanh'))\n",
        "  model.add(Dense(4, activation='tanh'))\n",
        "  model.add(Dense(2, activation='tanh'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "zYzOMbyWn_-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to compile and evaluate model\n",
        "def train_model(model, opt, x_train, y_train, x_val, y_val, x_test, y_test, epoch, batch_size):\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', Precision(), Recall()])\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "  hist = model.fit(x_train, y_train, epochs=epoch, batch_size=batch_size, validation_data=(x_val, y_val), callbacks=[early_stopping])\n",
        "  _, accuracy,precision,recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "  return accuracy,precision,recall, hist"
      ],
      "metadata": {
        "id": "xb9H8rSNoFXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_dl_model(x_train) # create model"
      ],
      "metadata": {
        "id": "fGtfd7JxS14j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to print evaluation metrices\n",
        "def print_score(score):\n",
        "  print(\"Accuracy  : \", score[0])\n",
        "  print(\"Precision : \", score[1])\n",
        "  print(\"Recall    : \", score[2])\n",
        "  f1_score = (2*score[1]*score[2])/(score[1]+score[2])\n",
        "  print(\"F1- Score : \", f1_score)"
      ],
      "metadata": {
        "id": "l2YG8xbLoIdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model and evaluating scores with different batch size and optimizers and iterations"
      ],
      "metadata": {
        "id": "br-S2rBY2z5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [64, 128, 256, 512]\n",
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adam\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfnkotHyoTCf",
        "outputId": "80b32ed8-00ae-4ffc-b23c-9618c15b5f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 6s 7ms/step - loss: 0.6543 - accuracy: 0.6157 - precision: 0.5914 - recall: 0.6395 - val_loss: 0.6429 - val_accuracy: 0.6386 - val_precision: 0.6181 - val_recall: 0.5983\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6347 - accuracy: 0.6439 - precision: 0.6147 - recall: 0.6876 - val_loss: 0.6250 - val_accuracy: 0.6587 - val_precision: 0.6170 - val_recall: 0.7158\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 0.6281 - accuracy: 0.6498 - precision: 0.6220 - recall: 0.6854 - val_loss: 0.6232 - val_accuracy: 0.6587 - val_precision: 0.6115 - val_recall: 0.7443\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.6250 - accuracy: 0.6511 - precision: 0.6254 - recall: 0.6771 - val_loss: 0.6203 - val_accuracy: 0.6571 - val_precision: 0.6224 - val_recall: 0.6811\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.6217 - accuracy: 0.6559 - precision: 0.6292 - recall: 0.6855 - val_loss: 0.6258 - val_accuracy: 0.6544 - val_precision: 0.5969 - val_recall: 0.8079\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.6214 - accuracy: 0.6557 - precision: 0.6283 - recall: 0.6882 - val_loss: 0.6282 - val_accuracy: 0.6542 - val_precision: 0.6237 - val_recall: 0.6601\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6201 - accuracy: 0.6565 - precision: 0.6300 - recall: 0.6851 - val_loss: 0.6182 - val_accuracy: 0.6643 - val_precision: 0.6262 - val_recall: 0.7030\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 0.6176 - accuracy: 0.6597 - precision: 0.6399 - recall: 0.6621 - val_loss: 0.6186 - val_accuracy: 0.6559 - val_precision: 0.6085 - val_recall: 0.7445\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.6169 - accuracy: 0.6595 - precision: 0.6367 - recall: 0.6732 - val_loss: 0.6188 - val_accuracy: 0.6524 - val_precision: 0.5947 - val_recall: 0.8103\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.6164 - accuracy: 0.6587 - precision: 0.6320 - recall: 0.6881 - val_loss: 0.6194 - val_accuracy: 0.6587 - val_precision: 0.6080 - val_recall: 0.7640\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.6144 - accuracy: 0.6589 - precision: 0.6360 - recall: 0.6728 - val_loss: 0.6124 - val_accuracy: 0.6602 - val_precision: 0.6191 - val_recall: 0.7139\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.6131 - accuracy: 0.6651 - precision: 0.6416 - recall: 0.6814 - val_loss: 0.6139 - val_accuracy: 0.6620 - val_precision: 0.6301 - val_recall: 0.6747\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.6127 - accuracy: 0.6635 - precision: 0.6428 - recall: 0.6695 - val_loss: 0.6149 - val_accuracy: 0.6623 - val_precision: 0.6118 - val_recall: 0.7637\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6114 - accuracy: 0.6636 - precision: 0.6401 - recall: 0.6797 - val_loss: 0.6188 - val_accuracy: 0.6556 - val_precision: 0.6029 - val_recall: 0.7760\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6112 - accuracy: 0.6642 - precision: 0.6419 - recall: 0.6760 - val_loss: 0.6152 - val_accuracy: 0.6628 - val_precision: 0.6279 - val_recall: 0.6881\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6092 - accuracy: 0.6664 - precision: 0.6437 - recall: 0.6797 - val_loss: 0.6121 - val_accuracy: 0.6564 - val_precision: 0.6541 - val_recall: 0.5658\n",
            "Epoch 17/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.6082 - accuracy: 0.6664 - precision: 0.6444 - recall: 0.6769 - val_loss: 0.6100 - val_accuracy: 0.6640 - val_precision: 0.6418 - val_recall: 0.6404\n",
            "Epoch 18/100\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 0.6064 - accuracy: 0.6683 - precision: 0.6480 - recall: 0.6732 - val_loss: 0.6119 - val_accuracy: 0.6598 - val_precision: 0.6575 - val_recall: 0.5717\n",
            "Epoch 19/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6064 - accuracy: 0.6679 - precision: 0.6475 - recall: 0.6728 - val_loss: 0.6097 - val_accuracy: 0.6596 - val_precision: 0.6197 - val_recall: 0.7075\n",
            "Epoch 20/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6061 - accuracy: 0.6671 - precision: 0.6444 - recall: 0.6803 - val_loss: 0.6154 - val_accuracy: 0.6582 - val_precision: 0.6030 - val_recall: 0.7914\n",
            "Epoch 21/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6071 - accuracy: 0.6671 - precision: 0.6417 - recall: 0.6906 - val_loss: 0.6092 - val_accuracy: 0.6629 - val_precision: 0.6304 - val_recall: 0.6782\n",
            "Epoch 22/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6037 - accuracy: 0.6690 - precision: 0.6452 - recall: 0.6864 - val_loss: 0.6202 - val_accuracy: 0.6578 - val_precision: 0.6006 - val_recall: 0.8045\n",
            "Epoch 23/100\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 0.6040 - accuracy: 0.6684 - precision: 0.6462 - recall: 0.6795 - val_loss: 0.6053 - val_accuracy: 0.6609 - val_precision: 0.6180 - val_recall: 0.7235\n",
            "Epoch 24/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.6047 - accuracy: 0.6665 - precision: 0.6409 - recall: 0.6907 - val_loss: 0.6129 - val_accuracy: 0.6594 - val_precision: 0.6050 - val_recall: 0.7864\n",
            "Epoch 25/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6019 - accuracy: 0.6706 - precision: 0.6501 - recall: 0.6763 - val_loss: 0.6092 - val_accuracy: 0.6581 - val_precision: 0.6088 - val_recall: 0.7555\n",
            "Epoch 26/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6032 - accuracy: 0.6703 - precision: 0.6457 - recall: 0.6904 - val_loss: 0.6069 - val_accuracy: 0.6640 - val_precision: 0.6156 - val_recall: 0.7533\n",
            "Epoch 27/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6018 - accuracy: 0.6694 - precision: 0.6435 - recall: 0.6943 - val_loss: 0.6105 - val_accuracy: 0.6518 - val_precision: 0.5960 - val_recall: 0.7970\n",
            "Epoch 28/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.6016 - accuracy: 0.6697 - precision: 0.6460 - recall: 0.6864 - val_loss: 0.6074 - val_accuracy: 0.6648 - val_precision: 0.6551 - val_recall: 0.6010\n",
            "Epoch 29/100\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 0.6004 - accuracy: 0.6716 - precision: 0.6502 - recall: 0.6807 - val_loss: 0.6091 - val_accuracy: 0.6640 - val_precision: 0.6317 - val_recall: 0.6785\n",
            "Epoch 30/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.6008 - accuracy: 0.6715 - precision: 0.6515 - recall: 0.6753 - val_loss: 0.6069 - val_accuracy: 0.6624 - val_precision: 0.6256 - val_recall: 0.6961\n",
            "Epoch 31/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5993 - accuracy: 0.6716 - precision: 0.6489 - recall: 0.6847 - val_loss: 0.6047 - val_accuracy: 0.6637 - val_precision: 0.6555 - val_recall: 0.5946\n",
            "Epoch 32/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5984 - accuracy: 0.6738 - precision: 0.6540 - recall: 0.6773 - val_loss: 0.6068 - val_accuracy: 0.6630 - val_precision: 0.6191 - val_recall: 0.7299\n",
            "Epoch 33/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5986 - accuracy: 0.6736 - precision: 0.6507 - recall: 0.6876 - val_loss: 0.6082 - val_accuracy: 0.6652 - val_precision: 0.6445 - val_recall: 0.6361\n",
            "Epoch 34/100\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 0.5974 - accuracy: 0.6757 - precision: 0.6559 - recall: 0.6796 - val_loss: 0.6132 - val_accuracy: 0.6628 - val_precision: 0.6113 - val_recall: 0.7696\n",
            "Epoch 35/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.5960 - accuracy: 0.6758 - precision: 0.6552 - recall: 0.6819 - val_loss: 0.6044 - val_accuracy: 0.6642 - val_precision: 0.6498 - val_recall: 0.6140\n",
            "Epoch 36/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5970 - accuracy: 0.6749 - precision: 0.6523 - recall: 0.6879 - val_loss: 0.6149 - val_accuracy: 0.6592 - val_precision: 0.6228 - val_recall: 0.6913\n",
            "Epoch 37/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5967 - accuracy: 0.6761 - precision: 0.6562 - recall: 0.6799 - val_loss: 0.6127 - val_accuracy: 0.6618 - val_precision: 0.6123 - val_recall: 0.7584\n",
            "Epoch 38/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5972 - accuracy: 0.6758 - precision: 0.6548 - recall: 0.6833 - val_loss: 0.6241 - val_accuracy: 0.6559 - val_precision: 0.6097 - val_recall: 0.7381\n",
            "Epoch 39/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5968 - accuracy: 0.6735 - precision: 0.6532 - recall: 0.6786 - val_loss: 0.6096 - val_accuracy: 0.6660 - val_precision: 0.6366 - val_recall: 0.6692\n",
            "Epoch 40/100\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 0.5941 - accuracy: 0.6769 - precision: 0.6577 - recall: 0.6786 - val_loss: 0.6086 - val_accuracy: 0.6684 - val_precision: 0.6264 - val_recall: 0.7240\n",
            "Epoch 41/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.5945 - accuracy: 0.6752 - precision: 0.6527 - recall: 0.6879 - val_loss: 0.6079 - val_accuracy: 0.6628 - val_precision: 0.6249 - val_recall: 0.7011\n",
            "Epoch 42/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5927 - accuracy: 0.6775 - precision: 0.6574 - recall: 0.6821 - val_loss: 0.6069 - val_accuracy: 0.6639 - val_precision: 0.6253 - val_recall: 0.7051\n",
            "Epoch 43/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5924 - accuracy: 0.6783 - precision: 0.6562 - recall: 0.6896 - val_loss: 0.6232 - val_accuracy: 0.6572 - val_precision: 0.5983 - val_recall: 0.8162\n",
            "Epoch 44/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5923 - accuracy: 0.6792 - precision: 0.6580 - recall: 0.6877 - val_loss: 0.6096 - val_accuracy: 0.6658 - val_precision: 0.6346 - val_recall: 0.6755\n",
            "Epoch 45/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.5929 - accuracy: 0.6776 - precision: 0.6604 - recall: 0.6729 - val_loss: 0.6087 - val_accuracy: 0.6645 - val_precision: 0.6353 - val_recall: 0.6665\n",
            "Accuracy  :  0.6618520617485046\n",
            "Precision :  0.6533280611038208\n",
            "Recall    :  0.6086367964744568\n",
            "F1- Score :  0.6301910798374712\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 3s 7ms/step - loss: 0.5929 - accuracy: 0.6800 - precision_1: 0.6569 - recall_1: 0.6948 - val_loss: 0.6081 - val_accuracy: 0.6639 - val_precision_1: 0.6356 - val_recall_1: 0.6622\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5918 - accuracy: 0.6794 - precision_1: 0.6564 - recall_1: 0.6939 - val_loss: 0.6033 - val_accuracy: 0.6642 - val_precision_1: 0.6523 - val_recall_1: 0.6063\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5911 - accuracy: 0.6803 - precision_1: 0.6601 - recall_1: 0.6856 - val_loss: 0.6072 - val_accuracy: 0.6620 - val_precision_1: 0.6356 - val_recall_1: 0.6532\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5898 - accuracy: 0.6811 - precision_1: 0.6608 - recall_1: 0.6865 - val_loss: 0.6078 - val_accuracy: 0.6640 - val_precision_1: 0.6191 - val_recall_1: 0.7355\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 2s 6ms/step - loss: 0.5891 - accuracy: 0.6820 - precision_1: 0.6558 - recall_1: 0.7075 - val_loss: 0.6074 - val_accuracy: 0.6640 - val_precision_1: 0.6517 - val_recall_1: 0.6076\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.5900 - accuracy: 0.6808 - precision_1: 0.6568 - recall_1: 0.6984 - val_loss: 0.6053 - val_accuracy: 0.6648 - val_precision_1: 0.6338 - val_recall_1: 0.6737\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 2s 6ms/step - loss: 0.5886 - accuracy: 0.6823 - precision_1: 0.6631 - recall_1: 0.6844 - val_loss: 0.6051 - val_accuracy: 0.6670 - val_precision_1: 0.6302 - val_recall_1: 0.7001\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.5871 - accuracy: 0.6815 - precision_1: 0.6624 - recall_1: 0.6830 - val_loss: 0.6082 - val_accuracy: 0.6629 - val_precision_1: 0.6189 - val_recall_1: 0.7299\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.6827 - precision_1: 0.6603 - recall_1: 0.6952 - val_loss: 0.6121 - val_accuracy: 0.6578 - val_precision_1: 0.6120 - val_recall_1: 0.7365\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.6832 - precision_1: 0.6620 - recall_1: 0.6917 - val_loss: 0.6135 - val_accuracy: 0.6625 - val_precision_1: 0.6187 - val_recall_1: 0.7288\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5858 - accuracy: 0.6834 - precision_1: 0.6628 - recall_1: 0.6901 - val_loss: 0.6132 - val_accuracy: 0.6630 - val_precision_1: 0.6245 - val_recall_1: 0.7043\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5856 - accuracy: 0.6838 - precision_1: 0.6676 - recall_1: 0.6768 - val_loss: 0.6076 - val_accuracy: 0.6653 - val_precision_1: 0.6356 - val_recall_1: 0.6694\n",
            "Accuracy  :  0.6617938280105591\n",
            "Precision :  0.6573559045791626\n",
            "Recall    :  0.5964567065238953\n",
            "F1- Score :  0.625427331623953\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 4s 16ms/step - loss: 0.5888 - accuracy: 0.6804 - precision_2: 0.6597 - recall_2: 0.6872 - val_loss: 0.6047 - val_accuracy: 0.6672 - val_precision_2: 0.6291 - val_recall_2: 0.7054\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.5867 - accuracy: 0.6811 - precision_2: 0.6583 - recall_2: 0.6948 - val_loss: 0.6075 - val_accuracy: 0.6609 - val_precision_2: 0.6191 - val_recall_2: 0.7182\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5871 - accuracy: 0.6820 - precision_2: 0.6599 - recall_2: 0.6936 - val_loss: 0.6075 - val_accuracy: 0.6653 - val_precision_2: 0.6182 - val_recall_2: 0.7469\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5864 - accuracy: 0.6828 - precision_2: 0.6631 - recall_2: 0.6866 - val_loss: 0.6052 - val_accuracy: 0.6648 - val_precision_2: 0.6294 - val_recall_2: 0.6921\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5844 - accuracy: 0.6848 - precision_2: 0.6653 - recall_2: 0.6881 - val_loss: 0.6060 - val_accuracy: 0.6668 - val_precision_2: 0.6284 - val_recall_2: 0.7067\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5860 - accuracy: 0.6845 - precision_2: 0.6639 - recall_2: 0.6913 - val_loss: 0.6084 - val_accuracy: 0.6643 - val_precision_2: 0.6312 - val_recall_2: 0.6817\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5854 - accuracy: 0.6844 - precision_2: 0.6638 - recall_2: 0.6909 - val_loss: 0.6047 - val_accuracy: 0.6684 - val_precision_2: 0.6402 - val_recall_2: 0.6673\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5830 - accuracy: 0.6838 - precision_2: 0.6641 - recall_2: 0.6874 - val_loss: 0.6062 - val_accuracy: 0.6653 - val_precision_2: 0.6311 - val_recall_2: 0.6875\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5812 - accuracy: 0.6850 - precision_2: 0.6650 - recall_2: 0.6896 - val_loss: 0.6059 - val_accuracy: 0.6670 - val_precision_2: 0.6338 - val_recall_2: 0.6851\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5829 - accuracy: 0.6871 - precision_2: 0.6656 - recall_2: 0.6968 - val_loss: 0.6085 - val_accuracy: 0.6619 - val_precision_2: 0.6400 - val_recall_2: 0.6364\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5818 - accuracy: 0.6861 - precision_2: 0.6653 - recall_2: 0.6934 - val_loss: 0.6020 - val_accuracy: 0.6680 - val_precision_2: 0.6415 - val_recall_2: 0.6606\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5803 - accuracy: 0.6870 - precision_2: 0.6678 - recall_2: 0.6895 - val_loss: 0.6033 - val_accuracy: 0.6638 - val_precision_2: 0.6285 - val_recall_2: 0.6907\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.5798 - accuracy: 0.6863 - precision_2: 0.6678 - recall_2: 0.6863 - val_loss: 0.6123 - val_accuracy: 0.6634 - val_precision_2: 0.6250 - val_recall_2: 0.7038\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5797 - accuracy: 0.6880 - precision_2: 0.6667 - recall_2: 0.6971 - val_loss: 0.6091 - val_accuracy: 0.6632 - val_precision_2: 0.6380 - val_recall_2: 0.6497\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 1s 9ms/step - loss: 0.5787 - accuracy: 0.6882 - precision_2: 0.6697 - recall_2: 0.6886 - val_loss: 0.6035 - val_accuracy: 0.6680 - val_precision_2: 0.6318 - val_recall_2: 0.6985\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5797 - accuracy: 0.6887 - precision_2: 0.6684 - recall_2: 0.6947 - val_loss: 0.6047 - val_accuracy: 0.6630 - val_precision_2: 0.6405 - val_recall_2: 0.6401\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5788 - accuracy: 0.6888 - precision_2: 0.6698 - recall_2: 0.6907 - val_loss: 0.6116 - val_accuracy: 0.6598 - val_precision_2: 0.6104 - val_recall_2: 0.7571\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5775 - accuracy: 0.6884 - precision_2: 0.6660 - recall_2: 0.7011 - val_loss: 0.6151 - val_accuracy: 0.6608 - val_precision_2: 0.6188 - val_recall_2: 0.7190\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5760 - accuracy: 0.6917 - precision_2: 0.6713 - recall_2: 0.6979 - val_loss: 0.6074 - val_accuracy: 0.6650 - val_precision_2: 0.6359 - val_recall_2: 0.6668\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5749 - accuracy: 0.6901 - precision_2: 0.6727 - recall_2: 0.6876 - val_loss: 0.6042 - val_accuracy: 0.6660 - val_precision_2: 0.6358 - val_recall_2: 0.6721\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5759 - accuracy: 0.6909 - precision_2: 0.6711 - recall_2: 0.6956 - val_loss: 0.6056 - val_accuracy: 0.6658 - val_precision_2: 0.6559 - val_recall_2: 0.6028\n",
            "Accuracy  :  0.6712871193885803\n",
            "Precision :  0.652617335319519\n",
            "Recall    :  0.6534202694892883\n",
            "F1- Score :  0.653018555587896\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 4s 26ms/step - loss: 0.5794 - accuracy: 0.6875 - precision_3: 0.6670 - recall_3: 0.6943 - val_loss: 0.6054 - val_accuracy: 0.6699 - val_precision_3: 0.6501 - val_recall_3: 0.6396\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.5766 - accuracy: 0.6899 - precision_3: 0.6692 - recall_3: 0.6972 - val_loss: 0.6078 - val_accuracy: 0.6670 - val_precision_3: 0.6345 - val_recall_3: 0.6825\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5756 - accuracy: 0.6912 - precision_3: 0.6728 - recall_3: 0.6916 - val_loss: 0.6063 - val_accuracy: 0.6668 - val_precision_3: 0.6447 - val_recall_3: 0.6433\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5750 - accuracy: 0.6927 - precision_3: 0.6759 - recall_3: 0.6886 - val_loss: 0.6028 - val_accuracy: 0.6675 - val_precision_3: 0.6384 - val_recall_3: 0.6697\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5745 - accuracy: 0.6893 - precision_3: 0.6700 - recall_3: 0.6921 - val_loss: 0.6047 - val_accuracy: 0.6662 - val_precision_3: 0.6420 - val_recall_3: 0.6497\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5739 - accuracy: 0.6917 - precision_3: 0.6727 - recall_3: 0.6939 - val_loss: 0.6056 - val_accuracy: 0.6657 - val_precision_3: 0.6302 - val_recall_3: 0.6931\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.5729 - accuracy: 0.6925 - precision_3: 0.6747 - recall_3: 0.6911 - val_loss: 0.6067 - val_accuracy: 0.6648 - val_precision_3: 0.6262 - val_recall_3: 0.7056\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5728 - accuracy: 0.6913 - precision_3: 0.6729 - recall_3: 0.6919 - val_loss: 0.6042 - val_accuracy: 0.6662 - val_precision_3: 0.6413 - val_recall_3: 0.6521\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5712 - accuracy: 0.6933 - precision_3: 0.6750 - recall_3: 0.6937 - val_loss: 0.6120 - val_accuracy: 0.6648 - val_precision_3: 0.6200 - val_recall_3: 0.7349\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5718 - accuracy: 0.6951 - precision_3: 0.6774 - recall_3: 0.6937 - val_loss: 0.6130 - val_accuracy: 0.6653 - val_precision_3: 0.6277 - val_recall_3: 0.7019\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.6943 - precision_3: 0.6755 - recall_3: 0.6961 - val_loss: 0.6081 - val_accuracy: 0.6620 - val_precision_3: 0.6381 - val_recall_3: 0.6438\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5705 - accuracy: 0.6934 - precision_3: 0.6755 - recall_3: 0.6924 - val_loss: 0.6077 - val_accuracy: 0.6637 - val_precision_3: 0.6367 - val_recall_3: 0.6569\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.5703 - accuracy: 0.6964 - precision_3: 0.6787 - recall_3: 0.6952 - val_loss: 0.6058 - val_accuracy: 0.6643 - val_precision_3: 0.6531 - val_recall_3: 0.6044\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.5681 - accuracy: 0.6974 - precision_3: 0.6836 - recall_3: 0.6855 - val_loss: 0.6076 - val_accuracy: 0.6677 - val_precision_3: 0.6335 - val_recall_3: 0.6897\n",
            "Accuracy  :  0.6705882549285889\n",
            "Precision :  0.6497455835342407\n",
            "Recall    :  0.6598179340362549\n",
            "F1- Score :  0.6547430236482062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [64, 128, 256, 512]\n",
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adadelta\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8VKmrn0shvM",
        "outputId": "1ea45b18-71ed-486a-e2e6-90818eaafd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 6s 7ms/step - loss: 0.5719 - accuracy: 0.6924 - precision_4: 0.6772 - recall_4: 0.6839 - val_loss: 0.6029 - val_accuracy: 0.6673 - val_precision_4: 0.6364 - val_recall_4: 0.6761\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5716 - accuracy: 0.6921 - precision_4: 0.6755 - recall_4: 0.6872 - val_loss: 0.6031 - val_accuracy: 0.6665 - val_precision_4: 0.6348 - val_recall_4: 0.6785\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5714 - accuracy: 0.6923 - precision_4: 0.6750 - recall_4: 0.6895 - val_loss: 0.6032 - val_accuracy: 0.6657 - val_precision_4: 0.6335 - val_recall_4: 0.6795\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5711 - accuracy: 0.6925 - precision_4: 0.6742 - recall_4: 0.6926 - val_loss: 0.6033 - val_accuracy: 0.6658 - val_precision_4: 0.6332 - val_recall_4: 0.6814\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.5710 - accuracy: 0.6929 - precision_4: 0.6746 - recall_4: 0.6934 - val_loss: 0.6034 - val_accuracy: 0.6654 - val_precision_4: 0.6324 - val_recall_4: 0.6825\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 0.5708 - accuracy: 0.6925 - precision_4: 0.6735 - recall_4: 0.6948 - val_loss: 0.6035 - val_accuracy: 0.6654 - val_precision_4: 0.6324 - val_recall_4: 0.6827\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.5706 - accuracy: 0.6926 - precision_4: 0.6736 - recall_4: 0.6949 - val_loss: 0.6036 - val_accuracy: 0.6660 - val_precision_4: 0.6330 - val_recall_4: 0.6833\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5705 - accuracy: 0.6929 - precision_4: 0.6739 - recall_4: 0.6952 - val_loss: 0.6037 - val_accuracy: 0.6655 - val_precision_4: 0.6323 - val_recall_4: 0.6838\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.5704 - accuracy: 0.6931 - precision_4: 0.6739 - recall_4: 0.6958 - val_loss: 0.6037 - val_accuracy: 0.6662 - val_precision_4: 0.6328 - val_recall_4: 0.6849\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 2s 5ms/step - loss: 0.5703 - accuracy: 0.6931 - precision_4: 0.6741 - recall_4: 0.6957 - val_loss: 0.6038 - val_accuracy: 0.6663 - val_precision_4: 0.6329 - val_recall_4: 0.6851\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5702 - accuracy: 0.6931 - precision_4: 0.6739 - recall_4: 0.6961 - val_loss: 0.6039 - val_accuracy: 0.6660 - val_precision_4: 0.6326 - val_recall_4: 0.6851\n",
            "Accuracy  :  0.6695981621742249\n",
            "Precision :  0.6471645832061768\n",
            "Recall    :  0.6641240119934082\n",
            "F1- Score :  0.6555346260042939\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 3s 7ms/step - loss: 0.5716 - accuracy: 0.6921 - precision_5: 0.6755 - recall_5: 0.6872 - val_loss: 0.6030 - val_accuracy: 0.6665 - val_precision_5: 0.6348 - val_recall_5: 0.6785\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5714 - accuracy: 0.6925 - precision_5: 0.6753 - recall_5: 0.6895 - val_loss: 0.6031 - val_accuracy: 0.6657 - val_precision_5: 0.6335 - val_recall_5: 0.6795\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5712 - accuracy: 0.6927 - precision_5: 0.6747 - recall_5: 0.6920 - val_loss: 0.6032 - val_accuracy: 0.6659 - val_precision_5: 0.6335 - val_recall_5: 0.6806\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 2s 6ms/step - loss: 0.5711 - accuracy: 0.6928 - precision_5: 0.6745 - recall_5: 0.6930 - val_loss: 0.6033 - val_accuracy: 0.6658 - val_precision_5: 0.6332 - val_recall_5: 0.6814\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 2s 8ms/step - loss: 0.5710 - accuracy: 0.6927 - precision_5: 0.6741 - recall_5: 0.6939 - val_loss: 0.6034 - val_accuracy: 0.6652 - val_precision_5: 0.6323 - val_recall_5: 0.6819\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.5709 - accuracy: 0.6928 - precision_5: 0.6741 - recall_5: 0.6943 - val_loss: 0.6034 - val_accuracy: 0.6650 - val_precision_5: 0.6320 - val_recall_5: 0.6825\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5707 - accuracy: 0.6928 - precision_5: 0.6740 - recall_5: 0.6945 - val_loss: 0.6035 - val_accuracy: 0.6655 - val_precision_5: 0.6324 - val_recall_5: 0.6833\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5706 - accuracy: 0.6927 - precision_5: 0.6737 - recall_5: 0.6950 - val_loss: 0.6036 - val_accuracy: 0.6659 - val_precision_5: 0.6329 - val_recall_5: 0.6833\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.5705 - accuracy: 0.6928 - precision_5: 0.6738 - recall_5: 0.6952 - val_loss: 0.6036 - val_accuracy: 0.6655 - val_precision_5: 0.6323 - val_recall_5: 0.6835\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5704 - accuracy: 0.6929 - precision_5: 0.6739 - recall_5: 0.6954 - val_loss: 0.6037 - val_accuracy: 0.6659 - val_precision_5: 0.6325 - val_recall_5: 0.6846\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5704 - accuracy: 0.6929 - precision_5: 0.6738 - recall_5: 0.6958 - val_loss: 0.6037 - val_accuracy: 0.6664 - val_precision_5: 0.6330 - val_recall_5: 0.6854\n",
            "Accuracy  :  0.6697728633880615\n",
            "Precision :  0.6465537548065186\n",
            "Recall    :  0.6670767664909363\n",
            "F1- Score :  0.6566549438770896\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 4s 16ms/step - loss: 0.5714 - accuracy: 0.6921 - precision_6: 0.6750 - recall_6: 0.6888 - val_loss: 0.6031 - val_accuracy: 0.6659 - val_precision_6: 0.6339 - val_recall_6: 0.6793\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.5713 - accuracy: 0.6926 - precision_6: 0.6749 - recall_6: 0.6911 - val_loss: 0.6031 - val_accuracy: 0.6657 - val_precision_6: 0.6335 - val_recall_6: 0.6795\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5712 - accuracy: 0.6928 - precision_6: 0.6747 - recall_6: 0.6922 - val_loss: 0.6032 - val_accuracy: 0.6659 - val_precision_6: 0.6334 - val_recall_6: 0.6811\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5711 - accuracy: 0.6927 - precision_6: 0.6743 - recall_6: 0.6931 - val_loss: 0.6033 - val_accuracy: 0.6655 - val_precision_6: 0.6329 - val_recall_6: 0.6811\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5710 - accuracy: 0.6928 - precision_6: 0.6743 - recall_6: 0.6935 - val_loss: 0.6033 - val_accuracy: 0.6657 - val_precision_6: 0.6329 - val_recall_6: 0.6819\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5709 - accuracy: 0.6930 - precision_6: 0.6745 - recall_6: 0.6939 - val_loss: 0.6034 - val_accuracy: 0.6653 - val_precision_6: 0.6323 - val_recall_6: 0.6822\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5709 - accuracy: 0.6927 - precision_6: 0.6739 - recall_6: 0.6945 - val_loss: 0.6034 - val_accuracy: 0.6652 - val_precision_6: 0.6321 - val_recall_6: 0.6827\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5708 - accuracy: 0.6927 - precision_6: 0.6737 - recall_6: 0.6949 - val_loss: 0.6034 - val_accuracy: 0.6653 - val_precision_6: 0.6321 - val_recall_6: 0.6830\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 1s 8ms/step - loss: 0.5707 - accuracy: 0.6923 - precision_6: 0.6733 - recall_6: 0.6947 - val_loss: 0.6035 - val_accuracy: 0.6652 - val_precision_6: 0.6319 - val_recall_6: 0.6833\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5706 - accuracy: 0.6926 - precision_6: 0.6735 - recall_6: 0.6952 - val_loss: 0.6035 - val_accuracy: 0.6654 - val_precision_6: 0.6322 - val_recall_6: 0.6835\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5706 - accuracy: 0.6927 - precision_6: 0.6735 - recall_6: 0.6955 - val_loss: 0.6036 - val_accuracy: 0.6657 - val_precision_6: 0.6324 - val_recall_6: 0.6841\n",
            "Accuracy  :  0.6700057983398438\n",
            "Precision :  0.6464778780937195\n",
            "Recall    :  0.6684300899505615\n",
            "F1- Score :  0.6572707394084036\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 4s 25ms/step - loss: 0.5713 - accuracy: 0.6925 - precision_7: 0.6749 - recall_7: 0.6907 - val_loss: 0.6031 - val_accuracy: 0.6657 - val_precision_7: 0.6335 - val_recall_7: 0.6795\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.5712 - accuracy: 0.6926 - precision_7: 0.6746 - recall_7: 0.6919 - val_loss: 0.6032 - val_accuracy: 0.6659 - val_precision_7: 0.6336 - val_recall_7: 0.6803\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5712 - accuracy: 0.6929 - precision_7: 0.6749 - recall_7: 0.6924 - val_loss: 0.6032 - val_accuracy: 0.6658 - val_precision_7: 0.6332 - val_recall_7: 0.6811\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5711 - accuracy: 0.6929 - precision_7: 0.6746 - recall_7: 0.6930 - val_loss: 0.6032 - val_accuracy: 0.6657 - val_precision_7: 0.6330 - val_recall_7: 0.6814\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5710 - accuracy: 0.6928 - precision_7: 0.6743 - recall_7: 0.6934 - val_loss: 0.6033 - val_accuracy: 0.6654 - val_precision_7: 0.6326 - val_recall_7: 0.6819\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5710 - accuracy: 0.6928 - precision_7: 0.6743 - recall_7: 0.6936 - val_loss: 0.6033 - val_accuracy: 0.6654 - val_precision_7: 0.6325 - val_recall_7: 0.6822\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5709 - accuracy: 0.6928 - precision_7: 0.6742 - recall_7: 0.6939 - val_loss: 0.6033 - val_accuracy: 0.6655 - val_precision_7: 0.6325 - val_recall_7: 0.6827\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5709 - accuracy: 0.6927 - precision_7: 0.6740 - recall_7: 0.6943 - val_loss: 0.6034 - val_accuracy: 0.6653 - val_precision_7: 0.6322 - val_recall_7: 0.6827\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5708 - accuracy: 0.6926 - precision_7: 0.6737 - recall_7: 0.6947 - val_loss: 0.6034 - val_accuracy: 0.6653 - val_precision_7: 0.6321 - val_recall_7: 0.6830\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5708 - accuracy: 0.6927 - precision_7: 0.6737 - recall_7: 0.6949 - val_loss: 0.6034 - val_accuracy: 0.6655 - val_precision_7: 0.6323 - val_recall_7: 0.6835\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.5707 - accuracy: 0.6928 - precision_7: 0.6738 - recall_7: 0.6949 - val_loss: 0.6035 - val_accuracy: 0.6657 - val_precision_7: 0.6324 - val_recall_7: 0.6838\n",
            "Accuracy  :  0.6698893308639526\n",
            "Precision :  0.6460114121437073\n",
            "Recall    :  0.6695374250411987\n",
            "F1- Score :  0.657564060273853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [64, 128, 256, 512]\n",
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"rmsprop\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sR-b7GiobNB",
        "outputId": "f30b633a-8ce0-4e02-fcb9-cd784d1599a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 7s 9ms/step - loss: 0.5889 - accuracy: 0.6808 - precision_8: 0.6619 - recall_8: 0.6818 - val_loss: 0.6259 - val_accuracy: 0.6473 - val_precision_8: 0.6595 - val_recall_8: 0.5112\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.5892 - accuracy: 0.6812 - precision_8: 0.6615 - recall_8: 0.6848 - val_loss: 0.6199 - val_accuracy: 0.6603 - val_precision_8: 0.6285 - val_recall_8: 0.6723\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5884 - accuracy: 0.6815 - precision_8: 0.6621 - recall_8: 0.6844 - val_loss: 0.6108 - val_accuracy: 0.6650 - val_precision_8: 0.6202 - val_recall_8: 0.7352\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5882 - accuracy: 0.6830 - precision_8: 0.6631 - recall_8: 0.6876 - val_loss: 0.6109 - val_accuracy: 0.6607 - val_precision_8: 0.6122 - val_recall_8: 0.7523\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.5865 - accuracy: 0.6831 - precision_8: 0.6635 - recall_8: 0.6868 - val_loss: 0.6043 - val_accuracy: 0.6672 - val_precision_8: 0.6327 - val_recall_8: 0.6905\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 0.5885 - accuracy: 0.6811 - precision_8: 0.6617 - recall_8: 0.6838 - val_loss: 0.6056 - val_accuracy: 0.6664 - val_precision_8: 0.6302 - val_recall_8: 0.6969\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5866 - accuracy: 0.6829 - precision_8: 0.6637 - recall_8: 0.6851 - val_loss: 0.6134 - val_accuracy: 0.6662 - val_precision_8: 0.6316 - val_recall_8: 0.6897\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5867 - accuracy: 0.6827 - precision_8: 0.6614 - recall_8: 0.6913 - val_loss: 0.6051 - val_accuracy: 0.6640 - val_precision_8: 0.6457 - val_recall_8: 0.6268\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5853 - accuracy: 0.6837 - precision_8: 0.6645 - recall_8: 0.6857 - val_loss: 0.6153 - val_accuracy: 0.6557 - val_precision_8: 0.5998 - val_recall_8: 0.7965\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5835 - accuracy: 0.6854 - precision_8: 0.6668 - recall_8: 0.6859 - val_loss: 0.6128 - val_accuracy: 0.6642 - val_precision_8: 0.6153 - val_recall_8: 0.7555\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 3s 6ms/step - loss: 0.5857 - accuracy: 0.6841 - precision_8: 0.6639 - recall_8: 0.6894 - val_loss: 0.6056 - val_accuracy: 0.6650 - val_precision_8: 0.6452 - val_recall_8: 0.6332\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 3s 5ms/step - loss: 0.5843 - accuracy: 0.6846 - precision_8: 0.6645 - recall_8: 0.6897 - val_loss: 0.6113 - val_accuracy: 0.6607 - val_precision_8: 0.6791 - val_recall_8: 0.5226\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5834 - accuracy: 0.6852 - precision_8: 0.6632 - recall_8: 0.6965 - val_loss: 0.6090 - val_accuracy: 0.6640 - val_precision_8: 0.6229 - val_recall_8: 0.7168\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5832 - accuracy: 0.6859 - precision_8: 0.6630 - recall_8: 0.6999 - val_loss: 0.6180 - val_accuracy: 0.6592 - val_precision_8: 0.6493 - val_recall_8: 0.5924\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 2s 4ms/step - loss: 0.5823 - accuracy: 0.6855 - precision_8: 0.6650 - recall_8: 0.6921 - val_loss: 0.6139 - val_accuracy: 0.6566 - val_precision_8: 0.6683 - val_recall_8: 0.5298\n",
            "Accuracy  :  0.67070472240448\n",
            "Precision :  0.6446444988250732\n",
            "Recall    :  0.6782726645469666\n",
            "F1- Score :  0.6610311726383753\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 4s 10ms/step - loss: 0.5824 - accuracy: 0.6846 - precision_9: 0.6635 - recall_9: 0.6929 - val_loss: 0.6048 - val_accuracy: 0.6659 - val_precision_9: 0.6409 - val_recall_9: 0.6524\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 2s 7ms/step - loss: 0.5799 - accuracy: 0.6856 - precision_9: 0.6642 - recall_9: 0.6949 - val_loss: 0.6155 - val_accuracy: 0.6620 - val_precision_9: 0.6364 - val_recall_9: 0.6500\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5791 - accuracy: 0.6889 - precision_9: 0.6700 - recall_9: 0.6907 - val_loss: 0.6085 - val_accuracy: 0.6664 - val_precision_9: 0.6442 - val_recall_9: 0.6430\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5785 - accuracy: 0.6892 - precision_9: 0.6689 - recall_9: 0.6952 - val_loss: 0.6078 - val_accuracy: 0.6659 - val_precision_9: 0.6417 - val_recall_9: 0.6497\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5781 - accuracy: 0.6885 - precision_9: 0.6690 - recall_9: 0.6923 - val_loss: 0.6135 - val_accuracy: 0.6625 - val_precision_9: 0.6289 - val_recall_9: 0.6825\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5780 - accuracy: 0.6899 - precision_9: 0.6695 - recall_9: 0.6962 - val_loss: 0.6099 - val_accuracy: 0.6660 - val_precision_9: 0.6358 - val_recall_9: 0.6723\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5754 - accuracy: 0.6905 - precision_9: 0.6712 - recall_9: 0.6936 - val_loss: 0.6111 - val_accuracy: 0.6623 - val_precision_9: 0.6476 - val_recall_9: 0.6124\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 0.5756 - accuracy: 0.6901 - precision_9: 0.6697 - recall_9: 0.6967 - val_loss: 0.6054 - val_accuracy: 0.6655 - val_precision_9: 0.6280 - val_recall_9: 0.7019\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 1s 6ms/step - loss: 0.5745 - accuracy: 0.6910 - precision_9: 0.6719 - recall_9: 0.6934 - val_loss: 0.6166 - val_accuracy: 0.6614 - val_precision_9: 0.6346 - val_recall_9: 0.6537\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 2s 7ms/step - loss: 0.5746 - accuracy: 0.6931 - precision_9: 0.6740 - recall_9: 0.6955 - val_loss: 0.6156 - val_accuracy: 0.6606 - val_precision_9: 0.6534 - val_recall_9: 0.5866\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 2s 8ms/step - loss: 0.5737 - accuracy: 0.6938 - precision_9: 0.6738 - recall_9: 0.6994 - val_loss: 0.6336 - val_accuracy: 0.6497 - val_precision_9: 0.5986 - val_recall_9: 0.7658\n",
            "Accuracy  :  0.6682003736495972\n",
            "Precision :  0.6507503390312195\n",
            "Recall    :  0.6455462574958801\n",
            "F1- Score :  0.6481378521724704\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 2s 10ms/step - loss: 0.5776 - accuracy: 0.6884 - precision_10: 0.6711 - recall_10: 0.6853 - val_loss: 0.6068 - val_accuracy: 0.6647 - val_precision_10: 0.6317 - val_recall_10: 0.6817\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.6904 - precision_10: 0.6701 - recall_10: 0.6964 - val_loss: 0.6152 - val_accuracy: 0.6648 - val_precision_10: 0.6616 - val_recall_10: 0.5823\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5737 - accuracy: 0.6917 - precision_10: 0.6717 - recall_10: 0.6968 - val_loss: 0.6114 - val_accuracy: 0.6658 - val_precision_10: 0.6374 - val_recall_10: 0.6649\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5743 - accuracy: 0.6928 - precision_10: 0.6750 - recall_10: 0.6915 - val_loss: 0.6177 - val_accuracy: 0.6557 - val_precision_10: 0.6734 - val_recall_10: 0.5147\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.5724 - accuracy: 0.6942 - precision_10: 0.6766 - recall_10: 0.6924 - val_loss: 0.6088 - val_accuracy: 0.6660 - val_precision_10: 0.6412 - val_recall_10: 0.6518\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.5726 - accuracy: 0.6950 - precision_10: 0.6750 - recall_10: 0.7005 - val_loss: 0.6135 - val_accuracy: 0.6581 - val_precision_10: 0.6431 - val_recall_10: 0.6068\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 1s 10ms/step - loss: 0.5710 - accuracy: 0.6931 - precision_10: 0.6753 - recall_10: 0.6921 - val_loss: 0.6126 - val_accuracy: 0.6665 - val_precision_10: 0.6291 - val_recall_10: 0.7025\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5709 - accuracy: 0.6938 - precision_10: 0.6757 - recall_10: 0.6935 - val_loss: 0.6324 - val_accuracy: 0.6583 - val_precision_10: 0.6076 - val_recall_10: 0.7643\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.6963 - precision_10: 0.6755 - recall_10: 0.7043 - val_loss: 0.6323 - val_accuracy: 0.6579 - val_precision_10: 0.6112 - val_recall_10: 0.7413\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5690 - accuracy: 0.6966 - precision_10: 0.6784 - recall_10: 0.6970 - val_loss: 0.6154 - val_accuracy: 0.6494 - val_precision_10: 0.6652 - val_recall_10: 0.5069\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 1s 7ms/step - loss: 0.5680 - accuracy: 0.6980 - precision_10: 0.6794 - recall_10: 0.6997 - val_loss: 0.6100 - val_accuracy: 0.6608 - val_precision_10: 0.6462 - val_recall_10: 0.6100\n",
            "Accuracy  :  0.6680256128311157\n",
            "Precision :  0.6419550776481628\n",
            "Recall    :  0.6754429340362549\n",
            "F1- Score :  0.6582733802850412\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 2s 15ms/step - loss: 0.5742 - accuracy: 0.6917 - precision_11: 0.6740 - recall_11: 0.6901 - val_loss: 0.6043 - val_accuracy: 0.6662 - val_precision_11: 0.6438 - val_recall_11: 0.6433\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5727 - accuracy: 0.6930 - precision_11: 0.6749 - recall_11: 0.6924 - val_loss: 0.6081 - val_accuracy: 0.6678 - val_precision_11: 0.6194 - val_recall_11: 0.7544\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5707 - accuracy: 0.6937 - precision_11: 0.6732 - recall_11: 0.7005 - val_loss: 0.6097 - val_accuracy: 0.6675 - val_precision_11: 0.6371 - val_recall_11: 0.6745\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5705 - accuracy: 0.6938 - precision_11: 0.6752 - recall_11: 0.6951 - val_loss: 0.6119 - val_accuracy: 0.6654 - val_precision_11: 0.6182 - val_recall_11: 0.7475\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5695 - accuracy: 0.6944 - precision_11: 0.6742 - recall_11: 0.7007 - val_loss: 0.6100 - val_accuracy: 0.6648 - val_precision_11: 0.6330 - val_recall_11: 0.6771\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5688 - accuracy: 0.6976 - precision_11: 0.6800 - recall_11: 0.6963 - val_loss: 0.6170 - val_accuracy: 0.6598 - val_precision_11: 0.6086 - val_recall_11: 0.7674\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.5683 - accuracy: 0.6953 - precision_11: 0.6761 - recall_11: 0.6982 - val_loss: 0.6064 - val_accuracy: 0.6698 - val_precision_11: 0.6471 - val_recall_11: 0.6492\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 16ms/step - loss: 0.5676 - accuracy: 0.6975 - precision_11: 0.6779 - recall_11: 0.7020 - val_loss: 0.6061 - val_accuracy: 0.6673 - val_precision_11: 0.6571 - val_recall_11: 0.6060\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.5669 - accuracy: 0.6959 - precision_11: 0.6784 - recall_11: 0.6940 - val_loss: 0.6059 - val_accuracy: 0.6685 - val_precision_11: 0.6402 - val_recall_11: 0.6678\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 11ms/step - loss: 0.5668 - accuracy: 0.6971 - precision_11: 0.6795 - recall_11: 0.6958 - val_loss: 0.6162 - val_accuracy: 0.6674 - val_precision_11: 0.6222 - val_recall_11: 0.7387\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.5656 - accuracy: 0.6979 - precision_11: 0.6802 - recall_11: 0.6970 - val_loss: 0.6109 - val_accuracy: 0.6699 - val_precision_11: 0.6444 - val_recall_11: 0.6590\n",
            "Accuracy  :  0.6715783476829529\n",
            "Precision :  0.6582326889038086\n",
            "Recall    :  0.6369340419769287\n",
            "F1- Score :  0.6474082403579758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM**"
      ],
      "metadata": {
        "id": "ju1D8u98t9aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create LSTM Model\n",
        "def create_model(data):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.LSTM(64, input_shape=(1, data.shape[2]), return_sequences=True),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.LSTM(32),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "yP916APos9wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to split data into train, test and val and preprocess it\n",
        "def split_data(x, y):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
        "  x_val = x_val.reshape(x_val.shape[0], 1, x_val.shape[1])\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
        "  return x_train, x_val, x_test, y_train, y_val, y_test"
      ],
      "metadata": {
        "id": "AbTSaOahu6H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate_score(model, x_test, y_test):\n",
        "#   _, acc, prec, rec = model.evaluate(x_test, y_test)\n",
        "#   try:\n",
        "#     f1_score = (2*prec*rec)/(prec+rec)\n",
        "#   except:\n",
        "#     f1_score = 0\n",
        "#   print(\"Accuracy  :\", acc)\n",
        "#   print(\"Precision :\", prec)\n",
        "#   print(\"Recall    :\", rec)\n",
        "#   print(\"F1-Score  :\", f1_score)"
      ],
      "metadata": {
        "id": "HRxpH97Cv8bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting dataset and creating model\n",
        "batches = [64, 128, 256, 512]\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = split_data(x.values, y.values)\n",
        "model = create_model(x_train)"
      ],
      "metadata": {
        "id": "tjw2yRMzzhoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model and evaluating scores with different batch size and optimizers and iterations"
      ],
      "metadata": {
        "id": "e4DMUyxv3OLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adam\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw0UcPsauFAm",
        "outputId": "55e98c39-157a-45ba-e4e1-aa6091be9197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 13s 13ms/step - loss: 0.6790 - accuracy: 0.5906 - precision_12: 0.5930 - recall_12: 0.4629 - val_loss: 0.6531 - val_accuracy: 0.6262 - val_precision_12: 0.5794 - val_recall_12: 0.7379\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6539 - accuracy: 0.6308 - precision_12: 0.6107 - recall_12: 0.6321 - val_loss: 0.6440 - val_accuracy: 0.6295 - val_precision_12: 0.6267 - val_recall_12: 0.5173\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6458 - accuracy: 0.6396 - precision_12: 0.6151 - recall_12: 0.6612 - val_loss: 0.6351 - val_accuracy: 0.6524 - val_precision_12: 0.6035 - val_recall_12: 0.7525\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6389 - accuracy: 0.6469 - precision_12: 0.6191 - recall_12: 0.6828 - val_loss: 0.6260 - val_accuracy: 0.6604 - val_precision_12: 0.6190 - val_recall_12: 0.7158\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6339 - accuracy: 0.6488 - precision_12: 0.6201 - recall_12: 0.6887 - val_loss: 0.6297 - val_accuracy: 0.6458 - val_precision_12: 0.5912 - val_recall_12: 0.7912\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6326 - accuracy: 0.6496 - precision_12: 0.6218 - recall_12: 0.6849 - val_loss: 0.6224 - val_accuracy: 0.6628 - val_precision_12: 0.6340 - val_recall_12: 0.6628\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6292 - accuracy: 0.6527 - precision_12: 0.6245 - recall_12: 0.6894 - val_loss: 0.6255 - val_accuracy: 0.6473 - val_precision_12: 0.5932 - val_recall_12: 0.7869\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6287 - accuracy: 0.6534 - precision_12: 0.6227 - recall_12: 0.7011 - val_loss: 0.6211 - val_accuracy: 0.6620 - val_precision_12: 0.6368 - val_recall_12: 0.6484\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6306 - accuracy: 0.6525 - precision_12: 0.6285 - recall_12: 0.6714 - val_loss: 0.6206 - val_accuracy: 0.6573 - val_precision_12: 0.6103 - val_recall_12: 0.7429\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6283 - accuracy: 0.6547 - precision_12: 0.6291 - recall_12: 0.6801 - val_loss: 0.6214 - val_accuracy: 0.6581 - val_precision_12: 0.6137 - val_recall_12: 0.7288\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6274 - accuracy: 0.6562 - precision_12: 0.6304 - recall_12: 0.6820 - val_loss: 0.6198 - val_accuracy: 0.6549 - val_precision_12: 0.6455 - val_recall_12: 0.5844\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6264 - accuracy: 0.6561 - precision_12: 0.6328 - recall_12: 0.6715 - val_loss: 0.6226 - val_accuracy: 0.6591 - val_precision_12: 0.6180 - val_recall_12: 0.7128\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6274 - accuracy: 0.6569 - precision_12: 0.6358 - recall_12: 0.6640 - val_loss: 0.6168 - val_accuracy: 0.6630 - val_precision_12: 0.6236 - val_recall_12: 0.7083\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6246 - accuracy: 0.6556 - precision_12: 0.6339 - recall_12: 0.6650 - val_loss: 0.6161 - val_accuracy: 0.6611 - val_precision_12: 0.6331 - val_recall_12: 0.6577\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6230 - accuracy: 0.6571 - precision_12: 0.6362 - recall_12: 0.6635 - val_loss: 0.6171 - val_accuracy: 0.6587 - val_precision_12: 0.6478 - val_recall_12: 0.5948\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6238 - accuracy: 0.6591 - precision_12: 0.6378 - recall_12: 0.6666 - val_loss: 0.6192 - val_accuracy: 0.6608 - val_precision_12: 0.6133 - val_recall_12: 0.7467\n",
            "Epoch 17/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6228 - accuracy: 0.6603 - precision_12: 0.6399 - recall_12: 0.6650 - val_loss: 0.6167 - val_accuracy: 0.6638 - val_precision_12: 0.6152 - val_recall_12: 0.7541\n",
            "Epoch 18/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6215 - accuracy: 0.6612 - precision_12: 0.6372 - recall_12: 0.6794 - val_loss: 0.6165 - val_accuracy: 0.6623 - val_precision_12: 0.6387 - val_recall_12: 0.6428\n",
            "Epoch 19/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.6208 - accuracy: 0.6601 - precision_12: 0.6394 - recall_12: 0.6662 - val_loss: 0.6174 - val_accuracy: 0.6639 - val_precision_12: 0.6159 - val_recall_12: 0.7509\n",
            "Epoch 20/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6223 - accuracy: 0.6611 - precision_12: 0.6401 - recall_12: 0.6679 - val_loss: 0.6152 - val_accuracy: 0.6643 - val_precision_12: 0.6175 - val_recall_12: 0.7445\n",
            "Epoch 21/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6212 - accuracy: 0.6606 - precision_12: 0.6398 - recall_12: 0.6665 - val_loss: 0.6120 - val_accuracy: 0.6618 - val_precision_12: 0.6263 - val_recall_12: 0.6897\n",
            "Epoch 22/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6216 - accuracy: 0.6631 - precision_12: 0.6398 - recall_12: 0.6790 - val_loss: 0.6122 - val_accuracy: 0.6639 - val_precision_12: 0.6376 - val_recall_12: 0.6548\n",
            "Epoch 23/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6198 - accuracy: 0.6606 - precision_12: 0.6422 - recall_12: 0.6577 - val_loss: 0.6116 - val_accuracy: 0.6645 - val_precision_12: 0.6350 - val_recall_12: 0.6678\n",
            "Epoch 24/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6201 - accuracy: 0.6630 - precision_12: 0.6432 - recall_12: 0.6656 - val_loss: 0.6123 - val_accuracy: 0.6602 - val_precision_12: 0.6388 - val_recall_12: 0.6321\n",
            "Epoch 25/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6190 - accuracy: 0.6653 - precision_12: 0.6481 - recall_12: 0.6588 - val_loss: 0.6113 - val_accuracy: 0.6583 - val_precision_12: 0.6475 - val_recall_12: 0.5940\n",
            "Epoch 26/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6190 - accuracy: 0.6624 - precision_12: 0.6427 - recall_12: 0.6644 - val_loss: 0.6097 - val_accuracy: 0.6645 - val_precision_12: 0.6343 - val_recall_12: 0.6705\n",
            "Epoch 27/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6175 - accuracy: 0.6626 - precision_12: 0.6408 - recall_12: 0.6726 - val_loss: 0.6101 - val_accuracy: 0.6623 - val_precision_12: 0.6331 - val_recall_12: 0.6638\n",
            "Epoch 28/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6179 - accuracy: 0.6636 - precision_12: 0.6439 - recall_12: 0.6657 - val_loss: 0.6108 - val_accuracy: 0.6593 - val_precision_12: 0.6564 - val_recall_12: 0.5725\n",
            "Epoch 29/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6165 - accuracy: 0.6645 - precision_12: 0.6453 - recall_12: 0.6653 - val_loss: 0.6118 - val_accuracy: 0.6664 - val_precision_12: 0.6287 - val_recall_12: 0.7035\n",
            "Epoch 30/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6174 - accuracy: 0.6622 - precision_12: 0.6403 - recall_12: 0.6727 - val_loss: 0.6116 - val_accuracy: 0.6657 - val_precision_12: 0.6235 - val_recall_12: 0.7230\n",
            "Epoch 31/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.6176 - accuracy: 0.6621 - precision_12: 0.6421 - recall_12: 0.6655 - val_loss: 0.6104 - val_accuracy: 0.6609 - val_precision_12: 0.6564 - val_recall_12: 0.5796\n",
            "Epoch 32/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6159 - accuracy: 0.6662 - precision_12: 0.6472 - recall_12: 0.6663 - val_loss: 0.6208 - val_accuracy: 0.6582 - val_precision_12: 0.6020 - val_recall_12: 0.7978\n",
            "Epoch 33/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6158 - accuracy: 0.6667 - precision_12: 0.6473 - recall_12: 0.6681 - val_loss: 0.6084 - val_accuracy: 0.6643 - val_precision_12: 0.6301 - val_recall_12: 0.6865\n",
            "Epoch 34/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6148 - accuracy: 0.6661 - precision_12: 0.6440 - recall_12: 0.6771 - val_loss: 0.6084 - val_accuracy: 0.6660 - val_precision_12: 0.6459 - val_recall_12: 0.6356\n",
            "Epoch 35/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6148 - accuracy: 0.6657 - precision_12: 0.6462 - recall_12: 0.6674 - val_loss: 0.6088 - val_accuracy: 0.6674 - val_precision_12: 0.6264 - val_recall_12: 0.7187\n",
            "Epoch 36/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6144 - accuracy: 0.6658 - precision_12: 0.6463 - recall_12: 0.6672 - val_loss: 0.6091 - val_accuracy: 0.6653 - val_precision_12: 0.6422 - val_recall_12: 0.6449\n",
            "Epoch 37/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6152 - accuracy: 0.6666 - precision_12: 0.6476 - recall_12: 0.6668 - val_loss: 0.6145 - val_accuracy: 0.6603 - val_precision_12: 0.6085 - val_recall_12: 0.7709\n",
            "Epoch 38/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6141 - accuracy: 0.6636 - precision_12: 0.6443 - recall_12: 0.6646 - val_loss: 0.6084 - val_accuracy: 0.6618 - val_precision_12: 0.6515 - val_recall_12: 0.5980\n",
            "Epoch 39/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6123 - accuracy: 0.6662 - precision_12: 0.6489 - recall_12: 0.6605 - val_loss: 0.6154 - val_accuracy: 0.6683 - val_precision_12: 0.6223 - val_recall_12: 0.7427\n",
            "Epoch 40/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6126 - accuracy: 0.6672 - precision_12: 0.6485 - recall_12: 0.6661 - val_loss: 0.6078 - val_accuracy: 0.6674 - val_precision_12: 0.6514 - val_recall_12: 0.6241\n",
            "Epoch 41/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6120 - accuracy: 0.6673 - precision_12: 0.6445 - recall_12: 0.6812 - val_loss: 0.6095 - val_accuracy: 0.6639 - val_precision_12: 0.6499 - val_recall_12: 0.6127\n",
            "Epoch 42/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6109 - accuracy: 0.6693 - precision_12: 0.6483 - recall_12: 0.6766 - val_loss: 0.6149 - val_accuracy: 0.6650 - val_precision_12: 0.6163 - val_recall_12: 0.7555\n",
            "Epoch 43/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6128 - accuracy: 0.6660 - precision_12: 0.6443 - recall_12: 0.6754 - val_loss: 0.6099 - val_accuracy: 0.6640 - val_precision_12: 0.6148 - val_recall_12: 0.7573\n",
            "Epoch 44/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6106 - accuracy: 0.6689 - precision_12: 0.6496 - recall_12: 0.6702 - val_loss: 0.6105 - val_accuracy: 0.6640 - val_precision_12: 0.6487 - val_recall_12: 0.6169\n",
            "Epoch 45/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6095 - accuracy: 0.6692 - precision_12: 0.6539 - recall_12: 0.6571 - val_loss: 0.6064 - val_accuracy: 0.6679 - val_precision_12: 0.6313 - val_recall_12: 0.7001\n",
            "Epoch 46/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6117 - accuracy: 0.6687 - precision_12: 0.6496 - recall_12: 0.6690 - val_loss: 0.6056 - val_accuracy: 0.6679 - val_precision_12: 0.6431 - val_recall_12: 0.6542\n",
            "Epoch 47/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.6117 - accuracy: 0.6675 - precision_12: 0.6502 - recall_12: 0.6618 - val_loss: 0.6061 - val_accuracy: 0.6653 - val_precision_12: 0.6524 - val_recall_12: 0.6113\n",
            "Epoch 48/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.6094 - accuracy: 0.6706 - precision_12: 0.6509 - recall_12: 0.6733 - val_loss: 0.6122 - val_accuracy: 0.6642 - val_precision_12: 0.6146 - val_recall_12: 0.7592\n",
            "Epoch 49/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6093 - accuracy: 0.6725 - precision_12: 0.6529 - recall_12: 0.6754 - val_loss: 0.6055 - val_accuracy: 0.6668 - val_precision_12: 0.6491 - val_recall_12: 0.6284\n",
            "Epoch 50/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6100 - accuracy: 0.6705 - precision_12: 0.6527 - recall_12: 0.6672 - val_loss: 0.6103 - val_accuracy: 0.6667 - val_precision_12: 0.6196 - val_recall_12: 0.7472\n",
            "Epoch 51/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6062 - accuracy: 0.6724 - precision_12: 0.6533 - recall_12: 0.6732 - val_loss: 0.6056 - val_accuracy: 0.6682 - val_precision_12: 0.6329 - val_recall_12: 0.6945\n",
            "Epoch 52/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6085 - accuracy: 0.6742 - precision_12: 0.6528 - recall_12: 0.6829 - val_loss: 0.6099 - val_accuracy: 0.6622 - val_precision_12: 0.6100 - val_recall_12: 0.7733\n",
            "Epoch 53/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6085 - accuracy: 0.6715 - precision_12: 0.6494 - recall_12: 0.6827 - val_loss: 0.6059 - val_accuracy: 0.6652 - val_precision_12: 0.6161 - val_recall_12: 0.7568\n",
            "Epoch 54/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.6075 - accuracy: 0.6706 - precision_12: 0.6481 - recall_12: 0.6832 - val_loss: 0.6090 - val_accuracy: 0.6672 - val_precision_12: 0.6280 - val_recall_12: 0.7102\n",
            "Epoch 55/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6076 - accuracy: 0.6702 - precision_12: 0.6492 - recall_12: 0.6777 - val_loss: 0.6074 - val_accuracy: 0.6678 - val_precision_12: 0.6383 - val_recall_12: 0.6713\n",
            "Epoch 56/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6074 - accuracy: 0.6734 - precision_12: 0.6537 - recall_12: 0.6764 - val_loss: 0.6053 - val_accuracy: 0.6684 - val_precision_12: 0.6367 - val_recall_12: 0.6806\n",
            "Epoch 57/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6071 - accuracy: 0.6737 - precision_12: 0.6529 - recall_12: 0.6806 - val_loss: 0.6037 - val_accuracy: 0.6655 - val_precision_12: 0.6607 - val_recall_12: 0.5882\n",
            "Epoch 58/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6053 - accuracy: 0.6759 - precision_12: 0.6597 - recall_12: 0.6678 - val_loss: 0.6038 - val_accuracy: 0.6704 - val_precision_12: 0.6392 - val_recall_12: 0.6809\n",
            "Epoch 59/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6064 - accuracy: 0.6731 - precision_12: 0.6527 - recall_12: 0.6784 - val_loss: 0.6072 - val_accuracy: 0.6667 - val_precision_12: 0.6285 - val_recall_12: 0.7054\n",
            "Epoch 60/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6056 - accuracy: 0.6731 - precision_12: 0.6550 - recall_12: 0.6708 - val_loss: 0.6030 - val_accuracy: 0.6718 - val_precision_12: 0.6455 - val_recall_12: 0.6641\n",
            "Epoch 61/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6059 - accuracy: 0.6725 - precision_12: 0.6535 - recall_12: 0.6733 - val_loss: 0.6096 - val_accuracy: 0.6647 - val_precision_12: 0.6144 - val_recall_12: 0.7635\n",
            "Epoch 62/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6052 - accuracy: 0.6744 - precision_12: 0.6544 - recall_12: 0.6785 - val_loss: 0.6045 - val_accuracy: 0.6710 - val_precision_12: 0.6327 - val_recall_12: 0.7099\n",
            "Epoch 63/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6051 - accuracy: 0.6732 - precision_12: 0.6568 - recall_12: 0.6653 - val_loss: 0.6099 - val_accuracy: 0.6627 - val_precision_12: 0.6133 - val_recall_12: 0.7579\n",
            "Epoch 64/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6043 - accuracy: 0.6734 - precision_12: 0.6519 - recall_12: 0.6825 - val_loss: 0.6055 - val_accuracy: 0.6689 - val_precision_12: 0.6236 - val_recall_12: 0.7397\n",
            "Epoch 65/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6024 - accuracy: 0.6762 - precision_12: 0.6554 - recall_12: 0.6833 - val_loss: 0.6041 - val_accuracy: 0.6697 - val_precision_12: 0.6524 - val_recall_12: 0.6313\n",
            "Epoch 66/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.6033 - accuracy: 0.6789 - precision_12: 0.6595 - recall_12: 0.6814 - val_loss: 0.6055 - val_accuracy: 0.6635 - val_precision_12: 0.6546 - val_recall_12: 0.5967\n",
            "Epoch 67/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.6036 - accuracy: 0.6780 - precision_12: 0.6613 - recall_12: 0.6715 - val_loss: 0.6043 - val_accuracy: 0.6699 - val_precision_12: 0.6244 - val_recall_12: 0.7416\n",
            "Epoch 68/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.6025 - accuracy: 0.6765 - precision_12: 0.6570 - recall_12: 0.6788 - val_loss: 0.6034 - val_accuracy: 0.6713 - val_precision_12: 0.6441 - val_recall_12: 0.6668\n",
            "Epoch 69/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6039 - accuracy: 0.6755 - precision_12: 0.6526 - recall_12: 0.6896 - val_loss: 0.6076 - val_accuracy: 0.6663 - val_precision_12: 0.6125 - val_recall_12: 0.7832\n",
            "Epoch 70/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.6022 - accuracy: 0.6769 - precision_12: 0.6538 - recall_12: 0.6919 - val_loss: 0.6021 - val_accuracy: 0.6753 - val_precision_12: 0.6438 - val_recall_12: 0.6870\n",
            "Epoch 71/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6015 - accuracy: 0.6797 - precision_12: 0.6616 - recall_12: 0.6781 - val_loss: 0.6028 - val_accuracy: 0.6700 - val_precision_12: 0.6339 - val_recall_12: 0.6998\n",
            "Epoch 72/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5997 - accuracy: 0.6776 - precision_12: 0.6565 - recall_12: 0.6859 - val_loss: 0.6044 - val_accuracy: 0.6700 - val_precision_12: 0.6245 - val_recall_12: 0.7416\n",
            "Epoch 73/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6033 - accuracy: 0.6747 - precision_12: 0.6529 - recall_12: 0.6850 - val_loss: 0.6038 - val_accuracy: 0.6708 - val_precision_12: 0.6407 - val_recall_12: 0.6769\n",
            "Epoch 74/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5997 - accuracy: 0.6796 - precision_12: 0.6601 - recall_12: 0.6822 - val_loss: 0.6060 - val_accuracy: 0.6707 - val_precision_12: 0.6412 - val_recall_12: 0.6742\n",
            "Epoch 75/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6011 - accuracy: 0.6803 - precision_12: 0.6616 - recall_12: 0.6808 - val_loss: 0.6024 - val_accuracy: 0.6710 - val_precision_12: 0.6574 - val_recall_12: 0.6220\n",
            "Epoch 76/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.6003 - accuracy: 0.6776 - precision_12: 0.6563 - recall_12: 0.6860 - val_loss: 0.6028 - val_accuracy: 0.6738 - val_precision_12: 0.6425 - val_recall_12: 0.6846\n",
            "Epoch 77/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6011 - accuracy: 0.6819 - precision_12: 0.6631 - recall_12: 0.6829 - val_loss: 0.6017 - val_accuracy: 0.6704 - val_precision_12: 0.6400 - val_recall_12: 0.6777\n",
            "Epoch 78/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6000 - accuracy: 0.6792 - precision_12: 0.6577 - recall_12: 0.6887 - val_loss: 0.6068 - val_accuracy: 0.6672 - val_precision_12: 0.6242 - val_recall_12: 0.7278\n",
            "Epoch 79/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.5970 - accuracy: 0.6847 - precision_12: 0.6639 - recall_12: 0.6922 - val_loss: 0.6055 - val_accuracy: 0.6660 - val_precision_12: 0.6189 - val_recall_12: 0.7475\n",
            "Epoch 80/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5971 - accuracy: 0.6789 - precision_12: 0.6584 - recall_12: 0.6851 - val_loss: 0.6096 - val_accuracy: 0.6574 - val_precision_12: 0.6055 - val_recall_12: 0.7714\n",
            "Epoch 81/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5995 - accuracy: 0.6778 - precision_12: 0.6606 - recall_12: 0.6734 - val_loss: 0.6021 - val_accuracy: 0.6732 - val_precision_12: 0.6413 - val_recall_12: 0.6859\n",
            "Epoch 82/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5978 - accuracy: 0.6838 - precision_12: 0.6616 - recall_12: 0.6956 - val_loss: 0.6026 - val_accuracy: 0.6727 - val_precision_12: 0.6351 - val_recall_12: 0.7080\n",
            "Epoch 83/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.5983 - accuracy: 0.6811 - precision_12: 0.6604 - recall_12: 0.6880 - val_loss: 0.6021 - val_accuracy: 0.6683 - val_precision_12: 0.6188 - val_recall_12: 0.7603\n",
            "Epoch 84/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5967 - accuracy: 0.6812 - precision_12: 0.6596 - recall_12: 0.6911 - val_loss: 0.6026 - val_accuracy: 0.6707 - val_precision_12: 0.6639 - val_recall_12: 0.6015\n",
            "Epoch 85/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.5965 - accuracy: 0.6825 - precision_12: 0.6608 - recall_12: 0.6926 - val_loss: 0.6029 - val_accuracy: 0.6712 - val_precision_12: 0.6334 - val_recall_12: 0.7078\n",
            "Epoch 86/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.5971 - accuracy: 0.6834 - precision_12: 0.6615 - recall_12: 0.6941 - val_loss: 0.6024 - val_accuracy: 0.6670 - val_precision_12: 0.6217 - val_recall_12: 0.7387\n",
            "Epoch 87/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5955 - accuracy: 0.6835 - precision_12: 0.6613 - recall_12: 0.6954 - val_loss: 0.6017 - val_accuracy: 0.6717 - val_precision_12: 0.6565 - val_recall_12: 0.6273\n",
            "Accuracy  :  0.670471727848053\n",
            "Precision :  0.6467443108558655\n",
            "Recall    :  0.6696604490280151\n",
            "F1- Score :  0.658002916446848\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 13s 23ms/step - loss: 0.5969 - accuracy: 0.6816 - precision_13: 0.6588 - recall_13: 0.6957 - val_loss: 0.6012 - val_accuracy: 0.6757 - val_precision_13: 0.6381 - val_recall_13: 0.7107\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5973 - accuracy: 0.6783 - precision_13: 0.6579 - recall_13: 0.6840 - val_loss: 0.6067 - val_accuracy: 0.6684 - val_precision_13: 0.6215 - val_recall_13: 0.7475\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5956 - accuracy: 0.6841 - precision_13: 0.6615 - recall_13: 0.6973 - val_loss: 0.6034 - val_accuracy: 0.6673 - val_precision_13: 0.6460 - val_recall_13: 0.6412\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5974 - accuracy: 0.6825 - precision_13: 0.6613 - recall_13: 0.6910 - val_loss: 0.6031 - val_accuracy: 0.6720 - val_precision_13: 0.6266 - val_recall_13: 0.7421\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.5960 - accuracy: 0.6824 - precision_13: 0.6605 - recall_13: 0.6930 - val_loss: 0.6011 - val_accuracy: 0.6723 - val_precision_13: 0.6373 - val_recall_13: 0.6974\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5952 - accuracy: 0.6842 - precision_13: 0.6626 - recall_13: 0.6941 - val_loss: 0.6028 - val_accuracy: 0.6725 - val_precision_13: 0.6444 - val_recall_13: 0.6718\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5960 - accuracy: 0.6837 - precision_13: 0.6619 - recall_13: 0.6941 - val_loss: 0.6006 - val_accuracy: 0.6744 - val_precision_13: 0.6505 - val_recall_13: 0.6590\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5955 - accuracy: 0.6823 - precision_13: 0.6604 - recall_13: 0.6931 - val_loss: 0.6024 - val_accuracy: 0.6730 - val_precision_13: 0.6408 - val_recall_13: 0.6873\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5927 - accuracy: 0.6849 - precision_13: 0.6643 - recall_13: 0.6915 - val_loss: 0.6016 - val_accuracy: 0.6724 - val_precision_13: 0.6312 - val_recall_13: 0.7232\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5929 - accuracy: 0.6816 - precision_13: 0.6616 - recall_13: 0.6861 - val_loss: 0.6022 - val_accuracy: 0.6695 - val_precision_13: 0.6549 - val_recall_13: 0.6228\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5927 - accuracy: 0.6859 - precision_13: 0.6652 - recall_13: 0.6928 - val_loss: 0.6012 - val_accuracy: 0.6694 - val_precision_13: 0.6430 - val_recall_13: 0.6617\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5922 - accuracy: 0.6849 - precision_13: 0.6630 - recall_13: 0.6956 - val_loss: 0.5995 - val_accuracy: 0.6712 - val_precision_13: 0.6552 - val_recall_13: 0.6292\n",
            "Epoch 13/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5920 - accuracy: 0.6864 - precision_13: 0.6650 - recall_13: 0.6956 - val_loss: 0.5994 - val_accuracy: 0.6724 - val_precision_13: 0.6414 - val_recall_13: 0.6822\n",
            "Epoch 14/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5925 - accuracy: 0.6847 - precision_13: 0.6638 - recall_13: 0.6926 - val_loss: 0.6044 - val_accuracy: 0.6665 - val_precision_13: 0.6338 - val_recall_13: 0.6827\n",
            "Epoch 15/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5940 - accuracy: 0.6838 - precision_13: 0.6611 - recall_13: 0.6973 - val_loss: 0.5995 - val_accuracy: 0.6745 - val_precision_13: 0.6488 - val_recall_13: 0.6654\n",
            "Epoch 16/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5935 - accuracy: 0.6844 - precision_13: 0.6618 - recall_13: 0.6974 - val_loss: 0.5995 - val_accuracy: 0.6728 - val_precision_13: 0.6372 - val_recall_13: 0.7003\n",
            "Epoch 17/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5922 - accuracy: 0.6829 - precision_13: 0.6630 - recall_13: 0.6872 - val_loss: 0.6021 - val_accuracy: 0.6667 - val_precision_13: 0.6206 - val_recall_13: 0.7424\n",
            "Epoch 18/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.5892 - accuracy: 0.6887 - precision_13: 0.6654 - recall_13: 0.7042 - val_loss: 0.6014 - val_accuracy: 0.6714 - val_precision_13: 0.6499 - val_recall_13: 0.6473\n",
            "Epoch 19/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5907 - accuracy: 0.6856 - precision_13: 0.6640 - recall_13: 0.6954 - val_loss: 0.6042 - val_accuracy: 0.6739 - val_precision_13: 0.6481 - val_recall_13: 0.6652\n",
            "Epoch 20/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5911 - accuracy: 0.6880 - precision_13: 0.6679 - recall_13: 0.6936 - val_loss: 0.6021 - val_accuracy: 0.6724 - val_precision_13: 0.6347 - val_recall_13: 0.7086\n",
            "Epoch 21/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5918 - accuracy: 0.6850 - precision_13: 0.6639 - recall_13: 0.6936 - val_loss: 0.6010 - val_accuracy: 0.6689 - val_precision_13: 0.6533 - val_recall_13: 0.6249\n",
            "Epoch 22/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5922 - accuracy: 0.6843 - precision_13: 0.6621 - recall_13: 0.6960 - val_loss: 0.5988 - val_accuracy: 0.6722 - val_precision_13: 0.6310 - val_recall_13: 0.7230\n",
            "Epoch 23/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.5893 - accuracy: 0.6901 - precision_13: 0.6690 - recall_13: 0.6988 - val_loss: 0.6000 - val_accuracy: 0.6767 - val_precision_13: 0.6504 - val_recall_13: 0.6700\n",
            "Epoch 24/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5886 - accuracy: 0.6894 - precision_13: 0.6666 - recall_13: 0.7033 - val_loss: 0.5996 - val_accuracy: 0.6747 - val_precision_13: 0.6416 - val_recall_13: 0.6921\n",
            "Epoch 25/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5894 - accuracy: 0.6903 - precision_13: 0.6678 - recall_13: 0.7032 - val_loss: 0.6011 - val_accuracy: 0.6735 - val_precision_13: 0.6402 - val_recall_13: 0.6921\n",
            "Epoch 26/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5892 - accuracy: 0.6871 - precision_13: 0.6640 - recall_13: 0.7017 - val_loss: 0.5997 - val_accuracy: 0.6738 - val_precision_13: 0.6491 - val_recall_13: 0.6609\n",
            "Epoch 27/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.5896 - accuracy: 0.6859 - precision_13: 0.6659 - recall_13: 0.6907 - val_loss: 0.5995 - val_accuracy: 0.6764 - val_precision_13: 0.6414 - val_recall_13: 0.7014\n",
            "Epoch 28/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5899 - accuracy: 0.6872 - precision_13: 0.6660 - recall_13: 0.6958 - val_loss: 0.6001 - val_accuracy: 0.6722 - val_precision_13: 0.6325 - val_recall_13: 0.7166\n",
            "Epoch 29/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5913 - accuracy: 0.6895 - precision_13: 0.6658 - recall_13: 0.7063 - val_loss: 0.5985 - val_accuracy: 0.6740 - val_precision_13: 0.6458 - val_recall_13: 0.6737\n",
            "Epoch 30/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5901 - accuracy: 0.6869 - precision_13: 0.6657 - recall_13: 0.6954 - val_loss: 0.5997 - val_accuracy: 0.6729 - val_precision_13: 0.6425 - val_recall_13: 0.6803\n",
            "Epoch 31/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5877 - accuracy: 0.6908 - precision_13: 0.6705 - recall_13: 0.6971 - val_loss: 0.6001 - val_accuracy: 0.6688 - val_precision_13: 0.6593 - val_recall_13: 0.6063\n",
            "Epoch 32/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5892 - accuracy: 0.6884 - precision_13: 0.6673 - recall_13: 0.6969 - val_loss: 0.6021 - val_accuracy: 0.6734 - val_precision_13: 0.6482 - val_recall_13: 0.6625\n",
            "Epoch 33/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5878 - accuracy: 0.6885 - precision_13: 0.6696 - recall_13: 0.6902 - val_loss: 0.6041 - val_accuracy: 0.6727 - val_precision_13: 0.6212 - val_recall_13: 0.7722\n",
            "Epoch 34/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5874 - accuracy: 0.6893 - precision_13: 0.6661 - recall_13: 0.7042 - val_loss: 0.6002 - val_accuracy: 0.6744 - val_precision_13: 0.6426 - val_recall_13: 0.6873\n",
            "Epoch 35/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5874 - accuracy: 0.6902 - precision_13: 0.6682 - recall_13: 0.7014 - val_loss: 0.6013 - val_accuracy: 0.6718 - val_precision_13: 0.6338 - val_recall_13: 0.7091\n",
            "Epoch 36/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5872 - accuracy: 0.6905 - precision_13: 0.6682 - recall_13: 0.7026 - val_loss: 0.6034 - val_accuracy: 0.6734 - val_precision_13: 0.6310 - val_recall_13: 0.7296\n",
            "Epoch 37/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.5859 - accuracy: 0.6924 - precision_13: 0.6720 - recall_13: 0.6990 - val_loss: 0.5994 - val_accuracy: 0.6732 - val_precision_13: 0.6397 - val_recall_13: 0.6923\n",
            "Epoch 38/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5873 - accuracy: 0.6907 - precision_13: 0.6697 - recall_13: 0.6988 - val_loss: 0.5979 - val_accuracy: 0.6785 - val_precision_13: 0.6472 - val_recall_13: 0.6899\n",
            "Epoch 39/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5851 - accuracy: 0.6916 - precision_13: 0.6684 - recall_13: 0.7066 - val_loss: 0.6001 - val_accuracy: 0.6739 - val_precision_13: 0.6561 - val_recall_13: 0.6388\n",
            "Epoch 40/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5844 - accuracy: 0.6931 - precision_13: 0.6692 - recall_13: 0.7103 - val_loss: 0.5997 - val_accuracy: 0.6719 - val_precision_13: 0.6325 - val_recall_13: 0.7152\n",
            "Epoch 41/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5846 - accuracy: 0.6910 - precision_13: 0.6675 - recall_13: 0.7072 - val_loss: 0.5993 - val_accuracy: 0.6729 - val_precision_13: 0.6549 - val_recall_13: 0.6380\n",
            "Epoch 42/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5879 - accuracy: 0.6907 - precision_13: 0.6684 - recall_13: 0.7031 - val_loss: 0.6011 - val_accuracy: 0.6732 - val_precision_13: 0.6319 - val_recall_13: 0.7240\n",
            "Epoch 43/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5850 - accuracy: 0.6920 - precision_13: 0.6706 - recall_13: 0.7014 - val_loss: 0.5986 - val_accuracy: 0.6789 - val_precision_13: 0.6537 - val_recall_13: 0.6689\n",
            "Epoch 44/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5868 - accuracy: 0.6910 - precision_13: 0.6712 - recall_13: 0.6956 - val_loss: 0.6000 - val_accuracy: 0.6757 - val_precision_13: 0.6362 - val_recall_13: 0.7187\n",
            "Epoch 45/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5845 - accuracy: 0.6918 - precision_13: 0.6703 - recall_13: 0.7018 - val_loss: 0.5988 - val_accuracy: 0.6713 - val_precision_13: 0.6593 - val_recall_13: 0.6175\n",
            "Epoch 46/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.5836 - accuracy: 0.6946 - precision_13: 0.6750 - recall_13: 0.6986 - val_loss: 0.5984 - val_accuracy: 0.6728 - val_precision_13: 0.6342 - val_recall_13: 0.7126\n",
            "Epoch 47/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5834 - accuracy: 0.6938 - precision_13: 0.6725 - recall_13: 0.7031 - val_loss: 0.5989 - val_accuracy: 0.6705 - val_precision_13: 0.6230 - val_recall_13: 0.7515\n",
            "Epoch 48/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5833 - accuracy: 0.6916 - precision_13: 0.6662 - recall_13: 0.7135 - val_loss: 0.6006 - val_accuracy: 0.6715 - val_precision_13: 0.6296 - val_recall_13: 0.7259\n",
            "Accuracy  :  0.6730343699455261\n",
            "Precision :  0.6489689350128174\n",
            "Recall    :  0.6737204790115356\n",
            "F1- Score :  0.6611131186574861\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 10s 29ms/step - loss: 0.5840 - accuracy: 0.6921 - precision_14: 0.6703 - recall_14: 0.7027 - val_loss: 0.5995 - val_accuracy: 0.6738 - val_precision_14: 0.6473 - val_recall_14: 0.6673\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5850 - accuracy: 0.6890 - precision_14: 0.6695 - recall_14: 0.6924 - val_loss: 0.6031 - val_accuracy: 0.6728 - val_precision_14: 0.6295 - val_recall_14: 0.7331\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.5841 - accuracy: 0.6924 - precision_14: 0.6727 - recall_14: 0.6966 - val_loss: 0.5975 - val_accuracy: 0.6764 - val_precision_14: 0.6447 - val_recall_14: 0.6889\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.5823 - accuracy: 0.6934 - precision_14: 0.6698 - recall_14: 0.7097 - val_loss: 0.5993 - val_accuracy: 0.6767 - val_precision_14: 0.6417 - val_recall_14: 0.7014\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5836 - accuracy: 0.6937 - precision_14: 0.6710 - recall_14: 0.7073 - val_loss: 0.5980 - val_accuracy: 0.6773 - val_precision_14: 0.6484 - val_recall_14: 0.6798\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5823 - accuracy: 0.6936 - precision_14: 0.6742 - recall_14: 0.6971 - val_loss: 0.6015 - val_accuracy: 0.6767 - val_precision_14: 0.6467 - val_recall_14: 0.6830\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.5837 - accuracy: 0.6943 - precision_14: 0.6723 - recall_14: 0.7060 - val_loss: 0.5993 - val_accuracy: 0.6767 - val_precision_14: 0.6443 - val_recall_14: 0.6915\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5817 - accuracy: 0.6942 - precision_14: 0.6698 - recall_14: 0.7131 - val_loss: 0.5996 - val_accuracy: 0.6707 - val_precision_14: 0.6247 - val_recall_14: 0.7437\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.5823 - accuracy: 0.6943 - precision_14: 0.6688 - recall_14: 0.7169 - val_loss: 0.6001 - val_accuracy: 0.6732 - val_precision_14: 0.6571 - val_recall_14: 0.6324\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5822 - accuracy: 0.6917 - precision_14: 0.6710 - recall_14: 0.6990 - val_loss: 0.5991 - val_accuracy: 0.6755 - val_precision_14: 0.6433 - val_recall_14: 0.6899\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5815 - accuracy: 0.6933 - precision_14: 0.6709 - recall_14: 0.7059 - val_loss: 0.5999 - val_accuracy: 0.6769 - val_precision_14: 0.6511 - val_recall_14: 0.6686\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5792 - accuracy: 0.6949 - precision_14: 0.6744 - recall_14: 0.7020 - val_loss: 0.6002 - val_accuracy: 0.6742 - val_precision_14: 0.6540 - val_recall_14: 0.6465\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.5793 - accuracy: 0.6957 - precision_14: 0.6748 - recall_14: 0.7038 - val_loss: 0.6002 - val_accuracy: 0.6769 - val_precision_14: 0.6446 - val_recall_14: 0.6915\n",
            "Accuracy  :  0.6738497614860535\n",
            "Precision :  0.6493030786514282\n",
            "Recall    :  0.6763041615486145\n",
            "F1- Score :  0.6625286297199482\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 11s 57ms/step - loss: 0.5814 - accuracy: 0.6939 - precision_15: 0.6726 - recall_15: 0.7031 - val_loss: 0.6001 - val_accuracy: 0.6740 - val_precision_15: 0.6417 - val_recall_15: 0.6889\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5824 - accuracy: 0.6958 - precision_15: 0.6735 - recall_15: 0.7082 - val_loss: 0.5998 - val_accuracy: 0.6734 - val_precision_15: 0.6296 - val_recall_15: 0.7357\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5804 - accuracy: 0.6965 - precision_15: 0.6700 - recall_15: 0.7218 - val_loss: 0.5993 - val_accuracy: 0.6730 - val_precision_15: 0.6290 - val_recall_15: 0.7365\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.5813 - accuracy: 0.6937 - precision_15: 0.6717 - recall_15: 0.7051 - val_loss: 0.5988 - val_accuracy: 0.6773 - val_precision_15: 0.6417 - val_recall_15: 0.7043\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 0.5814 - accuracy: 0.6951 - precision_15: 0.6727 - recall_15: 0.7075 - val_loss: 0.6000 - val_accuracy: 0.6715 - val_precision_15: 0.6539 - val_recall_15: 0.6351\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.5793 - accuracy: 0.6950 - precision_15: 0.6711 - recall_15: 0.7121 - val_loss: 0.6013 - val_accuracy: 0.6742 - val_precision_15: 0.6289 - val_recall_15: 0.7429\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5794 - accuracy: 0.6965 - precision_15: 0.6719 - recall_15: 0.7157 - val_loss: 0.5994 - val_accuracy: 0.6778 - val_precision_15: 0.6418 - val_recall_15: 0.7064\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5796 - accuracy: 0.6934 - precision_15: 0.6711 - recall_15: 0.7060 - val_loss: 0.6005 - val_accuracy: 0.6771 - val_precision_15: 0.6461 - val_recall_15: 0.6873\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 24ms/step - loss: 0.5807 - accuracy: 0.6935 - precision_15: 0.6714 - recall_15: 0.7050 - val_loss: 0.5987 - val_accuracy: 0.6786 - val_precision_15: 0.6493 - val_recall_15: 0.6830\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.5791 - accuracy: 0.6973 - precision_15: 0.6737 - recall_15: 0.7136 - val_loss: 0.5993 - val_accuracy: 0.6794 - val_precision_15: 0.6426 - val_recall_15: 0.7112\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5795 - accuracy: 0.6947 - precision_15: 0.6723 - recall_15: 0.7074 - val_loss: 0.5977 - val_accuracy: 0.6749 - val_precision_15: 0.6417 - val_recall_15: 0.6931\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5786 - accuracy: 0.6948 - precision_15: 0.6708 - recall_15: 0.7122 - val_loss: 0.5978 - val_accuracy: 0.6793 - val_precision_15: 0.6528 - val_recall_15: 0.6737\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 0.5798 - accuracy: 0.6947 - precision_15: 0.6734 - recall_15: 0.7040 - val_loss: 0.5993 - val_accuracy: 0.6775 - val_precision_15: 0.6483 - val_recall_15: 0.6814\n",
            "Epoch 14/100\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.5790 - accuracy: 0.6942 - precision_15: 0.6716 - recall_15: 0.7076 - val_loss: 0.5984 - val_accuracy: 0.6767 - val_precision_15: 0.6456 - val_recall_15: 0.6867\n",
            "Epoch 15/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5788 - accuracy: 0.6949 - precision_15: 0.6730 - recall_15: 0.7063 - val_loss: 0.5989 - val_accuracy: 0.6755 - val_precision_15: 0.6432 - val_recall_15: 0.6902\n",
            "Epoch 16/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5777 - accuracy: 0.6957 - precision_15: 0.6726 - recall_15: 0.7106 - val_loss: 0.5993 - val_accuracy: 0.6745 - val_precision_15: 0.6465 - val_recall_15: 0.6734\n",
            "Epoch 17/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5772 - accuracy: 0.6970 - precision_15: 0.6760 - recall_15: 0.7054 - val_loss: 0.6006 - val_accuracy: 0.6775 - val_precision_15: 0.6492 - val_recall_15: 0.6779\n",
            "Epoch 18/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5770 - accuracy: 0.6966 - precision_15: 0.6755 - recall_15: 0.7053 - val_loss: 0.6021 - val_accuracy: 0.6744 - val_precision_15: 0.6301 - val_recall_15: 0.7384\n",
            "Epoch 19/100\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.5766 - accuracy: 0.6990 - precision_15: 0.6766 - recall_15: 0.7119 - val_loss: 0.5994 - val_accuracy: 0.6768 - val_precision_15: 0.6487 - val_recall_15: 0.6763\n",
            "Epoch 20/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5777 - accuracy: 0.6991 - precision_15: 0.6757 - recall_15: 0.7150 - val_loss: 0.6007 - val_accuracy: 0.6754 - val_precision_15: 0.6411 - val_recall_15: 0.6979\n",
            "Epoch 21/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.5788 - accuracy: 0.6984 - precision_15: 0.6769 - recall_15: 0.7085 - val_loss: 0.5985 - val_accuracy: 0.6753 - val_precision_15: 0.6617 - val_recall_15: 0.6279\n",
            "Accuracy  :  0.6740826964378357\n",
            "Precision :  0.6466975808143616\n",
            "Recall    :  0.6866387724876404\n",
            "F1- Score :  0.6660699409588852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adadelta\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptw8NCdTuk5o",
        "outputId": "a261b6c6-5db8-485f-990c-5b26829d313d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 13s 13ms/step - loss: 0.5779 - accuracy: 0.6973 - precision_16: 0.6748 - recall_16: 0.7102 - val_loss: 0.5977 - val_accuracy: 0.6752 - val_precision_16: 0.6417 - val_recall_16: 0.6942\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.5772 - accuracy: 0.6983 - precision_16: 0.6751 - recall_16: 0.7137 - val_loss: 0.5977 - val_accuracy: 0.6757 - val_precision_16: 0.6421 - val_recall_16: 0.6950\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5783 - accuracy: 0.6969 - precision_16: 0.6741 - recall_16: 0.7108 - val_loss: 0.5977 - val_accuracy: 0.6755 - val_precision_16: 0.6423 - val_recall_16: 0.6939\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 6s 11ms/step - loss: 0.5784 - accuracy: 0.6959 - precision_16: 0.6730 - recall_16: 0.7102 - val_loss: 0.5977 - val_accuracy: 0.6764 - val_precision_16: 0.6430 - val_recall_16: 0.6953\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5787 - accuracy: 0.6964 - precision_16: 0.6736 - recall_16: 0.7103 - val_loss: 0.5977 - val_accuracy: 0.6765 - val_precision_16: 0.6430 - val_recall_16: 0.6961\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.5781 - accuracy: 0.6978 - precision_16: 0.6757 - recall_16: 0.7096 - val_loss: 0.5977 - val_accuracy: 0.6765 - val_precision_16: 0.6430 - val_recall_16: 0.6961\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 6s 11ms/step - loss: 0.5759 - accuracy: 0.6990 - precision_16: 0.6764 - recall_16: 0.7123 - val_loss: 0.5978 - val_accuracy: 0.6767 - val_precision_16: 0.6430 - val_recall_16: 0.6966\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5774 - accuracy: 0.6991 - precision_16: 0.6755 - recall_16: 0.7156 - val_loss: 0.5978 - val_accuracy: 0.6767 - val_precision_16: 0.6431 - val_recall_16: 0.6963\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5768 - accuracy: 0.6971 - precision_16: 0.6741 - recall_16: 0.7115 - val_loss: 0.5978 - val_accuracy: 0.6765 - val_precision_16: 0.6430 - val_recall_16: 0.6961\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.5787 - accuracy: 0.6954 - precision_16: 0.6734 - recall_16: 0.7068 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_16: 0.6431 - val_recall_16: 0.6966\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.5780 - accuracy: 0.6962 - precision_16: 0.6737 - recall_16: 0.7094 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_16: 0.6431 - val_recall_16: 0.6966\n",
            "Accuracy  :  0.6744321584701538\n",
            "Precision :  0.6468409895896912\n",
            "Recall    :  0.6877460479736328\n",
            "F1- Score :  0.6666666492878414\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 11s 16ms/step - loss: 0.5788 - accuracy: 0.6956 - precision_17: 0.6728 - recall_17: 0.7095 - val_loss: 0.5977 - val_accuracy: 0.6758 - val_precision_17: 0.6422 - val_recall_17: 0.6953\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5777 - accuracy: 0.6992 - precision_17: 0.6766 - recall_17: 0.7126 - val_loss: 0.5977 - val_accuracy: 0.6763 - val_precision_17: 0.6425 - val_recall_17: 0.6966\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5780 - accuracy: 0.6962 - precision_17: 0.6730 - recall_17: 0.7116 - val_loss: 0.5977 - val_accuracy: 0.6762 - val_precision_17: 0.6424 - val_recall_17: 0.6963\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.5769 - accuracy: 0.6986 - precision_17: 0.6761 - recall_17: 0.7116 - val_loss: 0.5977 - val_accuracy: 0.6765 - val_precision_17: 0.6428 - val_recall_17: 0.6966\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5778 - accuracy: 0.6969 - precision_17: 0.6741 - recall_17: 0.7107 - val_loss: 0.5977 - val_accuracy: 0.6768 - val_precision_17: 0.6432 - val_recall_17: 0.6963\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5783 - accuracy: 0.6983 - precision_17: 0.6754 - recall_17: 0.7126 - val_loss: 0.5977 - val_accuracy: 0.6767 - val_precision_17: 0.6431 - val_recall_17: 0.6963\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5757 - accuracy: 0.6976 - precision_17: 0.6744 - recall_17: 0.7126 - val_loss: 0.5977 - val_accuracy: 0.6769 - val_precision_17: 0.6433 - val_recall_17: 0.6966\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.5771 - accuracy: 0.6962 - precision_17: 0.6740 - recall_17: 0.7083 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_17: 0.6432 - val_recall_17: 0.6963\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5770 - accuracy: 0.6973 - precision_17: 0.6733 - recall_17: 0.7151 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_17: 0.6431 - val_recall_17: 0.6966\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5779 - accuracy: 0.6992 - precision_17: 0.6768 - recall_17: 0.7122 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_17: 0.6431 - val_recall_17: 0.6966\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5772 - accuracy: 0.6982 - precision_17: 0.6753 - recall_17: 0.7126 - val_loss: 0.5978 - val_accuracy: 0.6769 - val_precision_17: 0.6432 - val_recall_17: 0.6971\n",
            "Accuracy  :  0.6747233271598816\n",
            "Precision :  0.6470112204551697\n",
            "Recall    :  0.688484251499176\n",
            "F1- Score :  0.6671037756118636\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 10s 36ms/step - loss: 0.5777 - accuracy: 0.6972 - precision_18: 0.6753 - recall_18: 0.7083 - val_loss: 0.5977 - val_accuracy: 0.6760 - val_precision_18: 0.6424 - val_recall_18: 0.6958\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5765 - accuracy: 0.7000 - precision_18: 0.6769 - recall_18: 0.7147 - val_loss: 0.5977 - val_accuracy: 0.6760 - val_precision_18: 0.6424 - val_recall_18: 0.6958\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5766 - accuracy: 0.6990 - precision_18: 0.6762 - recall_18: 0.7129 - val_loss: 0.5977 - val_accuracy: 0.6759 - val_precision_18: 0.6423 - val_recall_18: 0.6955\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.5775 - accuracy: 0.6979 - precision_18: 0.6750 - recall_18: 0.7121 - val_loss: 0.5977 - val_accuracy: 0.6762 - val_precision_18: 0.6426 - val_recall_18: 0.6958\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.5799 - accuracy: 0.6970 - precision_18: 0.6745 - recall_18: 0.7100 - val_loss: 0.5977 - val_accuracy: 0.6767 - val_precision_18: 0.6431 - val_recall_18: 0.6961\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.5780 - accuracy: 0.6997 - precision_18: 0.6762 - recall_18: 0.7158 - val_loss: 0.5977 - val_accuracy: 0.6765 - val_precision_18: 0.6430 - val_recall_18: 0.6958\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.5773 - accuracy: 0.6968 - precision_18: 0.6747 - recall_18: 0.7085 - val_loss: 0.5977 - val_accuracy: 0.6765 - val_precision_18: 0.6430 - val_recall_18: 0.6958\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 2s 19ms/step - loss: 0.5770 - accuracy: 0.6975 - precision_18: 0.6755 - recall_18: 0.7091 - val_loss: 0.5977 - val_accuracy: 0.6767 - val_precision_18: 0.6431 - val_recall_18: 0.6961\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5780 - accuracy: 0.6962 - precision_18: 0.6742 - recall_18: 0.7078 - val_loss: 0.5977 - val_accuracy: 0.6769 - val_precision_18: 0.6433 - val_recall_18: 0.6966\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5781 - accuracy: 0.6981 - precision_18: 0.6762 - recall_18: 0.7092 - val_loss: 0.5978 - val_accuracy: 0.6767 - val_precision_18: 0.6431 - val_recall_18: 0.6963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5769 - accuracy: 0.6997 - precision_18: 0.6765 - recall_18: 0.7149 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_18: 0.6431 - val_recall_18: 0.6969\n",
            "Accuracy  :  0.674898087978363\n",
            "Precision :  0.6471676230430603\n",
            "Recall    :  0.6887302994728088\n",
            "F1- Score :  0.6673024088369417\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 9s 47ms/step - loss: 0.5765 - accuracy: 0.6989 - precision_19: 0.6770 - recall_19: 0.7102 - val_loss: 0.5977 - val_accuracy: 0.6763 - val_precision_19: 0.6426 - val_recall_19: 0.6963\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 0.5774 - accuracy: 0.6965 - precision_19: 0.6738 - recall_19: 0.7102 - val_loss: 0.5977 - val_accuracy: 0.6763 - val_precision_19: 0.6426 - val_recall_19: 0.6963\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.5769 - accuracy: 0.6964 - precision_19: 0.6734 - recall_19: 0.7109 - val_loss: 0.5977 - val_accuracy: 0.6763 - val_precision_19: 0.6426 - val_recall_19: 0.6963\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5776 - accuracy: 0.6970 - precision_19: 0.6740 - recall_19: 0.7115 - val_loss: 0.5977 - val_accuracy: 0.6763 - val_precision_19: 0.6425 - val_recall_19: 0.6966\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5790 - accuracy: 0.6980 - precision_19: 0.6753 - recall_19: 0.7117 - val_loss: 0.5977 - val_accuracy: 0.6764 - val_precision_19: 0.6427 - val_recall_19: 0.6966\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5760 - accuracy: 0.6979 - precision_19: 0.6750 - recall_19: 0.7122 - val_loss: 0.5977 - val_accuracy: 0.6765 - val_precision_19: 0.6428 - val_recall_19: 0.6966\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5780 - accuracy: 0.6984 - precision_19: 0.6758 - recall_19: 0.7120 - val_loss: 0.5977 - val_accuracy: 0.6768 - val_precision_19: 0.6432 - val_recall_19: 0.6963\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5770 - accuracy: 0.6983 - precision_19: 0.6765 - recall_19: 0.7091 - val_loss: 0.5977 - val_accuracy: 0.6765 - val_precision_19: 0.6429 - val_recall_19: 0.6963\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5764 - accuracy: 0.6992 - precision_19: 0.6760 - recall_19: 0.7145 - val_loss: 0.5977 - val_accuracy: 0.6764 - val_precision_19: 0.6427 - val_recall_19: 0.6963\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 0.5781 - accuracy: 0.6971 - precision_19: 0.6746 - recall_19: 0.7100 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_19: 0.6431 - val_recall_19: 0.6969\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.5754 - accuracy: 0.6996 - precision_19: 0.6775 - recall_19: 0.7114 - val_loss: 0.5978 - val_accuracy: 0.6768 - val_precision_19: 0.6431 - val_recall_19: 0.6969\n",
            "Accuracy  :  0.6750727891921997\n",
            "Precision :  0.6473580598831177\n",
            "Recall    :  0.6888533234596252\n",
            "F1- Score :  0.6674613860918993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"rmsprop\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGeHl8TVzvRa",
        "outputId": "44709d19-bccb-4fbf-f9da-6640ece6bf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 12s 14ms/step - loss: 0.5848 - accuracy: 0.6905 - precision_20: 0.6662 - recall_20: 0.7091 - val_loss: 0.6014 - val_accuracy: 0.6747 - val_precision_20: 0.6510 - val_recall_20: 0.6585\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5827 - accuracy: 0.6933 - precision_20: 0.6712 - recall_20: 0.7051 - val_loss: 0.6034 - val_accuracy: 0.6655 - val_precision_20: 0.6172 - val_recall_20: 0.7533\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5863 - accuracy: 0.6918 - precision_20: 0.6678 - recall_20: 0.7096 - val_loss: 0.6014 - val_accuracy: 0.6750 - val_precision_20: 0.6461 - val_recall_20: 0.6774\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.5859 - accuracy: 0.6942 - precision_20: 0.6715 - recall_20: 0.7078 - val_loss: 0.6014 - val_accuracy: 0.6738 - val_precision_20: 0.6349 - val_recall_20: 0.7147\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5857 - accuracy: 0.6910 - precision_20: 0.6706 - recall_20: 0.6976 - val_loss: 0.6020 - val_accuracy: 0.6699 - val_precision_20: 0.6181 - val_recall_20: 0.7730\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5838 - accuracy: 0.6934 - precision_20: 0.6718 - recall_20: 0.7036 - val_loss: 0.5983 - val_accuracy: 0.6734 - val_precision_20: 0.6438 - val_recall_20: 0.6779\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.5835 - accuracy: 0.6925 - precision_20: 0.6725 - recall_20: 0.6978 - val_loss: 0.6010 - val_accuracy: 0.6739 - val_precision_20: 0.6456 - val_recall_20: 0.6739\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.5856 - accuracy: 0.6932 - precision_20: 0.6705 - recall_20: 0.7065 - val_loss: 0.5994 - val_accuracy: 0.6752 - val_precision_20: 0.6482 - val_recall_20: 0.6705\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5858 - accuracy: 0.6948 - precision_20: 0.6731 - recall_20: 0.7055 - val_loss: 0.6024 - val_accuracy: 0.6692 - val_precision_20: 0.6338 - val_recall_20: 0.6958\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5840 - accuracy: 0.6952 - precision_20: 0.6745 - recall_20: 0.7028 - val_loss: 0.6041 - val_accuracy: 0.6735 - val_precision_20: 0.6359 - val_recall_20: 0.7094\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.5839 - accuracy: 0.6921 - precision_20: 0.6666 - recall_20: 0.7145 - val_loss: 0.5992 - val_accuracy: 0.6738 - val_precision_20: 0.6407 - val_recall_20: 0.6913\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5840 - accuracy: 0.6938 - precision_20: 0.6708 - recall_20: 0.7082 - val_loss: 0.6041 - val_accuracy: 0.6739 - val_precision_20: 0.6528 - val_recall_20: 0.6492\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5857 - accuracy: 0.6929 - precision_20: 0.6719 - recall_20: 0.7010 - val_loss: 0.6000 - val_accuracy: 0.6723 - val_precision_20: 0.6345 - val_recall_20: 0.7086\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.5837 - accuracy: 0.6926 - precision_20: 0.6695 - recall_20: 0.7076 - val_loss: 0.6036 - val_accuracy: 0.6744 - val_precision_20: 0.6305 - val_recall_20: 0.7368\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5830 - accuracy: 0.6956 - precision_20: 0.6714 - recall_20: 0.7137 - val_loss: 0.6019 - val_accuracy: 0.6770 - val_precision_20: 0.6564 - val_recall_20: 0.6518\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5839 - accuracy: 0.6952 - precision_20: 0.6727 - recall_20: 0.7081 - val_loss: 0.6004 - val_accuracy: 0.6744 - val_precision_20: 0.6458 - val_recall_20: 0.6755\n",
            "Accuracy  :  0.6693069338798523\n",
            "Precision :  0.6474127769470215\n",
            "Recall    :  0.6619094610214233\n",
            "F1- Score :  0.6545808660705168\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 10s 16ms/step - loss: 0.5832 - accuracy: 0.6945 - precision_21: 0.6735 - recall_21: 0.7030 - val_loss: 0.6033 - val_accuracy: 0.6710 - val_precision_21: 0.6221 - val_recall_21: 0.7589\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5794 - accuracy: 0.6962 - precision_21: 0.6735 - recall_21: 0.7100 - val_loss: 0.5995 - val_accuracy: 0.6771 - val_precision_21: 0.6536 - val_recall_21: 0.6614\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5821 - accuracy: 0.6947 - precision_21: 0.6747 - recall_21: 0.7005 - val_loss: 0.6041 - val_accuracy: 0.6713 - val_precision_21: 0.6325 - val_recall_21: 0.7120\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5817 - accuracy: 0.6943 - precision_21: 0.6723 - recall_21: 0.7057 - val_loss: 0.6000 - val_accuracy: 0.6765 - val_precision_21: 0.6393 - val_recall_21: 0.7104\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5802 - accuracy: 0.6977 - precision_21: 0.6774 - recall_21: 0.7044 - val_loss: 0.5997 - val_accuracy: 0.6752 - val_precision_21: 0.6515 - val_recall_21: 0.6593\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5809 - accuracy: 0.6948 - precision_21: 0.6720 - recall_21: 0.7087 - val_loss: 0.6013 - val_accuracy: 0.6774 - val_precision_21: 0.6442 - val_recall_21: 0.6955\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 3s 14ms/step - loss: 0.5809 - accuracy: 0.6930 - precision_21: 0.6709 - recall_21: 0.7046 - val_loss: 0.6025 - val_accuracy: 0.6767 - val_precision_21: 0.6384 - val_recall_21: 0.7144\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5799 - accuracy: 0.6952 - precision_21: 0.6755 - recall_21: 0.6999 - val_loss: 0.6000 - val_accuracy: 0.6779 - val_precision_21: 0.6511 - val_recall_21: 0.6731\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5824 - accuracy: 0.6946 - precision_21: 0.6742 - recall_21: 0.7012 - val_loss: 0.6008 - val_accuracy: 0.6759 - val_precision_21: 0.6577 - val_recall_21: 0.6428\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5804 - accuracy: 0.6952 - precision_21: 0.6718 - recall_21: 0.7107 - val_loss: 0.5994 - val_accuracy: 0.6776 - val_precision_21: 0.6331 - val_recall_21: 0.7419\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5792 - accuracy: 0.6972 - precision_21: 0.6731 - recall_21: 0.7152 - val_loss: 0.6026 - val_accuracy: 0.6693 - val_precision_21: 0.6188 - val_recall_21: 0.7661\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5799 - accuracy: 0.6994 - precision_21: 0.6756 - recall_21: 0.7165 - val_loss: 0.5991 - val_accuracy: 0.6744 - val_precision_21: 0.6472 - val_recall_21: 0.6705\n",
            "Epoch 13/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5809 - accuracy: 0.6958 - precision_21: 0.6746 - recall_21: 0.7048 - val_loss: 0.5988 - val_accuracy: 0.6764 - val_precision_21: 0.6429 - val_recall_21: 0.6958\n",
            "Epoch 14/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5798 - accuracy: 0.6973 - precision_21: 0.6750 - recall_21: 0.7097 - val_loss: 0.6040 - val_accuracy: 0.6692 - val_precision_21: 0.6219 - val_recall_21: 0.7493\n",
            "Epoch 15/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5789 - accuracy: 0.6973 - precision_21: 0.6730 - recall_21: 0.7158 - val_loss: 0.5998 - val_accuracy: 0.6740 - val_precision_21: 0.6524 - val_recall_21: 0.6510\n",
            "Epoch 16/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5785 - accuracy: 0.6976 - precision_21: 0.6747 - recall_21: 0.7118 - val_loss: 0.5995 - val_accuracy: 0.6730 - val_precision_21: 0.6259 - val_recall_21: 0.7509\n",
            "Epoch 17/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5801 - accuracy: 0.6966 - precision_21: 0.6731 - recall_21: 0.7126 - val_loss: 0.5997 - val_accuracy: 0.6778 - val_precision_21: 0.6530 - val_recall_21: 0.6662\n",
            "Epoch 18/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5801 - accuracy: 0.6940 - precision_21: 0.6792 - recall_21: 0.6842 - val_loss: 0.5973 - val_accuracy: 0.6770 - val_precision_21: 0.6610 - val_recall_21: 0.6377\n",
            "Epoch 19/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.5772 - accuracy: 0.6975 - precision_21: 0.6759 - recall_21: 0.7078 - val_loss: 0.6010 - val_accuracy: 0.6800 - val_precision_21: 0.6524 - val_recall_21: 0.6785\n",
            "Epoch 20/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5793 - accuracy: 0.6981 - precision_21: 0.6785 - recall_21: 0.7029 - val_loss: 0.5981 - val_accuracy: 0.6768 - val_precision_21: 0.6348 - val_recall_21: 0.7302\n",
            "Epoch 21/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.5779 - accuracy: 0.7003 - precision_21: 0.6773 - recall_21: 0.7148 - val_loss: 0.6019 - val_accuracy: 0.6742 - val_precision_21: 0.6596 - val_recall_21: 0.6292\n",
            "Epoch 22/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.5780 - accuracy: 0.6976 - precision_21: 0.6744 - recall_21: 0.7126 - val_loss: 0.6069 - val_accuracy: 0.6744 - val_precision_21: 0.6392 - val_recall_21: 0.7003\n",
            "Epoch 23/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5785 - accuracy: 0.6968 - precision_21: 0.6748 - recall_21: 0.7083 - val_loss: 0.5984 - val_accuracy: 0.6757 - val_precision_21: 0.6488 - val_recall_21: 0.6708\n",
            "Epoch 24/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5760 - accuracy: 0.6986 - precision_21: 0.6779 - recall_21: 0.7063 - val_loss: 0.5983 - val_accuracy: 0.6769 - val_precision_21: 0.6525 - val_recall_21: 0.6638\n",
            "Epoch 25/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5792 - accuracy: 0.6989 - precision_21: 0.6778 - recall_21: 0.7080 - val_loss: 0.6020 - val_accuracy: 0.6739 - val_precision_21: 0.6322 - val_recall_21: 0.7267\n",
            "Epoch 26/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.5780 - accuracy: 0.6984 - precision_21: 0.6758 - recall_21: 0.7120 - val_loss: 0.5985 - val_accuracy: 0.6768 - val_precision_21: 0.6463 - val_recall_21: 0.6849\n",
            "Epoch 27/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.5777 - accuracy: 0.6977 - precision_21: 0.6733 - recall_21: 0.7165 - val_loss: 0.5989 - val_accuracy: 0.6778 - val_precision_21: 0.6378 - val_recall_21: 0.7224\n",
            "Epoch 28/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5764 - accuracy: 0.6974 - precision_21: 0.6721 - recall_21: 0.7192 - val_loss: 0.5984 - val_accuracy: 0.6789 - val_precision_21: 0.6415 - val_recall_21: 0.7131\n",
            "Accuracy  :  0.6697728633880615\n",
            "Precision :  0.6607797145843506\n",
            "Recall    :  0.6214320659637451\n",
            "F1- Score :  0.6405021532489096\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 11s 39ms/step - loss: 0.5778 - accuracy: 0.6971 - precision_22: 0.6791 - recall_22: 0.6967 - val_loss: 0.5992 - val_accuracy: 0.6749 - val_precision_22: 0.6458 - val_recall_22: 0.6777\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.5763 - accuracy: 0.7000 - precision_22: 0.6786 - recall_22: 0.7098 - val_loss: 0.6017 - val_accuracy: 0.6753 - val_precision_22: 0.6549 - val_recall_22: 0.6486\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5773 - accuracy: 0.6983 - precision_22: 0.6757 - recall_22: 0.7115 - val_loss: 0.5979 - val_accuracy: 0.6755 - val_precision_22: 0.6466 - val_recall_22: 0.6779\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.5748 - accuracy: 0.7011 - precision_22: 0.6777 - recall_22: 0.7167 - val_loss: 0.5988 - val_accuracy: 0.6752 - val_precision_22: 0.6631 - val_recall_22: 0.6233\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 2s 19ms/step - loss: 0.5739 - accuracy: 0.7016 - precision_22: 0.6783 - recall_22: 0.7170 - val_loss: 0.6028 - val_accuracy: 0.6744 - val_precision_22: 0.6780 - val_recall_22: 0.5810\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.5743 - accuracy: 0.7001 - precision_22: 0.6778 - recall_22: 0.7125 - val_loss: 0.6125 - val_accuracy: 0.6660 - val_precision_22: 0.6115 - val_recall_22: 0.7874\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5753 - accuracy: 0.6990 - precision_22: 0.6746 - recall_22: 0.7177 - val_loss: 0.6029 - val_accuracy: 0.6692 - val_precision_22: 0.6206 - val_recall_22: 0.7560\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.5759 - accuracy: 0.7012 - precision_22: 0.6765 - recall_22: 0.7207 - val_loss: 0.5989 - val_accuracy: 0.6744 - val_precision_22: 0.6491 - val_recall_22: 0.6638\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.5762 - accuracy: 0.6990 - precision_22: 0.6767 - recall_22: 0.7115 - val_loss: 0.6006 - val_accuracy: 0.6788 - val_precision_22: 0.6604 - val_recall_22: 0.6470\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5735 - accuracy: 0.7020 - precision_22: 0.6793 - recall_22: 0.7156 - val_loss: 0.5979 - val_accuracy: 0.6759 - val_precision_22: 0.6366 - val_recall_22: 0.7182\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.5744 - accuracy: 0.7008 - precision_22: 0.6767 - recall_22: 0.7186 - val_loss: 0.6006 - val_accuracy: 0.6775 - val_precision_22: 0.6319 - val_recall_22: 0.7467\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 2s 19ms/step - loss: 0.5745 - accuracy: 0.7014 - precision_22: 0.6764 - recall_22: 0.7220 - val_loss: 0.6089 - val_accuracy: 0.6700 - val_precision_22: 0.6198 - val_recall_22: 0.7648\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.5751 - accuracy: 0.6991 - precision_22: 0.6740 - recall_22: 0.7198 - val_loss: 0.5989 - val_accuracy: 0.6770 - val_precision_22: 0.6466 - val_recall_22: 0.6851\n",
            "Accuracy  :  0.6725684404373169\n",
            "Precision :  0.6513650417327881\n",
            "Recall    :  0.663385808467865\n",
            "F1- Score :  0.6573204721665151\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 9s 50ms/step - loss: 0.5758 - accuracy: 0.6989 - precision_23: 0.6748 - recall_23: 0.7167 - val_loss: 0.5984 - val_accuracy: 0.6768 - val_precision_23: 0.6532 - val_recall_23: 0.6609\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.5752 - accuracy: 0.7011 - precision_23: 0.6800 - recall_23: 0.7102 - val_loss: 0.5981 - val_accuracy: 0.6788 - val_precision_23: 0.6443 - val_recall_23: 0.7019\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.5741 - accuracy: 0.7012 - precision_23: 0.6779 - recall_23: 0.7165 - val_loss: 0.5990 - val_accuracy: 0.6765 - val_precision_23: 0.6335 - val_recall_23: 0.7344\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5739 - accuracy: 0.7004 - precision_23: 0.6766 - recall_23: 0.7173 - val_loss: 0.5987 - val_accuracy: 0.6759 - val_precision_23: 0.6422 - val_recall_23: 0.6958\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5735 - accuracy: 0.7023 - precision_23: 0.6776 - recall_23: 0.7220 - val_loss: 0.5990 - val_accuracy: 0.6759 - val_precision_23: 0.6366 - val_recall_23: 0.7182\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.5745 - accuracy: 0.6986 - precision_23: 0.6748 - recall_23: 0.7158 - val_loss: 0.6001 - val_accuracy: 0.6750 - val_precision_23: 0.6440 - val_recall_23: 0.6851\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.5737 - accuracy: 0.7040 - precision_23: 0.6810 - recall_23: 0.7188 - val_loss: 0.5993 - val_accuracy: 0.6789 - val_precision_23: 0.6410 - val_recall_23: 0.7152\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.5738 - accuracy: 0.6998 - precision_23: 0.6790 - recall_23: 0.7079 - val_loss: 0.5997 - val_accuracy: 0.6793 - val_precision_23: 0.6504 - val_recall_23: 0.6819\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.5730 - accuracy: 0.7036 - precision_23: 0.6835 - recall_23: 0.7098 - val_loss: 0.5989 - val_accuracy: 0.6765 - val_precision_23: 0.6405 - val_recall_23: 0.7056\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 29ms/step - loss: 0.5747 - accuracy: 0.7009 - precision_23: 0.6785 - recall_23: 0.7137 - val_loss: 0.6010 - val_accuracy: 0.6767 - val_precision_23: 0.6498 - val_recall_23: 0.6721\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.5728 - accuracy: 0.7023 - precision_23: 0.6802 - recall_23: 0.7141 - val_loss: 0.6002 - val_accuracy: 0.6753 - val_precision_23: 0.6475 - val_recall_23: 0.6737\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.5746 - accuracy: 0.7009 - precision_23: 0.6781 - recall_23: 0.7148 - val_loss: 0.5996 - val_accuracy: 0.6796 - val_precision_23: 0.6387 - val_recall_23: 0.7280\n",
            "Accuracy  :  0.6758299469947815\n",
            "Precision :  0.649335503578186\n",
            "Recall    :  0.6852854490280151\n",
            "F1- Score :  0.6668262944178537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BiLSTM**"
      ],
      "metadata": {
        "id": "Mrrs4tJRnbOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create BiLSTM model\n",
        "def create_model_BiLSTM(data):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True), input_shape=(1, x_train.shape[2])),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(16, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "I0i9Mi3rzyBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model_BiLSTM(x_train) # calling model for training"
      ],
      "metadata": {
        "id": "SOnBz1uensZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model and evaluating scores with different batch size and optimizers and iterations"
      ],
      "metadata": {
        "id": "SFnapkpCqNzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adam\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0LVdQW9ntR-",
        "outputId": "8f2b650c-7068-4032-f8f8-9f4aa17c8f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 22s 19ms/step - loss: 0.6593 - accuracy: 0.6086 - precision_24: 0.5982 - recall_24: 0.5570 - val_loss: 0.6433 - val_accuracy: 0.6292 - val_precision_24: 0.6062 - val_recall_24: 0.5951\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.6432 - accuracy: 0.6356 - precision_24: 0.6139 - recall_24: 0.6447 - val_loss: 0.6425 - val_accuracy: 0.6362 - val_precision_24: 0.5810 - val_recall_24: 0.8013\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6332 - accuracy: 0.6461 - precision_24: 0.6189 - recall_24: 0.6796 - val_loss: 0.6257 - val_accuracy: 0.6534 - val_precision_24: 0.6294 - val_recall_24: 0.6329\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6273 - accuracy: 0.6521 - precision_24: 0.6197 - recall_24: 0.7083 - val_loss: 0.6203 - val_accuracy: 0.6561 - val_precision_24: 0.6083 - val_recall_24: 0.7464\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6270 - accuracy: 0.6523 - precision_24: 0.6224 - recall_24: 0.6965 - val_loss: 0.6301 - val_accuracy: 0.6402 - val_precision_24: 0.5805 - val_recall_24: 0.8362\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6227 - accuracy: 0.6550 - precision_24: 0.6255 - recall_24: 0.6973 - val_loss: 0.6274 - val_accuracy: 0.6455 - val_precision_24: 0.5885 - val_recall_24: 0.8090\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6211 - accuracy: 0.6571 - precision_24: 0.6276 - recall_24: 0.6986 - val_loss: 0.6174 - val_accuracy: 0.6548 - val_precision_24: 0.6093 - val_recall_24: 0.7336\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6197 - accuracy: 0.6585 - precision_24: 0.6285 - recall_24: 0.7018 - val_loss: 0.6164 - val_accuracy: 0.6573 - val_precision_24: 0.6447 - val_recall_24: 0.5980\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6187 - accuracy: 0.6595 - precision_24: 0.6329 - recall_24: 0.6886 - val_loss: 0.6147 - val_accuracy: 0.6569 - val_precision_24: 0.6104 - val_recall_24: 0.7400\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6183 - accuracy: 0.6598 - precision_24: 0.6315 - recall_24: 0.6955 - val_loss: 0.6158 - val_accuracy: 0.6578 - val_precision_24: 0.6082 - val_recall_24: 0.7576\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.6185 - accuracy: 0.6591 - precision_24: 0.6289 - recall_24: 0.7036 - val_loss: 0.6160 - val_accuracy: 0.6558 - val_precision_24: 0.6064 - val_recall_24: 0.7563\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6166 - accuracy: 0.6641 - precision_24: 0.6359 - recall_24: 0.6987 - val_loss: 0.6120 - val_accuracy: 0.6627 - val_precision_24: 0.6210 - val_recall_24: 0.7184\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6162 - accuracy: 0.6606 - precision_24: 0.6347 - recall_24: 0.6864 - val_loss: 0.6124 - val_accuracy: 0.6571 - val_precision_24: 0.6427 - val_recall_24: 0.6034\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.6143 - accuracy: 0.6647 - precision_24: 0.6384 - recall_24: 0.6917 - val_loss: 0.6115 - val_accuracy: 0.6594 - val_precision_24: 0.6159 - val_recall_24: 0.7256\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6131 - accuracy: 0.6653 - precision_24: 0.6433 - recall_24: 0.6762 - val_loss: 0.6109 - val_accuracy: 0.6644 - val_precision_24: 0.6184 - val_recall_24: 0.7411\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.6129 - accuracy: 0.6649 - precision_24: 0.6394 - recall_24: 0.6888 - val_loss: 0.6119 - val_accuracy: 0.6596 - val_precision_24: 0.6081 - val_recall_24: 0.7688\n",
            "Epoch 17/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.6107 - accuracy: 0.6653 - precision_24: 0.6411 - recall_24: 0.6844 - val_loss: 0.6113 - val_accuracy: 0.6652 - val_precision_24: 0.6175 - val_recall_24: 0.7499\n",
            "Epoch 18/100\n",
            "501/501 [==============================] - 8s 17ms/step - loss: 0.6116 - accuracy: 0.6637 - precision_24: 0.6424 - recall_24: 0.6719 - val_loss: 0.6113 - val_accuracy: 0.6603 - val_precision_24: 0.6080 - val_recall_24: 0.7738\n",
            "Epoch 19/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6101 - accuracy: 0.6651 - precision_24: 0.6382 - recall_24: 0.6945 - val_loss: 0.6095 - val_accuracy: 0.6601 - val_precision_24: 0.6080 - val_recall_24: 0.7722\n",
            "Epoch 20/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6093 - accuracy: 0.6668 - precision_24: 0.6437 - recall_24: 0.6816 - val_loss: 0.6093 - val_accuracy: 0.6633 - val_precision_24: 0.6219 - val_recall_24: 0.7176\n",
            "Epoch 21/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.6111 - accuracy: 0.6670 - precision_24: 0.6431 - recall_24: 0.6847 - val_loss: 0.6063 - val_accuracy: 0.6659 - val_precision_24: 0.6242 - val_recall_24: 0.7208\n",
            "Epoch 22/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6101 - accuracy: 0.6675 - precision_24: 0.6439 - recall_24: 0.6842 - val_loss: 0.6063 - val_accuracy: 0.6649 - val_precision_24: 0.6327 - val_recall_24: 0.6790\n",
            "Epoch 23/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6091 - accuracy: 0.6658 - precision_24: 0.6397 - recall_24: 0.6916 - val_loss: 0.6053 - val_accuracy: 0.6643 - val_precision_24: 0.6475 - val_recall_24: 0.6220\n",
            "Epoch 24/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6076 - accuracy: 0.6664 - precision_24: 0.6425 - recall_24: 0.6843 - val_loss: 0.6073 - val_accuracy: 0.6604 - val_precision_24: 0.6517 - val_recall_24: 0.5911\n",
            "Epoch 25/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.6071 - accuracy: 0.6688 - precision_24: 0.6445 - recall_24: 0.6878 - val_loss: 0.6061 - val_accuracy: 0.6640 - val_precision_24: 0.6522 - val_recall_24: 0.6060\n",
            "Epoch 26/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.6062 - accuracy: 0.6686 - precision_24: 0.6449 - recall_24: 0.6855 - val_loss: 0.6090 - val_accuracy: 0.6581 - val_precision_24: 0.6201 - val_recall_24: 0.6974\n",
            "Epoch 27/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.6062 - accuracy: 0.6682 - precision_24: 0.6454 - recall_24: 0.6820 - val_loss: 0.6052 - val_accuracy: 0.6708 - val_precision_24: 0.6411 - val_recall_24: 0.6753\n",
            "Epoch 28/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6061 - accuracy: 0.6694 - precision_24: 0.6468 - recall_24: 0.6826 - val_loss: 0.6083 - val_accuracy: 0.6603 - val_precision_24: 0.6083 - val_recall_24: 0.7720\n",
            "Epoch 29/100\n",
            "501/501 [==============================] - 8s 17ms/step - loss: 0.6047 - accuracy: 0.6703 - precision_24: 0.6460 - recall_24: 0.6895 - val_loss: 0.6031 - val_accuracy: 0.6658 - val_precision_24: 0.6466 - val_recall_24: 0.6321\n",
            "Epoch 30/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.6042 - accuracy: 0.6711 - precision_24: 0.6478 - recall_24: 0.6866 - val_loss: 0.6048 - val_accuracy: 0.6633 - val_precision_24: 0.6298 - val_recall_24: 0.6825\n",
            "Epoch 31/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6028 - accuracy: 0.6706 - precision_24: 0.6478 - recall_24: 0.6842 - val_loss: 0.6082 - val_accuracy: 0.6638 - val_precision_24: 0.6152 - val_recall_24: 0.7541\n",
            "Epoch 32/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.6038 - accuracy: 0.6682 - precision_24: 0.6451 - recall_24: 0.6831 - val_loss: 0.6039 - val_accuracy: 0.6677 - val_precision_24: 0.6410 - val_recall_24: 0.6606\n",
            "Epoch 33/100\n",
            "501/501 [==============================] - 8s 17ms/step - loss: 0.6011 - accuracy: 0.6728 - precision_24: 0.6510 - recall_24: 0.6832 - val_loss: 0.6076 - val_accuracy: 0.6652 - val_precision_24: 0.6244 - val_recall_24: 0.7158\n",
            "Epoch 34/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.6019 - accuracy: 0.6723 - precision_24: 0.6485 - recall_24: 0.6897 - val_loss: 0.6035 - val_accuracy: 0.6640 - val_precision_24: 0.6272 - val_recall_24: 0.6977\n",
            "Epoch 35/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6008 - accuracy: 0.6704 - precision_24: 0.6443 - recall_24: 0.6960 - val_loss: 0.6114 - val_accuracy: 0.6548 - val_precision_24: 0.5961 - val_recall_24: 0.8162\n",
            "Epoch 36/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.5995 - accuracy: 0.6752 - precision_24: 0.6525 - recall_24: 0.6885 - val_loss: 0.6064 - val_accuracy: 0.6662 - val_precision_24: 0.6163 - val_recall_24: 0.7616\n",
            "Epoch 37/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.6001 - accuracy: 0.6743 - precision_24: 0.6503 - recall_24: 0.6922 - val_loss: 0.6020 - val_accuracy: 0.6693 - val_precision_24: 0.6405 - val_recall_24: 0.6705\n",
            "Epoch 38/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.5981 - accuracy: 0.6750 - precision_24: 0.6497 - recall_24: 0.6975 - val_loss: 0.6045 - val_accuracy: 0.6670 - val_precision_24: 0.6251 - val_recall_24: 0.7230\n",
            "Epoch 39/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.5986 - accuracy: 0.6745 - precision_24: 0.6499 - recall_24: 0.6947 - val_loss: 0.6048 - val_accuracy: 0.6648 - val_precision_24: 0.6331 - val_recall_24: 0.6766\n",
            "Epoch 40/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5990 - accuracy: 0.6747 - precision_24: 0.6528 - recall_24: 0.6855 - val_loss: 0.6060 - val_accuracy: 0.6618 - val_precision_24: 0.6098 - val_recall_24: 0.7722\n",
            "Epoch 41/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.5972 - accuracy: 0.6769 - precision_24: 0.6555 - recall_24: 0.6857 - val_loss: 0.6048 - val_accuracy: 0.6654 - val_precision_24: 0.6190 - val_recall_24: 0.7435\n",
            "Epoch 42/100\n",
            "501/501 [==============================] - 8s 17ms/step - loss: 0.5975 - accuracy: 0.6742 - precision_24: 0.6509 - recall_24: 0.6899 - val_loss: 0.6055 - val_accuracy: 0.6682 - val_precision_24: 0.6208 - val_recall_24: 0.7493\n",
            "Epoch 43/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5975 - accuracy: 0.6750 - precision_24: 0.6513 - recall_24: 0.6917 - val_loss: 0.6028 - val_accuracy: 0.6638 - val_precision_24: 0.6393 - val_recall_24: 0.6478\n",
            "Epoch 44/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5965 - accuracy: 0.6756 - precision_24: 0.6508 - recall_24: 0.6964 - val_loss: 0.6065 - val_accuracy: 0.6668 - val_precision_24: 0.6234 - val_recall_24: 0.7294\n",
            "Epoch 45/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5952 - accuracy: 0.6764 - precision_24: 0.6509 - recall_24: 0.6996 - val_loss: 0.6145 - val_accuracy: 0.6574 - val_precision_24: 0.6029 - val_recall_24: 0.7874\n",
            "Epoch 46/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5948 - accuracy: 0.6764 - precision_24: 0.6503 - recall_24: 0.7018 - val_loss: 0.6089 - val_accuracy: 0.6597 - val_precision_24: 0.6098 - val_recall_24: 0.7595\n",
            "Epoch 47/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.5940 - accuracy: 0.6779 - precision_24: 0.6533 - recall_24: 0.6977 - val_loss: 0.6024 - val_accuracy: 0.6648 - val_precision_24: 0.6376 - val_recall_24: 0.6593\n",
            "Accuracy  :  0.6670937538146973\n",
            "Precision :  0.6448822617530823\n",
            "Recall    :  0.6604330539703369\n",
            "F1- Score :  0.6525650261674089\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 22s 29ms/step - loss: 0.5968 - accuracy: 0.6760 - precision_25: 0.6534 - recall_25: 0.6888 - val_loss: 0.6038 - val_accuracy: 0.6622 - val_precision_25: 0.6180 - val_recall_25: 0.7304\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 7s 26ms/step - loss: 0.5957 - accuracy: 0.6780 - precision_25: 0.6564 - recall_25: 0.6878 - val_loss: 0.6015 - val_accuracy: 0.6703 - val_precision_25: 0.6284 - val_recall_25: 0.7248\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.5953 - accuracy: 0.6766 - precision_25: 0.6559 - recall_25: 0.6833 - val_loss: 0.6019 - val_accuracy: 0.6692 - val_precision_25: 0.6307 - val_recall_25: 0.7088\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 5s 19ms/step - loss: 0.5963 - accuracy: 0.6768 - precision_25: 0.6530 - recall_25: 0.6940 - val_loss: 0.6011 - val_accuracy: 0.6710 - val_precision_25: 0.6337 - val_recall_25: 0.7056\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 7s 27ms/step - loss: 0.5945 - accuracy: 0.6774 - precision_25: 0.6544 - recall_25: 0.6917 - val_loss: 0.6011 - val_accuracy: 0.6680 - val_precision_25: 0.6380 - val_recall_25: 0.6737\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 5s 20ms/step - loss: 0.5940 - accuracy: 0.6788 - precision_25: 0.6569 - recall_25: 0.6896 - val_loss: 0.6000 - val_accuracy: 0.6695 - val_precision_25: 0.6288 - val_recall_25: 0.7190\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 6s 26ms/step - loss: 0.5937 - accuracy: 0.6775 - precision_25: 0.6567 - recall_25: 0.6847 - val_loss: 0.6007 - val_accuracy: 0.6629 - val_precision_25: 0.6262 - val_recall_25: 0.6958\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.5934 - accuracy: 0.6781 - precision_25: 0.6521 - recall_25: 0.7031 - val_loss: 0.6022 - val_accuracy: 0.6680 - val_precision_25: 0.6484 - val_recall_25: 0.6367\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.5921 - accuracy: 0.6795 - precision_25: 0.6568 - recall_25: 0.6931 - val_loss: 0.5985 - val_accuracy: 0.6672 - val_precision_25: 0.6351 - val_recall_25: 0.6806\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 7s 27ms/step - loss: 0.5943 - accuracy: 0.6797 - precision_25: 0.6570 - recall_25: 0.6932 - val_loss: 0.6013 - val_accuracy: 0.6698 - val_precision_25: 0.6353 - val_recall_25: 0.6931\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 5s 20ms/step - loss: 0.5912 - accuracy: 0.6801 - precision_25: 0.6565 - recall_25: 0.6967 - val_loss: 0.6024 - val_accuracy: 0.6637 - val_precision_25: 0.6543 - val_recall_25: 0.5980\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 7s 26ms/step - loss: 0.5916 - accuracy: 0.6796 - precision_25: 0.6572 - recall_25: 0.6921 - val_loss: 0.6029 - val_accuracy: 0.6657 - val_precision_25: 0.6297 - val_recall_25: 0.6953\n",
            "Epoch 13/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.5911 - accuracy: 0.6798 - precision_25: 0.6576 - recall_25: 0.6915 - val_loss: 0.6025 - val_accuracy: 0.6695 - val_precision_25: 0.6458 - val_recall_25: 0.6524\n",
            "Epoch 14/100\n",
            "251/251 [==============================] - 5s 20ms/step - loss: 0.5902 - accuracy: 0.6822 - precision_25: 0.6612 - recall_25: 0.6898 - val_loss: 0.5987 - val_accuracy: 0.6712 - val_precision_25: 0.6368 - val_recall_25: 0.6937\n",
            "Epoch 15/100\n",
            "251/251 [==============================] - 6s 24ms/step - loss: 0.5899 - accuracy: 0.6791 - precision_25: 0.6558 - recall_25: 0.6945 - val_loss: 0.5994 - val_accuracy: 0.6680 - val_precision_25: 0.6315 - val_recall_25: 0.6998\n",
            "Epoch 16/100\n",
            "251/251 [==============================] - 4s 18ms/step - loss: 0.5901 - accuracy: 0.6799 - precision_25: 0.6554 - recall_25: 0.6993 - val_loss: 0.6003 - val_accuracy: 0.6700 - val_precision_25: 0.6323 - val_recall_25: 0.7064\n",
            "Epoch 17/100\n",
            "251/251 [==============================] - 7s 26ms/step - loss: 0.5898 - accuracy: 0.6818 - precision_25: 0.6579 - recall_25: 0.6993 - val_loss: 0.6003 - val_accuracy: 0.6625 - val_precision_25: 0.6458 - val_recall_25: 0.6193\n",
            "Epoch 18/100\n",
            "251/251 [==============================] - 4s 18ms/step - loss: 0.5879 - accuracy: 0.6831 - precision_25: 0.6600 - recall_25: 0.6980 - val_loss: 0.6002 - val_accuracy: 0.6694 - val_precision_25: 0.6457 - val_recall_25: 0.6524\n",
            "Epoch 19/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.5876 - accuracy: 0.6817 - precision_25: 0.6565 - recall_25: 0.7037 - val_loss: 0.5992 - val_accuracy: 0.6680 - val_precision_25: 0.6398 - val_recall_25: 0.6670\n",
            "Accuracy  :  0.6644729375839233\n",
            "Precision :  0.6391206979751587\n",
            "Recall    :  0.6689222455024719\n",
            "F1- Score :  0.6536819827948738\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 18s 60ms/step - loss: 0.5908 - accuracy: 0.6819 - precision_26: 0.6599 - recall_26: 0.6930 - val_loss: 0.6001 - val_accuracy: 0.6690 - val_precision_26: 0.6389 - val_recall_26: 0.6753\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5909 - accuracy: 0.6825 - precision_26: 0.6600 - recall_26: 0.6955 - val_loss: 0.6004 - val_accuracy: 0.6703 - val_precision_26: 0.6392 - val_recall_26: 0.6801\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5889 - accuracy: 0.6830 - precision_26: 0.6592 - recall_26: 0.7001 - val_loss: 0.6022 - val_accuracy: 0.6677 - val_precision_26: 0.6345 - val_recall_26: 0.6857\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.5894 - accuracy: 0.6820 - precision_26: 0.6590 - recall_26: 0.6964 - val_loss: 0.5995 - val_accuracy: 0.6684 - val_precision_26: 0.6463 - val_recall_26: 0.6454\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5891 - accuracy: 0.6820 - precision_26: 0.6596 - recall_26: 0.6946 - val_loss: 0.6006 - val_accuracy: 0.6685 - val_precision_26: 0.6296 - val_recall_26: 0.7104\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5883 - accuracy: 0.6836 - precision_26: 0.6583 - recall_26: 0.7059 - val_loss: 0.5994 - val_accuracy: 0.6669 - val_precision_26: 0.6442 - val_recall_26: 0.6454\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 4s 31ms/step - loss: 0.5885 - accuracy: 0.6812 - precision_26: 0.6594 - recall_26: 0.6915 - val_loss: 0.6028 - val_accuracy: 0.6694 - val_precision_26: 0.6256 - val_recall_26: 0.7331\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.5871 - accuracy: 0.6839 - precision_26: 0.6595 - recall_26: 0.7028 - val_loss: 0.6044 - val_accuracy: 0.6662 - val_precision_26: 0.6141 - val_recall_26: 0.7736\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5873 - accuracy: 0.6839 - precision_26: 0.6591 - recall_26: 0.7042 - val_loss: 0.6017 - val_accuracy: 0.6607 - val_precision_26: 0.6132 - val_recall_26: 0.7467\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5862 - accuracy: 0.6812 - precision_26: 0.6580 - recall_26: 0.6962 - val_loss: 0.6057 - val_accuracy: 0.6665 - val_precision_26: 0.6164 - val_recall_26: 0.7632\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.5864 - accuracy: 0.6833 - precision_26: 0.6588 - recall_26: 0.7027 - val_loss: 0.5995 - val_accuracy: 0.6688 - val_precision_26: 0.6380 - val_recall_26: 0.6774\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5861 - accuracy: 0.6828 - precision_26: 0.6589 - recall_26: 0.7003 - val_loss: 0.6023 - val_accuracy: 0.6677 - val_precision_26: 0.6179 - val_recall_26: 0.7613\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5853 - accuracy: 0.6840 - precision_26: 0.6590 - recall_26: 0.7053 - val_loss: 0.5992 - val_accuracy: 0.6675 - val_precision_26: 0.6356 - val_recall_26: 0.6806\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5836 - accuracy: 0.6861 - precision_26: 0.6644 - recall_26: 0.6962 - val_loss: 0.6022 - val_accuracy: 0.6660 - val_precision_26: 0.6180 - val_recall_26: 0.7520\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.5842 - accuracy: 0.6847 - precision_26: 0.6617 - recall_26: 0.6992 - val_loss: 0.5983 - val_accuracy: 0.6698 - val_precision_26: 0.6304 - val_recall_26: 0.7136\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5844 - accuracy: 0.6868 - precision_26: 0.6636 - recall_26: 0.7018 - val_loss: 0.6027 - val_accuracy: 0.6709 - val_precision_26: 0.6279 - val_recall_26: 0.7302\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5846 - accuracy: 0.6861 - precision_26: 0.6607 - recall_26: 0.7082 - val_loss: 0.6023 - val_accuracy: 0.6687 - val_precision_26: 0.6248 - val_recall_26: 0.7328\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 4s 28ms/step - loss: 0.5841 - accuracy: 0.6846 - precision_26: 0.6625 - recall_26: 0.6962 - val_loss: 0.5981 - val_accuracy: 0.6703 - val_precision_26: 0.6378 - val_recall_26: 0.6854\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.5834 - accuracy: 0.6873 - precision_26: 0.6636 - recall_26: 0.7040 - val_loss: 0.6018 - val_accuracy: 0.6725 - val_precision_26: 0.6363 - val_recall_26: 0.7027\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5829 - accuracy: 0.6875 - precision_26: 0.6640 - recall_26: 0.7036 - val_loss: 0.5993 - val_accuracy: 0.6668 - val_precision_26: 0.6374 - val_recall_26: 0.6697\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5814 - accuracy: 0.6884 - precision_26: 0.6655 - recall_26: 0.7026 - val_loss: 0.6005 - val_accuracy: 0.6658 - val_precision_26: 0.6312 - val_recall_26: 0.6894\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.5819 - accuracy: 0.6847 - precision_26: 0.6627 - recall_26: 0.6960 - val_loss: 0.6076 - val_accuracy: 0.6614 - val_precision_26: 0.6062 - val_recall_26: 0.7917\n",
            "Epoch 23/100\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.5826 - accuracy: 0.6863 - precision_26: 0.6611 - recall_26: 0.7076 - val_loss: 0.6011 - val_accuracy: 0.6649 - val_precision_26: 0.6206 - val_recall_26: 0.7328\n",
            "Epoch 24/100\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.5833 - accuracy: 0.6864 - precision_26: 0.6614 - recall_26: 0.7072 - val_loss: 0.5990 - val_accuracy: 0.6700 - val_precision_26: 0.6402 - val_recall_26: 0.6753\n",
            "Epoch 25/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5796 - accuracy: 0.6872 - precision_26: 0.6607 - recall_26: 0.7132 - val_loss: 0.6011 - val_accuracy: 0.6677 - val_precision_26: 0.6303 - val_recall_26: 0.7030\n",
            "Epoch 26/100\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.5795 - accuracy: 0.6878 - precision_26: 0.6631 - recall_26: 0.7079 - val_loss: 0.6029 - val_accuracy: 0.6708 - val_precision_26: 0.6386 - val_recall_26: 0.6849\n",
            "Epoch 27/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5797 - accuracy: 0.6891 - precision_26: 0.6652 - recall_26: 0.7064 - val_loss: 0.6010 - val_accuracy: 0.6664 - val_precision_26: 0.6181 - val_recall_26: 0.7536\n",
            "Epoch 28/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5803 - accuracy: 0.6889 - precision_26: 0.6632 - recall_26: 0.7121 - val_loss: 0.6016 - val_accuracy: 0.6658 - val_precision_26: 0.6350 - val_recall_26: 0.6742\n",
            "Accuracy  :  0.669714629650116\n",
            "Precision :  0.6440379619598389\n",
            "Recall    :  0.6758120059967041\n",
            "F1- Score :  0.6595425201001915\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 18s 95ms/step - loss: 0.5825 - accuracy: 0.6839 - precision_27: 0.6593 - recall_27: 0.7035 - val_loss: 0.6034 - val_accuracy: 0.6670 - val_precision_27: 0.6218 - val_recall_27: 0.7384\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 3s 48ms/step - loss: 0.5799 - accuracy: 0.6882 - precision_27: 0.6621 - recall_27: 0.7127 - val_loss: 0.5987 - val_accuracy: 0.6713 - val_precision_27: 0.6429 - val_recall_27: 0.6710\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.5808 - accuracy: 0.6865 - precision_27: 0.6615 - recall_27: 0.7074 - val_loss: 0.6014 - val_accuracy: 0.6694 - val_precision_27: 0.6293 - val_recall_27: 0.7163\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.5806 - accuracy: 0.6879 - precision_27: 0.6630 - recall_27: 0.7084 - val_loss: 0.6002 - val_accuracy: 0.6692 - val_precision_27: 0.6275 - val_recall_27: 0.7230\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.5799 - accuracy: 0.6863 - precision_27: 0.6598 - recall_27: 0.7124 - val_loss: 0.6045 - val_accuracy: 0.6669 - val_precision_27: 0.6263 - val_recall_27: 0.7166\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.5804 - accuracy: 0.6876 - precision_27: 0.6617 - recall_27: 0.7115 - val_loss: 0.6006 - val_accuracy: 0.6707 - val_precision_27: 0.6349 - val_recall_27: 0.6990\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 3s 46ms/step - loss: 0.5804 - accuracy: 0.6900 - precision_27: 0.6656 - recall_27: 0.7091 - val_loss: 0.5997 - val_accuracy: 0.6698 - val_precision_27: 0.6273 - val_recall_27: 0.7272\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 0.5794 - accuracy: 0.6900 - precision_27: 0.6653 - recall_27: 0.7100 - val_loss: 0.5991 - val_accuracy: 0.6695 - val_precision_27: 0.6282 - val_recall_27: 0.7216\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 0.5771 - accuracy: 0.6870 - precision_27: 0.6624 - recall_27: 0.7070 - val_loss: 0.6068 - val_accuracy: 0.6634 - val_precision_27: 0.6469 - val_recall_27: 0.6199\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 0.5762 - accuracy: 0.6895 - precision_27: 0.6644 - recall_27: 0.7106 - val_loss: 0.5995 - val_accuracy: 0.6680 - val_precision_27: 0.6380 - val_recall_27: 0.6737\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.5773 - accuracy: 0.6874 - precision_27: 0.6631 - recall_27: 0.7063 - val_loss: 0.6056 - val_accuracy: 0.6653 - val_precision_27: 0.6182 - val_recall_27: 0.7467\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.5792 - accuracy: 0.6882 - precision_27: 0.6620 - recall_27: 0.7133 - val_loss: 0.6017 - val_accuracy: 0.6708 - val_precision_27: 0.6367 - val_recall_27: 0.6923\n",
            "Accuracy  :  0.6675596833229065\n",
            "Precision :  0.6449796557426453\n",
            "Recall    :  0.6622785329818726\n",
            "F1- Score :  0.6535146368066211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adadelta\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gvCymxEnxgg",
        "outputId": "54cd5094-fe0a-490a-8f43-365f57bc1bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 24s 22ms/step - loss: 0.5792 - accuracy: 0.6886 - precision_28: 0.6729 - recall_28: 0.6806 - val_loss: 0.5986 - val_accuracy: 0.6720 - val_precision_28: 0.6419 - val_recall_28: 0.6785\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5780 - accuracy: 0.6885 - precision_28: 0.6702 - recall_28: 0.6885 - val_loss: 0.5985 - val_accuracy: 0.6724 - val_precision_28: 0.6411 - val_recall_28: 0.6833\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.5782 - accuracy: 0.6911 - precision_28: 0.6718 - recall_28: 0.6943 - val_loss: 0.5984 - val_accuracy: 0.6713 - val_precision_28: 0.6390 - val_recall_28: 0.6857\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 9s 17ms/step - loss: 0.5776 - accuracy: 0.6894 - precision_28: 0.6696 - recall_28: 0.6939 - val_loss: 0.5984 - val_accuracy: 0.6714 - val_precision_28: 0.6382 - val_recall_28: 0.6894\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.5775 - accuracy: 0.6898 - precision_28: 0.6691 - recall_28: 0.6972 - val_loss: 0.5984 - val_accuracy: 0.6714 - val_precision_28: 0.6376 - val_recall_28: 0.6918\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 9s 18ms/step - loss: 0.5781 - accuracy: 0.6866 - precision_28: 0.6648 - recall_28: 0.6974 - val_loss: 0.5985 - val_accuracy: 0.6713 - val_precision_28: 0.6368 - val_recall_28: 0.6945\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 8s 17ms/step - loss: 0.5783 - accuracy: 0.6899 - precision_28: 0.6677 - recall_28: 0.7019 - val_loss: 0.5985 - val_accuracy: 0.6707 - val_precision_28: 0.6355 - val_recall_28: 0.6966\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.5775 - accuracy: 0.6881 - precision_28: 0.6643 - recall_28: 0.7051 - val_loss: 0.5985 - val_accuracy: 0.6702 - val_precision_28: 0.6348 - val_recall_28: 0.6969\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 9s 17ms/step - loss: 0.5789 - accuracy: 0.6893 - precision_28: 0.6657 - recall_28: 0.7055 - val_loss: 0.5986 - val_accuracy: 0.6704 - val_precision_28: 0.6348 - val_recall_28: 0.6982\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.5772 - accuracy: 0.6898 - precision_28: 0.6659 - recall_28: 0.7072 - val_loss: 0.5986 - val_accuracy: 0.6702 - val_precision_28: 0.6343 - val_recall_28: 0.6990\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 9s 17ms/step - loss: 0.5774 - accuracy: 0.6883 - precision_28: 0.6644 - recall_28: 0.7057 - val_loss: 0.5986 - val_accuracy: 0.6703 - val_precision_28: 0.6342 - val_recall_28: 0.7001\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 8s 17ms/step - loss: 0.5780 - accuracy: 0.6882 - precision_28: 0.6637 - recall_28: 0.7076 - val_loss: 0.5987 - val_accuracy: 0.6700 - val_precision_28: 0.6336 - val_recall_28: 0.7011\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5781 - accuracy: 0.6886 - precision_28: 0.6638 - recall_28: 0.7087 - val_loss: 0.5987 - val_accuracy: 0.6704 - val_precision_28: 0.6338 - val_recall_28: 0.7022\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 9s 18ms/step - loss: 0.5773 - accuracy: 0.6908 - precision_28: 0.6659 - recall_28: 0.7115 - val_loss: 0.5988 - val_accuracy: 0.6704 - val_precision_28: 0.6338 - val_recall_28: 0.7022\n",
            "Accuracy  :  0.6690157055854797\n",
            "Precision :  0.6422338485717773\n",
            "Recall    :  0.6791338324546814\n",
            "F1- Score :  0.6601686134382411\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 19s 30ms/step - loss: 0.5793 - accuracy: 0.6881 - precision_29: 0.6673 - recall_29: 0.6957 - val_loss: 0.5984 - val_accuracy: 0.6717 - val_precision_29: 0.6381 - val_recall_29: 0.6913\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 6s 25ms/step - loss: 0.5783 - accuracy: 0.6905 - precision_29: 0.6691 - recall_29: 0.7001 - val_loss: 0.5984 - val_accuracy: 0.6714 - val_precision_29: 0.6372 - val_recall_29: 0.6934\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 5s 20ms/step - loss: 0.5785 - accuracy: 0.6901 - precision_29: 0.6676 - recall_29: 0.7029 - val_loss: 0.5985 - val_accuracy: 0.6708 - val_precision_29: 0.6362 - val_recall_29: 0.6942\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 6s 23ms/step - loss: 0.5776 - accuracy: 0.6916 - precision_29: 0.6693 - recall_29: 0.7037 - val_loss: 0.5985 - val_accuracy: 0.6705 - val_precision_29: 0.6355 - val_recall_29: 0.6958\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 6s 22ms/step - loss: 0.5783 - accuracy: 0.6921 - precision_29: 0.6691 - recall_29: 0.7063 - val_loss: 0.5985 - val_accuracy: 0.6705 - val_precision_29: 0.6353 - val_recall_29: 0.6969\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.5785 - accuracy: 0.6879 - precision_29: 0.6653 - recall_29: 0.7014 - val_loss: 0.5985 - val_accuracy: 0.6704 - val_precision_29: 0.6351 - val_recall_29: 0.6969\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 7s 28ms/step - loss: 0.5780 - accuracy: 0.6872 - precision_29: 0.6638 - recall_29: 0.7031 - val_loss: 0.5985 - val_accuracy: 0.6707 - val_precision_29: 0.6350 - val_recall_29: 0.6985\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 4s 18ms/step - loss: 0.5782 - accuracy: 0.6891 - precision_29: 0.6650 - recall_29: 0.7071 - val_loss: 0.5986 - val_accuracy: 0.6700 - val_precision_29: 0.6341 - val_recall_29: 0.6990\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 5s 21ms/step - loss: 0.5779 - accuracy: 0.6904 - precision_29: 0.6669 - recall_29: 0.7066 - val_loss: 0.5986 - val_accuracy: 0.6704 - val_precision_29: 0.6343 - val_recall_29: 0.7001\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 5s 22ms/step - loss: 0.5789 - accuracy: 0.6904 - precision_29: 0.6654 - recall_29: 0.7113 - val_loss: 0.5986 - val_accuracy: 0.6707 - val_precision_29: 0.6344 - val_recall_29: 0.7009\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.5774 - accuracy: 0.6898 - precision_29: 0.6654 - recall_29: 0.7089 - val_loss: 0.5986 - val_accuracy: 0.6707 - val_precision_29: 0.6344 - val_recall_29: 0.7011\n",
            "Accuracy  :  0.6688410043716431\n",
            "Precision :  0.6411560773849487\n",
            "Recall    :  0.6823326945304871\n",
            "F1- Score :  0.6611038388539082\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 19s 57ms/step - loss: 0.5779 - accuracy: 0.6903 - precision_30: 0.6687 - recall_30: 0.7002 - val_loss: 0.5984 - val_accuracy: 0.6715 - val_precision_30: 0.6377 - val_recall_30: 0.6921\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.5777 - accuracy: 0.6890 - precision_30: 0.6670 - recall_30: 0.7003 - val_loss: 0.5985 - val_accuracy: 0.6713 - val_precision_30: 0.6370 - val_recall_30: 0.6937\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5787 - accuracy: 0.6895 - precision_30: 0.6677 - recall_30: 0.7002 - val_loss: 0.5985 - val_accuracy: 0.6714 - val_precision_30: 0.6367 - val_recall_30: 0.6953\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.5789 - accuracy: 0.6899 - precision_30: 0.6676 - recall_30: 0.7023 - val_loss: 0.5985 - val_accuracy: 0.6708 - val_precision_30: 0.6358 - val_recall_30: 0.6958\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 3s 28ms/step - loss: 0.5785 - accuracy: 0.6895 - precision_30: 0.6668 - recall_30: 0.7031 - val_loss: 0.5985 - val_accuracy: 0.6707 - val_precision_30: 0.6357 - val_recall_30: 0.6958\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 3s 27ms/step - loss: 0.5779 - accuracy: 0.6905 - precision_30: 0.6680 - recall_30: 0.7035 - val_loss: 0.5985 - val_accuracy: 0.6707 - val_precision_30: 0.6355 - val_recall_30: 0.6966\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.5787 - accuracy: 0.6902 - precision_30: 0.6678 - recall_30: 0.7030 - val_loss: 0.5985 - val_accuracy: 0.6702 - val_precision_30: 0.6349 - val_recall_30: 0.6966\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.5779 - accuracy: 0.6902 - precision_30: 0.6668 - recall_30: 0.7059 - val_loss: 0.5985 - val_accuracy: 0.6700 - val_precision_30: 0.6347 - val_recall_30: 0.6966\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5772 - accuracy: 0.6890 - precision_30: 0.6656 - recall_30: 0.7048 - val_loss: 0.5985 - val_accuracy: 0.6702 - val_precision_30: 0.6347 - val_recall_30: 0.6971\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5774 - accuracy: 0.6904 - precision_30: 0.6667 - recall_30: 0.7074 - val_loss: 0.5985 - val_accuracy: 0.6707 - val_precision_30: 0.6350 - val_recall_30: 0.6985\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.5784 - accuracy: 0.6887 - precision_30: 0.6645 - recall_30: 0.7070 - val_loss: 0.5986 - val_accuracy: 0.6700 - val_precision_30: 0.6342 - val_recall_30: 0.6987\n",
            "Accuracy  :  0.668724536895752\n",
            "Precision :  0.640747606754303\n",
            "Recall    :  0.6833169460296631\n",
            "F1- Score :  0.6613479635907187\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 17s 91ms/step - loss: 0.5778 - accuracy: 0.6884 - precision_31: 0.6665 - recall_31: 0.6992 - val_loss: 0.5984 - val_accuracy: 0.6714 - val_precision_31: 0.6373 - val_recall_31: 0.6931\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 0.5785 - accuracy: 0.6909 - precision_31: 0.6687 - recall_31: 0.7031 - val_loss: 0.5984 - val_accuracy: 0.6713 - val_precision_31: 0.6369 - val_recall_31: 0.6942\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 0.5784 - accuracy: 0.6892 - precision_31: 0.6669 - recall_31: 0.7014 - val_loss: 0.5985 - val_accuracy: 0.6708 - val_precision_31: 0.6362 - val_recall_31: 0.6942\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 3s 50ms/step - loss: 0.5792 - accuracy: 0.6899 - precision_31: 0.6678 - recall_31: 0.7015 - val_loss: 0.5985 - val_accuracy: 0.6707 - val_precision_31: 0.6360 - val_recall_31: 0.6945\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 3s 47ms/step - loss: 0.5786 - accuracy: 0.6894 - precision_31: 0.6667 - recall_31: 0.7029 - val_loss: 0.5985 - val_accuracy: 0.6705 - val_precision_31: 0.6356 - val_recall_31: 0.6955\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 39ms/step - loss: 0.5788 - accuracy: 0.6896 - precision_31: 0.6666 - recall_31: 0.7038 - val_loss: 0.5985 - val_accuracy: 0.6705 - val_precision_31: 0.6355 - val_recall_31: 0.6958\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 0.5777 - accuracy: 0.6893 - precision_31: 0.6661 - recall_31: 0.7042 - val_loss: 0.5985 - val_accuracy: 0.6705 - val_precision_31: 0.6353 - val_recall_31: 0.6966\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 0.5774 - accuracy: 0.6880 - precision_31: 0.6647 - recall_31: 0.7036 - val_loss: 0.5985 - val_accuracy: 0.6703 - val_precision_31: 0.6350 - val_recall_31: 0.6966\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 0.5778 - accuracy: 0.6873 - precision_31: 0.6647 - recall_31: 0.7003 - val_loss: 0.5985 - val_accuracy: 0.6702 - val_precision_31: 0.6349 - val_recall_31: 0.6966\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.5781 - accuracy: 0.6881 - precision_31: 0.6642 - recall_31: 0.7054 - val_loss: 0.5985 - val_accuracy: 0.6702 - val_precision_31: 0.6349 - val_recall_31: 0.6966\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 0.5779 - accuracy: 0.6898 - precision_31: 0.6665 - recall_31: 0.7053 - val_loss: 0.5985 - val_accuracy: 0.6700 - val_precision_31: 0.6347 - val_recall_31: 0.6966\n",
            "Accuracy  :  0.6686663031578064\n",
            "Precision :  0.6405763626098633\n",
            "Recall    :  0.6836860179901123\n",
            "F1- Score :  0.6614295006596909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"rmsprop\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6D0hrFonx1S",
        "outputId": "e7fe6704-1382-4392-a167-e3d16873c66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 22s 19ms/step - loss: 0.5870 - accuracy: 0.6824 - precision_32: 0.6588 - recall_32: 0.6985 - val_loss: 0.6055 - val_accuracy: 0.6669 - val_precision_32: 0.6322 - val_recall_32: 0.6910\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5890 - accuracy: 0.6812 - precision_32: 0.6553 - recall_32: 0.7055 - val_loss: 0.6003 - val_accuracy: 0.6739 - val_precision_32: 0.6414 - val_recall_32: 0.6894\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.5874 - accuracy: 0.6839 - precision_32: 0.6588 - recall_32: 0.7054 - val_loss: 0.6023 - val_accuracy: 0.6698 - val_precision_32: 0.6362 - val_recall_32: 0.6894\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5856 - accuracy: 0.6851 - precision_32: 0.6611 - recall_32: 0.7029 - val_loss: 0.6004 - val_accuracy: 0.6703 - val_precision_32: 0.6379 - val_recall_32: 0.6851\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.5857 - accuracy: 0.6849 - precision_32: 0.6577 - recall_32: 0.7132 - val_loss: 0.6010 - val_accuracy: 0.6690 - val_precision_32: 0.6287 - val_recall_32: 0.7168\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5858 - accuracy: 0.6849 - precision_32: 0.6611 - recall_32: 0.7018 - val_loss: 0.6023 - val_accuracy: 0.6665 - val_precision_32: 0.6237 - val_recall_32: 0.7264\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.5853 - accuracy: 0.6846 - precision_32: 0.6588 - recall_32: 0.7085 - val_loss: 0.6026 - val_accuracy: 0.6663 - val_precision_32: 0.6452 - val_recall_32: 0.6391\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5866 - accuracy: 0.6823 - precision_32: 0.6579 - recall_32: 0.7014 - val_loss: 0.6011 - val_accuracy: 0.6698 - val_precision_32: 0.6298 - val_recall_32: 0.7160\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.5865 - accuracy: 0.6830 - precision_32: 0.6568 - recall_32: 0.7085 - val_loss: 0.6052 - val_accuracy: 0.6678 - val_precision_32: 0.6211 - val_recall_32: 0.7461\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 6s 11ms/step - loss: 0.5852 - accuracy: 0.6845 - precision_32: 0.6611 - recall_32: 0.7001 - val_loss: 0.6051 - val_accuracy: 0.6664 - val_precision_32: 0.6293 - val_recall_32: 0.7006\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.5844 - accuracy: 0.6859 - precision_32: 0.6614 - recall_32: 0.7050 - val_loss: 0.6022 - val_accuracy: 0.6715 - val_precision_32: 0.6372 - val_recall_32: 0.6942\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5836 - accuracy: 0.6852 - precision_32: 0.6604 - recall_32: 0.7055 - val_loss: 0.6033 - val_accuracy: 0.6688 - val_precision_32: 0.6271 - val_recall_32: 0.7230\n",
            "Accuracy  :  0.6717530488967896\n",
            "Precision :  0.6457650661468506\n",
            "Recall    :  0.6791338324546814\n",
            "F1- Score :  0.6620292381563224\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 18s 31ms/step - loss: 0.5836 - accuracy: 0.6842 - precision_33: 0.6610 - recall_33: 0.6990 - val_loss: 0.6032 - val_accuracy: 0.6637 - val_precision_33: 0.6237 - val_recall_33: 0.7110\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.5823 - accuracy: 0.6824 - precision_33: 0.6578 - recall_33: 0.7021 - val_loss: 0.6022 - val_accuracy: 0.6655 - val_precision_33: 0.6262 - val_recall_33: 0.7096\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.5824 - accuracy: 0.6868 - precision_33: 0.6599 - recall_33: 0.7142 - val_loss: 0.6019 - val_accuracy: 0.6648 - val_precision_33: 0.6496 - val_recall_33: 0.6177\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 6s 24ms/step - loss: 0.5826 - accuracy: 0.6885 - precision_33: 0.6651 - recall_33: 0.7043 - val_loss: 0.6014 - val_accuracy: 0.6685 - val_precision_33: 0.6416 - val_recall_33: 0.6628\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5820 - accuracy: 0.6893 - precision_33: 0.6649 - recall_33: 0.7081 - val_loss: 0.6104 - val_accuracy: 0.6609 - val_precision_33: 0.6079 - val_recall_33: 0.7781\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.5823 - accuracy: 0.6873 - precision_33: 0.6634 - recall_33: 0.7047 - val_loss: 0.6040 - val_accuracy: 0.6687 - val_precision_33: 0.6372 - val_recall_33: 0.6798\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 6s 23ms/step - loss: 0.5805 - accuracy: 0.6866 - precision_33: 0.6611 - recall_33: 0.7094 - val_loss: 0.5990 - val_accuracy: 0.6704 - val_precision_33: 0.6531 - val_recall_33: 0.6324\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5819 - accuracy: 0.6876 - precision_33: 0.6629 - recall_33: 0.7076 - val_loss: 0.6006 - val_accuracy: 0.6678 - val_precision_33: 0.6375 - val_recall_33: 0.6742\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 5s 19ms/step - loss: 0.5810 - accuracy: 0.6854 - precision_33: 0.6632 - recall_33: 0.6974 - val_loss: 0.6057 - val_accuracy: 0.6658 - val_precision_33: 0.6580 - val_recall_33: 0.5967\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 6s 23ms/step - loss: 0.5794 - accuracy: 0.6883 - precision_33: 0.6623 - recall_33: 0.7122 - val_loss: 0.6027 - val_accuracy: 0.6717 - val_precision_33: 0.6367 - val_recall_33: 0.6969\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5805 - accuracy: 0.6887 - precision_33: 0.6632 - recall_33: 0.7113 - val_loss: 0.6016 - val_accuracy: 0.6657 - val_precision_33: 0.6224 - val_recall_33: 0.7283\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 5s 21ms/step - loss: 0.5804 - accuracy: 0.6878 - precision_33: 0.6632 - recall_33: 0.7074 - val_loss: 0.6008 - val_accuracy: 0.6654 - val_precision_33: 0.6528 - val_recall_33: 0.6105\n",
            "Epoch 13/100\n",
            "251/251 [==============================] - 5s 20ms/step - loss: 0.5798 - accuracy: 0.6845 - precision_33: 0.6598 - recall_33: 0.7047 - val_loss: 0.6032 - val_accuracy: 0.6697 - val_precision_33: 0.6276 - val_recall_33: 0.7251\n",
            "Epoch 14/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.5801 - accuracy: 0.6876 - precision_33: 0.6623 - recall_33: 0.7095 - val_loss: 0.6021 - val_accuracy: 0.6700 - val_precision_33: 0.6292 - val_recall_33: 0.7200\n",
            "Epoch 15/100\n",
            "251/251 [==============================] - 6s 25ms/step - loss: 0.5788 - accuracy: 0.6907 - precision_33: 0.6661 - recall_33: 0.7101 - val_loss: 0.6006 - val_accuracy: 0.6669 - val_precision_33: 0.6351 - val_recall_33: 0.6795\n",
            "Epoch 16/100\n",
            "251/251 [==============================] - 4s 18ms/step - loss: 0.5790 - accuracy: 0.6897 - precision_33: 0.6635 - recall_33: 0.7145 - val_loss: 0.6040 - val_accuracy: 0.6635 - val_precision_33: 0.6123 - val_recall_33: 0.7685\n",
            "Epoch 17/100\n",
            "251/251 [==============================] - 4s 18ms/step - loss: 0.5798 - accuracy: 0.6884 - precision_33: 0.6651 - recall_33: 0.7036 - val_loss: 0.6017 - val_accuracy: 0.6688 - val_precision_33: 0.6370 - val_recall_33: 0.6814\n",
            "Accuracy  :  0.6700057983398438\n",
            "Precision :  0.6617183685302734\n",
            "Recall    :  0.6197096705436707\n",
            "F1- Score :  0.6400254398224978\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 17s 51ms/step - loss: 0.5799 - accuracy: 0.6860 - precision_34: 0.6612 - recall_34: 0.7063 - val_loss: 0.6077 - val_accuracy: 0.6617 - val_precision_34: 0.6151 - val_recall_34: 0.7424\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.5785 - accuracy: 0.6900 - precision_34: 0.6666 - recall_34: 0.7057 - val_loss: 0.6030 - val_accuracy: 0.6700 - val_precision_34: 0.6281 - val_recall_34: 0.7251\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5792 - accuracy: 0.6899 - precision_34: 0.6641 - recall_34: 0.7135 - val_loss: 0.6021 - val_accuracy: 0.6680 - val_precision_34: 0.6285 - val_recall_34: 0.7128\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5785 - accuracy: 0.6925 - precision_34: 0.6675 - recall_34: 0.7133 - val_loss: 0.6010 - val_accuracy: 0.6650 - val_precision_34: 0.6499 - val_recall_34: 0.6180\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.5775 - accuracy: 0.6896 - precision_34: 0.6643 - recall_34: 0.7113 - val_loss: 0.5991 - val_accuracy: 0.6727 - val_precision_34: 0.6386 - val_recall_34: 0.6939\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.5776 - accuracy: 0.6900 - precision_34: 0.6665 - recall_34: 0.7059 - val_loss: 0.6044 - val_accuracy: 0.6642 - val_precision_34: 0.6106 - val_recall_34: 0.7818\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5786 - accuracy: 0.6919 - precision_34: 0.6669 - recall_34: 0.7126 - val_loss: 0.6045 - val_accuracy: 0.6669 - val_precision_34: 0.6261 - val_recall_34: 0.7176\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5788 - accuracy: 0.6889 - precision_34: 0.6665 - recall_34: 0.7014 - val_loss: 0.6085 - val_accuracy: 0.6674 - val_precision_34: 0.6497 - val_recall_34: 0.6295\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 5s 36ms/step - loss: 0.5767 - accuracy: 0.6898 - precision_34: 0.6682 - recall_34: 0.6999 - val_loss: 0.6131 - val_accuracy: 0.6657 - val_precision_34: 0.6109 - val_recall_34: 0.7885\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5776 - accuracy: 0.6893 - precision_34: 0.6651 - recall_34: 0.7078 - val_loss: 0.6056 - val_accuracy: 0.6652 - val_precision_34: 0.6189 - val_recall_34: 0.7424\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5790 - accuracy: 0.6884 - precision_34: 0.6645 - recall_34: 0.7059 - val_loss: 0.6043 - val_accuracy: 0.6733 - val_precision_34: 0.6402 - val_recall_34: 0.6910\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5779 - accuracy: 0.6902 - precision_34: 0.6682 - recall_34: 0.7014 - val_loss: 0.6033 - val_accuracy: 0.6715 - val_precision_34: 0.6448 - val_recall_34: 0.6654\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.5762 - accuracy: 0.6907 - precision_34: 0.6673 - recall_34: 0.7065 - val_loss: 0.5985 - val_accuracy: 0.6724 - val_precision_34: 0.6392 - val_recall_34: 0.6905\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5765 - accuracy: 0.6912 - precision_34: 0.6671 - recall_34: 0.7089 - val_loss: 0.6075 - val_accuracy: 0.6693 - val_precision_34: 0.6266 - val_recall_34: 0.7278\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5756 - accuracy: 0.6889 - precision_34: 0.6672 - recall_34: 0.6992 - val_loss: 0.6033 - val_accuracy: 0.6649 - val_precision_34: 0.6507 - val_recall_34: 0.6148\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5762 - accuracy: 0.6915 - precision_34: 0.6699 - recall_34: 0.7017 - val_loss: 0.6003 - val_accuracy: 0.6648 - val_precision_34: 0.6185 - val_recall_34: 0.7424\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.5760 - accuracy: 0.6922 - precision_34: 0.6686 - recall_34: 0.7085 - val_loss: 0.6053 - val_accuracy: 0.6606 - val_precision_34: 0.6133 - val_recall_34: 0.7453\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5764 - accuracy: 0.6905 - precision_34: 0.6656 - recall_34: 0.7109 - val_loss: 0.6142 - val_accuracy: 0.6668 - val_precision_34: 0.6682 - val_recall_34: 0.5735\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5748 - accuracy: 0.6904 - precision_34: 0.6678 - recall_34: 0.7038 - val_loss: 0.5993 - val_accuracy: 0.6715 - val_precision_34: 0.6389 - val_recall_34: 0.6875\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 3s 24ms/step - loss: 0.5748 - accuracy: 0.6922 - precision_34: 0.6658 - recall_34: 0.7175 - val_loss: 0.5995 - val_accuracy: 0.6700 - val_precision_34: 0.6449 - val_recall_34: 0.6580\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.5755 - accuracy: 0.6901 - precision_34: 0.6652 - recall_34: 0.7106 - val_loss: 0.6063 - val_accuracy: 0.6603 - val_precision_34: 0.6115 - val_recall_34: 0.7539\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.5736 - accuracy: 0.6925 - precision_34: 0.6685 - recall_34: 0.7100 - val_loss: 0.6040 - val_accuracy: 0.6664 - val_precision_34: 0.6475 - val_recall_34: 0.6321\n",
            "Epoch 23/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.5739 - accuracy: 0.6905 - precision_34: 0.6673 - recall_34: 0.7057 - val_loss: 0.6033 - val_accuracy: 0.6692 - val_precision_34: 0.6302 - val_recall_34: 0.7110\n",
            "Accuracy  :  0.6715201139450073\n",
            "Precision :  0.6449207663536072\n",
            "Recall    :  0.6811023354530334\n",
            "F1- Score :  0.6625179298115336\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 16s 74ms/step - loss: 0.5754 - accuracy: 0.6948 - precision_35: 0.6703 - recall_35: 0.7140 - val_loss: 0.6015 - val_accuracy: 0.6639 - val_precision_35: 0.6184 - val_recall_35: 0.7379\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.5745 - accuracy: 0.6923 - precision_35: 0.6679 - recall_35: 0.7109 - val_loss: 0.5994 - val_accuracy: 0.6688 - val_precision_35: 0.6405 - val_recall_35: 0.6678\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 0.5741 - accuracy: 0.6906 - precision_35: 0.6679 - recall_35: 0.7042 - val_loss: 0.5986 - val_accuracy: 0.6723 - val_precision_35: 0.6411 - val_recall_35: 0.6825\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 0.5734 - accuracy: 0.6928 - precision_35: 0.6700 - recall_35: 0.7069 - val_loss: 0.6006 - val_accuracy: 0.6728 - val_precision_35: 0.6334 - val_recall_35: 0.7160\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.5747 - accuracy: 0.6919 - precision_35: 0.6677 - recall_35: 0.7100 - val_loss: 0.6016 - val_accuracy: 0.6689 - val_precision_35: 0.6278 - val_recall_35: 0.7203\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.5741 - accuracy: 0.6914 - precision_35: 0.6684 - recall_35: 0.7059 - val_loss: 0.6000 - val_accuracy: 0.6717 - val_precision_35: 0.6381 - val_recall_35: 0.6913\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 0.5746 - accuracy: 0.6909 - precision_35: 0.6697 - recall_35: 0.6997 - val_loss: 0.5993 - val_accuracy: 0.6697 - val_precision_35: 0.6330 - val_recall_35: 0.7019\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 3s 46ms/step - loss: 0.5734 - accuracy: 0.6918 - precision_35: 0.6685 - recall_35: 0.7070 - val_loss: 0.6002 - val_accuracy: 0.6667 - val_precision_35: 0.6361 - val_recall_35: 0.6742\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.5737 - accuracy: 0.6918 - precision_35: 0.6678 - recall_35: 0.7091 - val_loss: 0.6041 - val_accuracy: 0.6705 - val_precision_35: 0.6476 - val_recall_35: 0.6510\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.5733 - accuracy: 0.6920 - precision_35: 0.6686 - recall_35: 0.7079 - val_loss: 0.5988 - val_accuracy: 0.6705 - val_precision_35: 0.6336 - val_recall_35: 0.7035\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 37ms/step - loss: 0.5738 - accuracy: 0.6923 - precision_35: 0.6680 - recall_35: 0.7109 - val_loss: 0.6013 - val_accuracy: 0.6680 - val_precision_35: 0.6240 - val_recall_35: 0.7334\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.5727 - accuracy: 0.6923 - precision_35: 0.6683 - recall_35: 0.7100 - val_loss: 0.6024 - val_accuracy: 0.6679 - val_precision_35: 0.6223 - val_recall_35: 0.7405\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.5724 - accuracy: 0.6935 - precision_35: 0.6676 - recall_35: 0.7173 - val_loss: 0.6105 - val_accuracy: 0.6649 - val_precision_35: 0.6702 - val_recall_35: 0.5607\n",
            "Accuracy  :  0.6706464886665344\n",
            "Precision :  0.6468701958656311\n",
            "Recall    :  0.6700295209884644\n",
            "F1- Score :  0.6582462156085094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Combination of rdkit, dpc and aac dataset**"
      ],
      "metadata": {
        "id": "p021GJCP4y-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "aac = pd.read_csv(\"/content/drive/MyDrive/AAC_feature.csv\")\n",
        "dpc = pd.read_csv(\"/content/drive/MyDrive/DPC_feature.csv\")\n",
        "target = pd.read_csv(\"/content/drive/MyDrive/target.csv\")"
      ],
      "metadata": {
        "id": "1wOdIY3QPDFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the dataset\n",
        "aac = pd.DataFrame(sc.fit_transform(aac))\n",
        "dpc = pd.DataFrame(sc.fit_transform(dpc))"
      ],
      "metadata": {
        "id": "6bdOgtgg4731"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aac # displaying the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "2Htk_Pvi5BCK",
        "outputId": "726e03bd-84d6-4d88-c2a9-22a9cceb9c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3        4         5         6   \\\n",
              "0      0.090959  0.000000  0.111167  0.100045  0.00000  0.166625  0.000000   \n",
              "1      0.272740  0.000000  0.000000  0.000000  0.00000  0.083375  0.000000   \n",
              "2      0.272740  0.000000  0.111167  0.100045  0.20012  0.083375  0.000000   \n",
              "3      0.181781  0.000000  0.111167  0.199940  0.00000  0.000000  0.000000   \n",
              "4      0.272740  0.000000  0.111167  0.000000  0.00000  0.083375  0.000000   \n",
              "...         ...       ...       ...       ...      ...       ...       ...   \n",
              "62164  0.090959  0.142918  0.000000  0.000000  0.00000  0.166625  0.142918   \n",
              "62165  0.181781  0.142918  0.111167  0.100045  0.00000  0.000000  0.000000   \n",
              "62166  0.000000  0.000000  0.000000  0.100045  0.00000  0.250000  0.285622   \n",
              "62167  0.000000  0.000000  0.222167  0.100045  0.00000  0.083375  0.000000   \n",
              "62168  0.181781  0.000000  0.000000  0.000000  0.20012  0.083375  0.000000   \n",
              "\n",
              "            7         8         9        10       11        12        13  \\\n",
              "0      0.00000  0.125070  0.125070  0.20012  0.00000  0.000000  0.142918   \n",
              "1      0.16675  0.249953  0.000000  0.20012  0.00000  0.000000  0.142918   \n",
              "2      0.00000  0.249953  0.125070  0.00000  0.16675  0.000000  0.142918   \n",
              "3      0.16675  0.249953  0.249953  0.00000  0.00000  0.000000  0.000000   \n",
              "4      0.00000  0.000000  0.125070  0.00000  0.16675  0.000000  0.000000   \n",
              "...        ...       ...       ...      ...      ...       ...       ...   \n",
              "62164  0.00000  0.125070  0.125070  0.00000  0.00000  0.199940  0.000000   \n",
              "62165  0.16675  0.000000  0.375023  0.00000  0.00000  0.100045  0.000000   \n",
              "62166  0.16675  0.000000  0.000000  0.00000  0.00000  0.199940  0.142918   \n",
              "62167  0.16675  0.125070  0.249953  0.00000  0.33325  0.000000  0.000000   \n",
              "62168  0.00000  0.125070  0.500094  0.00000  0.00000  0.100045  0.000000   \n",
              "\n",
              "             14      15        16       17      18        19  \n",
              "0      0.181781  0.0000  0.142827  0.33325  0.0000  0.000000  \n",
              "1      0.181781  0.0667  0.142827  0.16675  0.0000  0.000000  \n",
              "2      0.090959  0.0667  0.000000  0.16675  0.0000  0.000000  \n",
              "3      0.181781  0.0667  0.142827  0.00000  0.0000  0.000000  \n",
              "4      0.272740  0.0667  0.000000  0.50000  0.0000  0.142918  \n",
              "...         ...     ...       ...      ...     ...       ...  \n",
              "62164  0.090959  0.2000  0.000000  0.33325  0.0000  0.000000  \n",
              "62165  0.181781  0.0667  0.071467  0.16675  0.0000  0.000000  \n",
              "62166  0.000000  0.0667  0.071467  0.33325  0.0000  0.142918  \n",
              "62167  0.000000  0.0667  0.071467  0.16675  0.0000  0.285622  \n",
              "62168  0.090959  0.0667  0.071467  0.00000  0.3335  0.142918  \n",
              "\n",
              "[62169 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbea2c7a-1bda-4b30-8acb-37e691fda678\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.090959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111167</td>\n",
              "      <td>0.100045</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.166625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.20012</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142918</td>\n",
              "      <td>0.181781</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.142827</td>\n",
              "      <td>0.33325</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.272740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.083375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.249953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.20012</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142918</td>\n",
              "      <td>0.181781</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.142827</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.272740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111167</td>\n",
              "      <td>0.100045</td>\n",
              "      <td>0.20012</td>\n",
              "      <td>0.083375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.249953</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142918</td>\n",
              "      <td>0.090959</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.181781</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111167</td>\n",
              "      <td>0.199940</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.249953</td>\n",
              "      <td>0.249953</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181781</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.142827</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.272740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.083375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.272740</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.142918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62164</th>\n",
              "      <td>0.090959</td>\n",
              "      <td>0.142918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.166625</td>\n",
              "      <td>0.142918</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.199940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090959</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.33325</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62165</th>\n",
              "      <td>0.181781</td>\n",
              "      <td>0.142918</td>\n",
              "      <td>0.111167</td>\n",
              "      <td>0.100045</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375023</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.100045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181781</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.071467</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62166</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100045</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.285622</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.199940</td>\n",
              "      <td>0.142918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.071467</td>\n",
              "      <td>0.33325</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.142918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62167</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222167</td>\n",
              "      <td>0.100045</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.083375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.249953</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.33325</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.071467</td>\n",
              "      <td>0.16675</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.285622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62168</th>\n",
              "      <td>0.181781</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.20012</td>\n",
              "      <td>0.083375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.125070</td>\n",
              "      <td>0.500094</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.100045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090959</td>\n",
              "      <td>0.0667</td>\n",
              "      <td>0.071467</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.3335</td>\n",
              "      <td>0.142918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62169 rows × 20 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbea2c7a-1bda-4b30-8acb-37e691fda678')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbea2c7a-1bda-4b30-8acb-37e691fda678 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbea2c7a-1bda-4b30-8acb-37e691fda678');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3ffdd47-0fac-4d67-99f6-0db4ccd053ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3ffdd47-0fac-4d67-99f6-0db4ccd053ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3ffdd47-0fac-4d67-99f6-0db4ccd053ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "aac",
              "summary": "{\n  \"name\": \"aac\",\n  \"rows\": 62169,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10265993236449575,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.09095867993999728,\n          0.2727396699849993,\n          0.45452066003000136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0604528467099804,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.8570816370259267,\n          0.14291836297407326,\n          0.7141632740518534\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10189667898928567,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.8888333333333333,\n          0.35716666666666663,\n          0.11116666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11095023423357107,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.8999550022498874,\n          0.10709464526773661,\n          0.1000449977501125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12487690529402137,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.20012001200120014,\n          0.8001800180018003,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0954646564412479,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.16662500000000002,\n          0.083375,\n          0.416625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08076424792434335,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.4591814870366402,\n          0.14291836297407326,\n          0.1529890722091279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1338894567773051,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.1785,\n          0.0,\n          0.71425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12713793807559923,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1.0,\n          0.8751171948246766,\n          0.12507031689480594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13525511615664537,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.40183761485092817,\n          1.0,\n          0.12507031689480594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10565669936557688,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.0,\n          0.8001800180018003,\n          0.20012001200120014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1201280951811913,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.0,\n          0.16675,\n          0.35725\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11438681032936146,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.10709464526773661,\n          0.7000149992500375,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 13,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11307753097740021,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.42854081851296333,\n          0.14291836297407326,\n          0.4591814870366402\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 14,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09339223871063626,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.18178099004500206,\n          0.09095867993999728,\n          0.3636983499249966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 15,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10774312593606143,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.0,\n          0.1429,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 16,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07608366697444326,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.4285867352405443,\n          0.15311261116468444,\n          0.1428265295189114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 17,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15177877201585646,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.0,\n          0.16675,\n          0.35725\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 18,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10535690324670091,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          0.6665000000000001,\n          0.7145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 19,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10775659288770084,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          0.6121705592457681,\n          0.7141632740518534,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merging the rdkit features and dipeptide composition features\n",
        "combined_data = pd.concat([dpc, data, target], axis=1)\n",
        "combined_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "-jbNiIda5Z1u",
        "outputId": "deb45198-6625-46f7-a5f6-040529519a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0    1        2    3    4    5    6    7    8         9  ...  185  \\\n",
              "0      0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
              "1      0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
              "2      0.0  0.0  0.49965  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
              "3      0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
              "4      0.0  0.0  0.49965  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0   \n",
              "...    ...  ...      ...  ...  ...  ...  ...  ...  ...       ...  ...  ...   \n",
              "62164  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.249912  ...  NaN   \n",
              "62165  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  NaN   \n",
              "62166  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  NaN   \n",
              "62167  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  NaN   \n",
              "62168  0.0  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.500175  ...  NaN   \n",
              "\n",
              "       186  187  188  189  190  191       192  193  Target  \n",
              "0      0.0  0.0  0.0  0.0  0.0  0.0  0.401391  0.0       1  \n",
              "1      0.0  0.0  0.0  0.0  0.0  0.0  0.250889  0.0       1  \n",
              "2      0.0  0.0  0.0  0.0  0.0  0.0  0.259876  0.0       0  \n",
              "3      0.0  0.0  0.0  0.0  0.0  0.0  0.158587  1.0       1  \n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.031997  1.0       1  \n",
              "...    ...  ...  ...  ...  ...  ...       ...  ...     ...  \n",
              "62164  NaN  NaN  NaN  NaN  NaN  NaN       NaN  NaN       0  \n",
              "62165  NaN  NaN  NaN  NaN  NaN  NaN       NaN  NaN       0  \n",
              "62166  NaN  NaN  NaN  NaN  NaN  NaN       NaN  NaN       0  \n",
              "62167  NaN  NaN  NaN  NaN  NaN  NaN       NaN  NaN       1  \n",
              "62168  NaN  NaN  NaN  NaN  NaN  NaN       NaN  NaN       0  \n",
              "\n",
              "[62169 rows x 595 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f4365d5-abd0-47d1-bb9e-89c930578641\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.401391</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.49965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.259876</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.158587</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.49965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.031997</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62164</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.249912</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62165</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62166</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62167</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62168</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500175</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62169 rows × 595 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f4365d5-abd0-47d1-bb9e-89c930578641')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4f4365d5-abd0-47d1-bb9e-89c930578641 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4f4365d5-abd0-47d1-bb9e-89c930578641');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5fd8044c-22e3-42b3-8cd3-cfa79a9c3a6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fd8044c-22e3-42b3-8cd3-cfa79a9c3a6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5fd8044c-22e3-42b3-8cd3-cfa79a9c3a6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_data"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing null values\n",
        "combined_data.dropna(inplace=True)\n",
        "combined_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "5tILDzx18wwo",
        "outputId": "6c92f4ae-4c8a-4ea3-dbd4-f706a0d966cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0    1        2    3    4         5    6    7    8    9  ...  185  \\\n",
              "0      0.0  0.0  0.00000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "1      0.0  0.0  0.00000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "2      0.0  0.0  0.49965  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "3      0.0  0.0  0.00000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "4      0.0  0.0  0.49965  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "...    ...  ...      ...  ...  ...       ...  ...  ...  ...  ...  ...  ...   \n",
              "57227  0.0  0.0  0.00000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "57228  0.0  0.0  0.00000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "57229  0.0  0.0  0.00000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "57230  0.0  0.0  0.00000  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "57231  0.0  0.0  0.00000  0.0  0.0  0.333178  0.0  0.0  0.0  0.0  ...  0.0   \n",
              "\n",
              "       186  187  188  189  190   191       192  193  Target  \n",
              "0      0.0  0.0  0.0  0.0  0.0  0.00  0.401391  0.0       1  \n",
              "1      0.0  0.0  0.0  0.0  0.0  0.00  0.250889  0.0       1  \n",
              "2      0.0  0.0  0.0  0.0  0.0  0.00  0.259876  0.0       0  \n",
              "3      0.0  0.0  0.0  0.0  0.0  0.00  0.158587  1.0       1  \n",
              "4      0.0  0.0  0.0  0.0  0.0  0.00  0.031997  1.0       1  \n",
              "...    ...  ...  ...  ...  ...   ...       ...  ...     ...  \n",
              "57227  0.0  0.0  0.0  0.0  0.0  0.00  0.340727  1.0       0  \n",
              "57228  0.0  0.0  0.0  0.0  0.0  0.00  0.031450  0.0       0  \n",
              "57229  0.0  0.0  0.0  0.0  0.0  0.00  0.220864  0.0       1  \n",
              "57230  0.0  0.0  0.0  0.0  0.0  0.25  0.257904  1.0       0  \n",
              "57231  0.0  0.0  0.0  0.0  0.0  0.00  0.250949  1.0       0  \n",
              "\n",
              "[57232 rows x 595 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bf08f6c-49fc-4bde-9dda-4b36fcb1f4b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.401391</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.250889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.49965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.259876</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.158587</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.49965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.031997</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57227</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.340727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57228</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.031450</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57229</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.220864</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57230</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.257904</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57231</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333178</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.250949</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57232 rows × 595 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bf08f6c-49fc-4bde-9dda-4b36fcb1f4b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bf08f6c-49fc-4bde-9dda-4b36fcb1f4b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bf08f6c-49fc-4bde-9dda-4b36fcb1f4b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c62e96c-0a30-482c-a3cd-5130bf702c72\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c62e96c-0a30-482c-a3cd-5130bf702c72')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c62e96c-0a30-482c-a3cd-5130bf702c72 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_data"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into features and target\n",
        "x = combined_data.iloc[:,:-1]\n",
        "y = combined_data.iloc[:,-1]"
      ],
      "metadata": {
        "id": "jgnC5X5p6kJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1) # splitting data into trai test data"
      ],
      "metadata": {
        "id": "c9JPPnC07HHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying random forest classifier\n",
        "rf.fit(x_train,y_train)\n",
        "y_pred = rf.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94OiOC_U77Ng",
        "outputId": "032a4f7d-ebea-47e3-944b-222736c3d43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6755387303436226\n",
            "Precision :   0.6752314574014355\n",
            "Recall    :   0.726062639821029\n",
            "F1-score  :   0.6997251118417507\n",
            "Confusion matrix      : \n",
            "  [[5108 3122]\n",
            " [2449 6491]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.62      0.65      8230\n",
            "           1       0.68      0.73      0.70      8940\n",
            "\n",
            "    accuracy                           0.68     17170\n",
            "   macro avg       0.68      0.67      0.67     17170\n",
            "weighted avg       0.68      0.68      0.67     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying MLP classifier\n",
        "mlp.fit(x_train,y_train)\n",
        "y_pred = mlp.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG9Qtiso9vPk",
        "outputId": "cb36777d-f5be-4dc9-99a2-e195688d8cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.7135701805474665\n",
            "Precision :   0.7199737475388318\n",
            "Recall    :   0.736241610738255\n",
            "F1-score  :   0.7280168122995244\n",
            "Confusion matrix      : \n",
            "  [[5670 2560]\n",
            " [2358 6582]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70      8230\n",
            "           1       0.72      0.74      0.73      8940\n",
            "\n",
            "    accuracy                           0.71     17170\n",
            "   macro avg       0.71      0.71      0.71     17170\n",
            "weighted avg       0.71      0.71      0.71     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying stochastic gradient classifier classifier\n",
        "sgd.fit(x_train,y_train)\n",
        "y_pred = sgd.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5is6ejAS_M3o",
        "outputId": "d21b2748-4443-493e-c9c8-991c929b83b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6739662201514269\n",
            "Precision :   0.6603954693799193\n",
            "Recall    :   0.7695749440715883\n",
            "F1-score  :   0.7108172331852464\n",
            "Confusion matrix      : \n",
            "  [[4692 3538]\n",
            " [2060 6880]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.57      0.63      8230\n",
            "           1       0.66      0.77      0.71      8940\n",
            "\n",
            "    accuracy                           0.67     17170\n",
            "   macro avg       0.68      0.67      0.67     17170\n",
            "weighted avg       0.68      0.67      0.67     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying SVM classifier\n",
        "svc.fit(x_train,y_train)\n",
        "y_pred = svc.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcJ8WKZvEZoI",
        "outputId": "c493e3c5-82a6-4de6-81b8-222b7476aa52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6842166569598136\n",
            "Precision :   0.6792702812882185\n",
            "Recall    :   0.7455257270693513\n",
            "F1-score  :   0.7108575085324231\n",
            "Confusion matrix      : \n",
            "  [[5083 3147]\n",
            " [2275 6665]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.62      0.65      8230\n",
            "           1       0.68      0.75      0.71      8940\n",
            "\n",
            "    accuracy                           0.68     17170\n",
            "   macro avg       0.69      0.68      0.68     17170\n",
            "weighted avg       0.68      0.68      0.68     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying Logistic regression classifier\n",
        "lr.fit(x_train,y_train)\n",
        "y_pred = lr.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKHvZuMhKAF-",
        "outputId": "ff33a637-45f7-45e2-ef23-61e951f46815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6725101921956902\n",
            "Precision :   0.6749288049783778\n",
            "Recall    :   0.7157718120805369\n",
            "F1-score  :   0.6947505564301611\n",
            "Confusion matrix      : \n",
            "  [[5148 3082]\n",
            " [2541 6399]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.63      0.65      8230\n",
            "           1       0.67      0.72      0.69      8940\n",
            "\n",
            "    accuracy                           0.67     17170\n",
            "   macro avg       0.67      0.67      0.67     17170\n",
            "weighted avg       0.67      0.67      0.67     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying KNN classifier with diffenet values of k\n",
        "for k in range(1, 10,2):\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(x_train,y_train)\n",
        "  y_pred = knn.predict(x_test)\n",
        "  print(\"k = \", k)\n",
        "  metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZcumWjtKOUW",
        "outputId": "cbbf9bc2-26a7-4a71-9779-504d2af2ee5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k =  1\n",
            "Accuracy  :   0.5801397786837508\n",
            "Precision :   0.6103531811806706\n",
            "Recall    :   0.5354586129753915\n",
            "F1-score  :   0.5704582017517726\n",
            "Confusion matrix      : \n",
            "  [[5174 3056]\n",
            " [4153 4787]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.63      0.59      8230\n",
            "           1       0.61      0.54      0.57      8940\n",
            "\n",
            "    accuracy                           0.58     17170\n",
            "   macro avg       0.58      0.58      0.58     17170\n",
            "weighted avg       0.58      0.58      0.58     17170\n",
            "\n",
            "k =  3\n",
            "Accuracy  :   0.5675596971461853\n",
            "Precision :   0.6077065263756576\n",
            "Recall    :   0.47807606263982105\n",
            "F1-score  :   0.5351530708069868\n",
            "Confusion matrix      : \n",
            "  [[5471 2759]\n",
            " [4666 4274]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.66      0.60      8230\n",
            "           1       0.61      0.48      0.54      8940\n",
            "\n",
            "    accuracy                           0.57     17170\n",
            "   macro avg       0.57      0.57      0.57     17170\n",
            "weighted avg       0.58      0.57      0.56     17170\n",
            "\n",
            "k =  5\n",
            "Accuracy  :   0.5648806057076295\n",
            "Precision :   0.6122916985170463\n",
            "Recall    :   0.44798657718120805\n",
            "F1-score  :   0.5174084361475357\n",
            "Confusion matrix      : \n",
            "  [[5694 2536]\n",
            " [4935 4005]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.69      0.60      8230\n",
            "           1       0.61      0.45      0.52      8940\n",
            "\n",
            "    accuracy                           0.56     17170\n",
            "   macro avg       0.57      0.57      0.56     17170\n",
            "weighted avg       0.58      0.56      0.56     17170\n",
            "\n",
            "k =  7\n",
            "Accuracy  :   0.5587652882935352\n",
            "Precision :   0.6119133574007221\n",
            "Recall    :   0.41711409395973154\n",
            "F1-score  :   0.49607556205933223\n",
            "Confusion matrix      : \n",
            "  [[5865 2365]\n",
            " [5211 3729]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.71      0.61      8230\n",
            "           1       0.61      0.42      0.50      8940\n",
            "\n",
            "    accuracy                           0.56     17170\n",
            "   macro avg       0.57      0.56      0.55     17170\n",
            "weighted avg       0.57      0.56      0.55     17170\n",
            "\n",
            "k =  9\n",
            "Accuracy  :   0.5569598136284216\n",
            "Precision :   0.6176522506619594\n",
            "Recall    :   0.3913870246085011\n",
            "F1-score  :   0.47915097569325577\n",
            "Confusion matrix      : \n",
            "  [[6064 2166]\n",
            " [5441 3499]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.74      0.61      8230\n",
            "           1       0.62      0.39      0.48      8940\n",
            "\n",
            "    accuracy                           0.56     17170\n",
            "   macro avg       0.57      0.56      0.55     17170\n",
            "weighted avg       0.57      0.56      0.54     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying bagging classifier\n",
        "bgc_rf.fit(x_train,y_train)\n",
        "y_pred = bgc_rf.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXPNX6egLTGG",
        "outputId": "0b9f94a1-9d8c-4e69-a8fc-583c214cd4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6912638322655795\n",
            "Precision :   0.679632737683878\n",
            "Recall    :   0.7700223713646532\n",
            "F1-score  :   0.7220095442865383\n",
            "Confusion matrix      : \n",
            "  [[4985 3245]\n",
            " [2056 6884]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.61      0.65      8230\n",
            "           1       0.68      0.77      0.72      8940\n",
            "\n",
            "    accuracy                           0.69     17170\n",
            "   macro avg       0.69      0.69      0.69     17170\n",
            "weighted avg       0.69      0.69      0.69     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying histogram gradient boosting classifier\n",
        "hist_gbc.fit(x_train,y_train)\n",
        "y_pred = hist_gbc.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvRQp9P9M7ru",
        "outputId": "831c3f24-1f4d-4c59-add1-ff03d076db8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.6976121141525917\n",
            "Precision :   0.6939557027530532\n",
            "Recall    :   0.75\n",
            "F1-score  :   0.7208902268573273\n",
            "Confusion matrix      : \n",
            "  [[5273 2957]\n",
            " [2235 6705]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.64      0.67      8230\n",
            "           1       0.69      0.75      0.72      8940\n",
            "\n",
            "    accuracy                           0.70     17170\n",
            "   macro avg       0.70      0.70      0.70     17170\n",
            "weighted avg       0.70      0.70      0.70     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# applying adaboost classifier\n",
        "ada.fit(x_train,y_train)\n",
        "y_pred = ada.predict(x_test)\n",
        "metric_calculation(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDqrnCpqQ1Fp",
        "outputId": "4e9e6705-2a34-4ff5-eabd-9445bce31c53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy  :   0.693185789167152\n",
            "Precision :   0.690259067357513\n",
            "Recall    :   0.7450782997762864\n",
            "F1-score  :   0.7166218396987628\n",
            "Confusion matrix      : \n",
            "  [[5241 2989]\n",
            " [2279 6661]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.64      0.67      8230\n",
            "           1       0.69      0.75      0.72      8940\n",
            "\n",
            "    accuracy                           0.69     17170\n",
            "   macro avg       0.69      0.69      0.69     17170\n",
            "weighted avg       0.69      0.69      0.69     17170\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into train test and validation\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BwNcsgQVSYZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_dl_model(x_train) # create dl model"
      ],
      "metadata": {
        "id": "bPnVXlDlSZ2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model and evaluating scores with different batch size and optimizers and iterations"
      ],
      "metadata": {
        "id": "qms3wK0etEgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [64, 128, 256, 512]\n",
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adam\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed4A8IRCTVSH",
        "outputId": "036e3bf1-4430-496b-9ef4-2c9ac036b49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 11s 15ms/step - loss: 0.6557 - accuracy: 0.6160 - precision: 0.6110 - recall: 0.7034 - val_loss: 0.6538 - val_accuracy: 0.6187 - val_precision: 0.5857 - val_recall: 0.9109\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6158 - accuracy: 0.6734 - precision: 0.6682 - recall: 0.7288 - val_loss: 0.6143 - val_accuracy: 0.6693 - val_precision: 0.6974 - val_recall: 0.6428\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.6053 - accuracy: 0.6792 - precision: 0.6720 - recall: 0.7388 - val_loss: 0.6098 - val_accuracy: 0.6763 - val_precision: 0.6679 - val_recall: 0.7504\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.5997 - accuracy: 0.6829 - precision: 0.6746 - recall: 0.7443 - val_loss: 0.6075 - val_accuracy: 0.6733 - val_precision: 0.6503 - val_recall: 0.8039\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5931 - accuracy: 0.6872 - precision: 0.6815 - recall: 0.7392 - val_loss: 0.6020 - val_accuracy: 0.6774 - val_precision: 0.6951 - val_recall: 0.6759\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5850 - accuracy: 0.6914 - precision: 0.6807 - recall: 0.7567 - val_loss: 0.6026 - val_accuracy: 0.6813 - val_precision: 0.6604 - val_recall: 0.7964\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.5782 - accuracy: 0.6992 - precision: 0.6869 - recall: 0.7661 - val_loss: 0.6028 - val_accuracy: 0.6804 - val_precision: 0.6540 - val_recall: 0.8181\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5713 - accuracy: 0.7051 - precision: 0.6904 - recall: 0.7764 - val_loss: 0.5988 - val_accuracy: 0.6858 - val_precision: 0.6767 - val_recall: 0.7573\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5586 - accuracy: 0.7162 - precision: 0.7021 - recall: 0.7815 - val_loss: 0.5942 - val_accuracy: 0.6874 - val_precision: 0.6642 - val_recall: 0.8063\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.5453 - accuracy: 0.7249 - precision: 0.7072 - recall: 0.7963 - val_loss: 0.5969 - val_accuracy: 0.6921 - val_precision: 0.6915 - val_recall: 0.7364\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.5335 - accuracy: 0.7349 - precision: 0.7151 - recall: 0.8079 - val_loss: 0.5996 - val_accuracy: 0.6873 - val_precision: 0.6761 - val_recall: 0.7648\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.5208 - accuracy: 0.7447 - precision: 0.7258 - recall: 0.8117 - val_loss: 0.6014 - val_accuracy: 0.6869 - val_precision: 0.6942 - val_recall: 0.7110\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.5087 - accuracy: 0.7543 - precision: 0.7344 - recall: 0.8204 - val_loss: 0.6060 - val_accuracy: 0.6888 - val_precision: 0.6859 - val_recall: 0.7405\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.4937 - accuracy: 0.7634 - precision: 0.7455 - recall: 0.8218 - val_loss: 0.6184 - val_accuracy: 0.6858 - val_precision: 0.6573 - val_recall: 0.8265\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.4832 - accuracy: 0.7720 - precision: 0.7577 - recall: 0.8205 - val_loss: 0.6051 - val_accuracy: 0.6910 - val_precision: 0.6802 - val_recall: 0.7657\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.4655 - accuracy: 0.7874 - precision: 0.7762 - recall: 0.8260 - val_loss: 0.6293 - val_accuracy: 0.6785 - val_precision: 0.6665 - val_recall: 0.7640\n",
            "Epoch 17/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.4531 - accuracy: 0.7920 - precision: 0.7818 - recall: 0.8278 - val_loss: 0.6396 - val_accuracy: 0.6899 - val_precision: 0.7189 - val_recall: 0.6625\n",
            "Epoch 18/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.4420 - accuracy: 0.8019 - precision: 0.7937 - recall: 0.8321 - val_loss: 0.6343 - val_accuracy: 0.6856 - val_precision: 0.6998 - val_recall: 0.6923\n",
            "Epoch 19/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.4217 - accuracy: 0.8165 - precision: 0.8119 - recall: 0.8386 - val_loss: 0.6510 - val_accuracy: 0.6820 - val_precision: 0.7036 - val_recall: 0.6711\n",
            "Accuracy  :  0.6852650046348572\n",
            "Precision :  0.6602835655212402\n",
            "Recall    :  0.8071123361587524\n",
            "F1- Score :  0.7263520505746892\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 6s 16ms/step - loss: 0.5354 - accuracy: 0.7366 - precision_1: 0.7155 - recall_1: 0.8124 - val_loss: 0.6035 - val_accuracy: 0.6825 - val_precision_1: 0.7119 - val_recall_1: 0.6541\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.5226 - accuracy: 0.7446 - precision_1: 0.7273 - recall_1: 0.8078 - val_loss: 0.6030 - val_accuracy: 0.6876 - val_precision_1: 0.6966 - val_recall_1: 0.7072\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.5092 - accuracy: 0.7557 - precision_1: 0.7366 - recall_1: 0.8195 - val_loss: 0.6085 - val_accuracy: 0.6843 - val_precision_1: 0.6814 - val_recall_1: 0.7376\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4981 - accuracy: 0.7638 - precision_1: 0.7492 - recall_1: 0.8147 - val_loss: 0.6273 - val_accuracy: 0.6900 - val_precision_1: 0.7072 - val_recall_1: 0.6889\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4832 - accuracy: 0.7758 - precision_1: 0.7629 - recall_1: 0.8203 - val_loss: 0.6248 - val_accuracy: 0.6808 - val_precision_1: 0.7116 - val_recall_1: 0.6491\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 3s 13ms/step - loss: 0.4716 - accuracy: 0.7850 - precision_1: 0.7752 - recall_1: 0.8213 - val_loss: 0.6150 - val_accuracy: 0.6876 - val_precision_1: 0.6846 - val_recall_1: 0.7403\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.4553 - accuracy: 0.7957 - precision_1: 0.7877 - recall_1: 0.8267 - val_loss: 0.6265 - val_accuracy: 0.6898 - val_precision_1: 0.6913 - val_recall_1: 0.7285\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.4440 - accuracy: 0.8043 - precision_1: 0.7950 - recall_1: 0.8363 - val_loss: 0.6368 - val_accuracy: 0.6844 - val_precision_1: 0.6751 - val_recall_1: 0.7576\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4269 - accuracy: 0.8164 - precision_1: 0.8109 - recall_1: 0.8398 - val_loss: 0.6357 - val_accuracy: 0.6870 - val_precision_1: 0.6931 - val_recall_1: 0.7144\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4089 - accuracy: 0.8280 - precision_1: 0.8218 - recall_1: 0.8511 - val_loss: 0.6953 - val_accuracy: 0.6883 - val_precision_1: 0.7084 - val_recall_1: 0.6805\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.3938 - accuracy: 0.8371 - precision_1: 0.8324 - recall_1: 0.8566 - val_loss: 0.6892 - val_accuracy: 0.6816 - val_precision_1: 0.6841 - val_recall_1: 0.7204\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 4s 14ms/step - loss: 0.3820 - accuracy: 0.8457 - precision_1: 0.8412 - recall_1: 0.8640 - val_loss: 0.6945 - val_accuracy: 0.6798 - val_precision_1: 0.6884 - val_recall_1: 0.7016\n",
            "Accuracy  :  0.6870704889297485\n",
            "Precision :  0.6919462084770203\n",
            "Recall    :  0.7125815749168396\n",
            "F1- Score :  0.7021123039700298\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 4s 17ms/step - loss: 0.5005 - accuracy: 0.7617 - precision_2: 0.7418 - recall_2: 0.8253 - val_loss: 0.6065 - val_accuracy: 0.6841 - val_precision_2: 0.7036 - val_recall_2: 0.6781\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.4840 - accuracy: 0.7771 - precision_2: 0.7654 - recall_2: 0.8188 - val_loss: 0.6188 - val_accuracy: 0.6875 - val_precision_2: 0.6733 - val_recall_2: 0.7748\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.4733 - accuracy: 0.7847 - precision_2: 0.7792 - recall_2: 0.8129 - val_loss: 0.6254 - val_accuracy: 0.6833 - val_precision_2: 0.6840 - val_recall_2: 0.7264\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 2s 18ms/step - loss: 0.4599 - accuracy: 0.7947 - precision_2: 0.7924 - recall_2: 0.8156 - val_loss: 0.6449 - val_accuracy: 0.6879 - val_precision_2: 0.7149 - val_recall_2: 0.6647\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 0.4476 - accuracy: 0.8036 - precision_2: 0.8029 - recall_2: 0.8209 - val_loss: 0.6378 - val_accuracy: 0.6737 - val_precision_2: 0.6832 - val_recall_2: 0.6942\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4386 - accuracy: 0.8111 - precision_2: 0.8117 - recall_2: 0.8252 - val_loss: 0.6451 - val_accuracy: 0.6791 - val_precision_2: 0.6756 - val_recall_2: 0.7364\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4188 - accuracy: 0.8237 - precision_2: 0.8222 - recall_2: 0.8398 - val_loss: 0.6444 - val_accuracy: 0.6775 - val_precision_2: 0.6745 - val_recall_2: 0.7338\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.4032 - accuracy: 0.8349 - precision_2: 0.8323 - recall_2: 0.8515 - val_loss: 0.6747 - val_accuracy: 0.6914 - val_precision_2: 0.6969 - val_recall_2: 0.7192\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.3905 - accuracy: 0.8432 - precision_2: 0.8436 - recall_2: 0.8545 - val_loss: 0.6939 - val_accuracy: 0.6859 - val_precision_2: 0.7014 - val_recall_2: 0.6892\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.3864 - accuracy: 0.8449 - precision_2: 0.8448 - recall_2: 0.8566 - val_loss: 0.6923 - val_accuracy: 0.6853 - val_precision_2: 0.6928 - val_recall_2: 0.7091\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.3653 - accuracy: 0.8568 - precision_2: 0.8540 - recall_2: 0.8712 - val_loss: 0.7047 - val_accuracy: 0.6808 - val_precision_2: 0.7017 - val_recall_2: 0.6714\n",
            "Accuracy  :  0.6763541102409363\n",
            "Precision :  0.6931646466255188\n",
            "Recall    :  0.6721809506416321\n",
            "F1- Score :  0.6825115517309503\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 4s 27ms/step - loss: 0.4822 - accuracy: 0.7767 - precision_3: 0.7638 - recall_3: 0.8210 - val_loss: 0.6330 - val_accuracy: 0.6856 - val_precision_3: 0.6617 - val_recall_3: 0.8089\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.4670 - accuracy: 0.7885 - precision_3: 0.7807 - recall_3: 0.8205 - val_loss: 0.6270 - val_accuracy: 0.6861 - val_precision_3: 0.6861 - val_recall_3: 0.7304\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.4534 - accuracy: 0.7997 - precision_3: 0.7965 - recall_3: 0.8215 - val_loss: 0.6363 - val_accuracy: 0.6920 - val_precision_3: 0.6908 - val_recall_3: 0.7379\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.4410 - accuracy: 0.8097 - precision_3: 0.8054 - recall_3: 0.8321 - val_loss: 0.6369 - val_accuracy: 0.6878 - val_precision_3: 0.6970 - val_recall_3: 0.7067\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.4246 - accuracy: 0.8198 - precision_3: 0.8170 - recall_3: 0.8386 - val_loss: 0.6610 - val_accuracy: 0.6843 - val_precision_3: 0.6811 - val_recall_3: 0.7386\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.4144 - accuracy: 0.8294 - precision_3: 0.8234 - recall_3: 0.8522 - val_loss: 0.6644 - val_accuracy: 0.6799 - val_precision_3: 0.7091 - val_recall_3: 0.6517\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3992 - accuracy: 0.8397 - precision_3: 0.8371 - recall_3: 0.8559 - val_loss: 0.6824 - val_accuracy: 0.6871 - val_precision_3: 0.6759 - val_recall_3: 0.7650\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3915 - accuracy: 0.8444 - precision_3: 0.8397 - recall_3: 0.8631 - val_loss: 0.6904 - val_accuracy: 0.6814 - val_precision_3: 0.6893 - val_recall_3: 0.7050\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 27ms/step - loss: 0.3797 - accuracy: 0.8500 - precision_3: 0.8456 - recall_3: 0.8676 - val_loss: 0.6873 - val_accuracy: 0.6854 - val_precision_3: 0.7010 - val_recall_3: 0.6887\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3725 - accuracy: 0.8551 - precision_3: 0.8531 - recall_3: 0.8686 - val_loss: 0.7031 - val_accuracy: 0.6894 - val_precision_3: 0.6881 - val_recall_3: 0.7362\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3607 - accuracy: 0.8638 - precision_3: 0.8622 - recall_3: 0.8759 - val_loss: 0.7132 - val_accuracy: 0.6779 - val_precision_3: 0.6830 - val_recall_3: 0.7100\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3536 - accuracy: 0.8665 - precision_3: 0.8628 - recall_3: 0.8813 - val_loss: 0.7281 - val_accuracy: 0.6883 - val_precision_3: 0.6800 - val_recall_3: 0.7564\n",
            "Accuracy  :  0.677751898765564\n",
            "Precision :  0.6770514249801636\n",
            "Recall    :  0.7214719653129578\n",
            "F1- Score :  0.6985562423750329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [64, 128, 256, 512]\n",
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adadelta\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBqL3yzKTi-n",
        "outputId": "b0dba654-6ed0-4ade-d987-480d93361def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 12s 18ms/step - loss: 0.4499 - accuracy: 0.8033 - precision_4: 0.7928 - recall_4: 0.8377 - val_loss: 0.6273 - val_accuracy: 0.6858 - val_precision_4: 0.6882 - val_recall_4: 0.7232\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.4480 - accuracy: 0.8052 - precision_4: 0.7973 - recall_4: 0.8346 - val_loss: 0.6278 - val_accuracy: 0.6858 - val_precision_4: 0.6899 - val_recall_4: 0.7187\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 6s 11ms/step - loss: 0.4465 - accuracy: 0.8066 - precision_4: 0.7996 - recall_4: 0.8343 - val_loss: 0.6283 - val_accuracy: 0.6856 - val_precision_4: 0.6901 - val_recall_4: 0.7175\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.4454 - accuracy: 0.8075 - precision_4: 0.8006 - recall_4: 0.8348 - val_loss: 0.6288 - val_accuracy: 0.6865 - val_precision_4: 0.6909 - val_recall_4: 0.7184\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.4444 - accuracy: 0.8078 - precision_4: 0.8007 - recall_4: 0.8353 - val_loss: 0.6292 - val_accuracy: 0.6873 - val_precision_4: 0.6917 - val_recall_4: 0.7189\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.4435 - accuracy: 0.8080 - precision_4: 0.7998 - recall_4: 0.8373 - val_loss: 0.6296 - val_accuracy: 0.6873 - val_precision_4: 0.6920 - val_recall_4: 0.7182\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.4428 - accuracy: 0.8081 - precision_4: 0.8010 - recall_4: 0.8357 - val_loss: 0.6300 - val_accuracy: 0.6885 - val_precision_4: 0.6928 - val_recall_4: 0.7204\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.4422 - accuracy: 0.8088 - precision_4: 0.8013 - recall_4: 0.8369 - val_loss: 0.6303 - val_accuracy: 0.6881 - val_precision_4: 0.6922 - val_recall_4: 0.7206\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 6s 11ms/step - loss: 0.4417 - accuracy: 0.8087 - precision_4: 0.8005 - recall_4: 0.8381 - val_loss: 0.6307 - val_accuracy: 0.6890 - val_precision_4: 0.6932 - val_recall_4: 0.7208\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.4412 - accuracy: 0.8092 - precision_4: 0.8013 - recall_4: 0.8380 - val_loss: 0.6311 - val_accuracy: 0.6883 - val_precision_4: 0.6927 - val_recall_4: 0.7196\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.4408 - accuracy: 0.8093 - precision_4: 0.8014 - recall_4: 0.8380 - val_loss: 0.6314 - val_accuracy: 0.6884 - val_precision_4: 0.6929 - val_recall_4: 0.7194\n",
            "Accuracy  :  0.6776936650276184\n",
            "Precision :  0.6800601482391357\n",
            "Recall    :  0.7123565077781677\n",
            "F1- Score :  0.6958337796164852\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 7s 15ms/step - loss: 0.4480 - accuracy: 0.8054 - precision_5: 0.7977 - recall_5: 0.8344 - val_loss: 0.6277 - val_accuracy: 0.6856 - val_precision_5: 0.6894 - val_recall_5: 0.7196\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 4s 18ms/step - loss: 0.4469 - accuracy: 0.8062 - precision_5: 0.7994 - recall_5: 0.8336 - val_loss: 0.6280 - val_accuracy: 0.6864 - val_precision_5: 0.6907 - val_recall_5: 0.7184\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 3s 13ms/step - loss: 0.4459 - accuracy: 0.8071 - precision_5: 0.7997 - recall_5: 0.8353 - val_loss: 0.6283 - val_accuracy: 0.6861 - val_precision_5: 0.6904 - val_recall_5: 0.7184\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.4451 - accuracy: 0.8075 - precision_5: 0.8002 - recall_5: 0.8353 - val_loss: 0.6286 - val_accuracy: 0.6865 - val_precision_5: 0.6910 - val_recall_5: 0.7182\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4443 - accuracy: 0.8081 - precision_5: 0.8013 - recall_5: 0.8350 - val_loss: 0.6289 - val_accuracy: 0.6874 - val_precision_5: 0.6919 - val_recall_5: 0.7187\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4437 - accuracy: 0.8084 - precision_5: 0.8008 - recall_5: 0.8367 - val_loss: 0.6292 - val_accuracy: 0.6879 - val_precision_5: 0.6924 - val_recall_5: 0.7192\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.4431 - accuracy: 0.8083 - precision_5: 0.8009 - recall_5: 0.8363 - val_loss: 0.6295 - val_accuracy: 0.6883 - val_precision_5: 0.6924 - val_recall_5: 0.7204\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.4426 - accuracy: 0.8087 - precision_5: 0.8010 - recall_5: 0.8371 - val_loss: 0.6297 - val_accuracy: 0.6888 - val_precision_5: 0.6928 - val_recall_5: 0.7211\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.4422 - accuracy: 0.8087 - precision_5: 0.8012 - recall_5: 0.8369 - val_loss: 0.6300 - val_accuracy: 0.6889 - val_precision_5: 0.6931 - val_recall_5: 0.7208\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 3s 11ms/step - loss: 0.4418 - accuracy: 0.8090 - precision_5: 0.8010 - recall_5: 0.8380 - val_loss: 0.6303 - val_accuracy: 0.6889 - val_precision_5: 0.6931 - val_recall_5: 0.7206\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.4414 - accuracy: 0.8089 - precision_5: 0.8010 - recall_5: 0.8376 - val_loss: 0.6305 - val_accuracy: 0.6888 - val_precision_5: 0.6930 - val_recall_5: 0.7206\n",
            "Accuracy  :  0.6778683662414551\n",
            "Precision :  0.6815672516822815\n",
            "Recall    :  0.7086427807807922\n",
            "F1- Score :  0.694841356691307\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 4s 17ms/step - loss: 0.4469 - accuracy: 0.8064 - precision_6: 0.7992 - recall_6: 0.8343 - val_loss: 0.6278 - val_accuracy: 0.6865 - val_precision_6: 0.6907 - val_recall_6: 0.7189\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4461 - accuracy: 0.8071 - precision_6: 0.7998 - recall_6: 0.8349 - val_loss: 0.6280 - val_accuracy: 0.6858 - val_precision_6: 0.6900 - val_recall_6: 0.7182\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.4454 - accuracy: 0.8074 - precision_6: 0.8002 - recall_6: 0.8353 - val_loss: 0.6282 - val_accuracy: 0.6861 - val_precision_6: 0.6904 - val_recall_6: 0.7184\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 3s 20ms/step - loss: 0.4448 - accuracy: 0.8075 - precision_6: 0.8004 - recall_6: 0.8350 - val_loss: 0.6284 - val_accuracy: 0.6866 - val_precision_6: 0.6908 - val_recall_6: 0.7192\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4443 - accuracy: 0.8079 - precision_6: 0.8010 - recall_6: 0.8352 - val_loss: 0.6286 - val_accuracy: 0.6875 - val_precision_6: 0.6919 - val_recall_6: 0.7192\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4438 - accuracy: 0.8081 - precision_6: 0.8005 - recall_6: 0.8365 - val_loss: 0.6288 - val_accuracy: 0.6878 - val_precision_6: 0.6923 - val_recall_6: 0.7189\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.4434 - accuracy: 0.8081 - precision_6: 0.8005 - recall_6: 0.8365 - val_loss: 0.6290 - val_accuracy: 0.6881 - val_precision_6: 0.6925 - val_recall_6: 0.7196\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4430 - accuracy: 0.8081 - precision_6: 0.8005 - recall_6: 0.8364 - val_loss: 0.6292 - val_accuracy: 0.6884 - val_precision_6: 0.6927 - val_recall_6: 0.7201\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 2s 14ms/step - loss: 0.4426 - accuracy: 0.8082 - precision_6: 0.8008 - recall_6: 0.8363 - val_loss: 0.6294 - val_accuracy: 0.6888 - val_precision_6: 0.6930 - val_recall_6: 0.7206\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4423 - accuracy: 0.8085 - precision_6: 0.8011 - recall_6: 0.8364 - val_loss: 0.6296 - val_accuracy: 0.6890 - val_precision_6: 0.6933 - val_recall_6: 0.7206\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 3s 21ms/step - loss: 0.4420 - accuracy: 0.8088 - precision_6: 0.8010 - recall_6: 0.8372 - val_loss: 0.6298 - val_accuracy: 0.6894 - val_precision_6: 0.6936 - val_recall_6: 0.7211\n",
            "Accuracy  :  0.6776354312896729\n",
            "Precision :  0.6814293265342712\n",
            "Recall    :  0.7081926465034485\n",
            "F1- Score :  0.6945532634439264\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 4s 42ms/step - loss: 0.4462 - accuracy: 0.8069 - precision_7: 0.7996 - recall_7: 0.8350 - val_loss: 0.6280 - val_accuracy: 0.6860 - val_precision_7: 0.6904 - val_recall_7: 0.7180\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.4457 - accuracy: 0.8072 - precision_7: 0.8002 - recall_7: 0.8347 - val_loss: 0.6281 - val_accuracy: 0.6856 - val_precision_7: 0.6901 - val_recall_7: 0.7175\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4453 - accuracy: 0.8072 - precision_7: 0.8000 - recall_7: 0.8350 - val_loss: 0.6283 - val_accuracy: 0.6860 - val_precision_7: 0.6907 - val_recall_7: 0.7172\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4449 - accuracy: 0.8077 - precision_7: 0.8010 - recall_7: 0.8346 - val_loss: 0.6284 - val_accuracy: 0.6860 - val_precision_7: 0.6906 - val_recall_7: 0.7175\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4445 - accuracy: 0.8077 - precision_7: 0.8008 - recall_7: 0.8349 - val_loss: 0.6286 - val_accuracy: 0.6869 - val_precision_7: 0.6917 - val_recall_7: 0.7175\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4442 - accuracy: 0.8080 - precision_7: 0.8009 - recall_7: 0.8355 - val_loss: 0.6287 - val_accuracy: 0.6873 - val_precision_7: 0.6922 - val_recall_7: 0.7175\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.4438 - accuracy: 0.8080 - precision_7: 0.8009 - recall_7: 0.8357 - val_loss: 0.6288 - val_accuracy: 0.6874 - val_precision_7: 0.6924 - val_recall_7: 0.7175\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4435 - accuracy: 0.8079 - precision_7: 0.8010 - recall_7: 0.8352 - val_loss: 0.6289 - val_accuracy: 0.6876 - val_precision_7: 0.6924 - val_recall_7: 0.7182\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 19ms/step - loss: 0.4432 - accuracy: 0.8084 - precision_7: 0.8011 - recall_7: 0.8361 - val_loss: 0.6290 - val_accuracy: 0.6880 - val_precision_7: 0.6926 - val_recall_7: 0.7192\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.4430 - accuracy: 0.8082 - precision_7: 0.8008 - recall_7: 0.8363 - val_loss: 0.6292 - val_accuracy: 0.6880 - val_precision_7: 0.6924 - val_recall_7: 0.7196\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4427 - accuracy: 0.8084 - precision_7: 0.8009 - recall_7: 0.8366 - val_loss: 0.6293 - val_accuracy: 0.6881 - val_precision_7: 0.6925 - val_recall_7: 0.7196\n",
            "Accuracy  :  0.6774606704711914\n",
            "Precision :  0.6816012263298035\n",
            "Recall    :  0.7070673108100891\n",
            "F1- Score :  0.6941007637985007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batches = [64, 128, 256, 512]\n",
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"rmsprop\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLMZ_9S_W8Bq",
        "outputId": "961ddca0-3aa0-43c1-8594-6cf3941d259c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 8s 10ms/step - loss: 0.4938 - accuracy: 0.7690 - precision_8: 0.7624 - recall_8: 0.8022 - val_loss: 0.6118 - val_accuracy: 0.6846 - val_precision_8: 0.7186 - val_recall_8: 0.6467\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 4s 8ms/step - loss: 0.4841 - accuracy: 0.7780 - precision_8: 0.7721 - recall_8: 0.8083 - val_loss: 0.6181 - val_accuracy: 0.6783 - val_precision_8: 0.6564 - val_recall_8: 0.7998\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 5s 11ms/step - loss: 0.4754 - accuracy: 0.7856 - precision_8: 0.7763 - recall_8: 0.8210 - val_loss: 0.6437 - val_accuracy: 0.6794 - val_precision_8: 0.6504 - val_recall_8: 0.8289\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.4631 - accuracy: 0.7930 - precision_8: 0.7845 - recall_8: 0.8254 - val_loss: 0.6385 - val_accuracy: 0.6906 - val_precision_8: 0.7312 - val_recall_8: 0.6404\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.4534 - accuracy: 0.7992 - precision_8: 0.7961 - recall_8: 0.8211 - val_loss: 0.6260 - val_accuracy: 0.6905 - val_precision_8: 0.6999 - val_recall_8: 0.7086\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 5s 10ms/step - loss: 0.4416 - accuracy: 0.8075 - precision_8: 0.8054 - recall_8: 0.8265 - val_loss: 0.6428 - val_accuracy: 0.6927 - val_precision_8: 0.7069 - val_recall_8: 0.6988\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 4s 7ms/step - loss: 0.4320 - accuracy: 0.8161 - precision_8: 0.8108 - recall_8: 0.8394 - val_loss: 0.6484 - val_accuracy: 0.6762 - val_precision_8: 0.6798 - val_recall_8: 0.7129\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 0.4204 - accuracy: 0.8219 - precision_8: 0.8169 - recall_8: 0.8438 - val_loss: 0.6460 - val_accuracy: 0.6788 - val_precision_8: 0.6823 - val_recall_8: 0.7151\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 5s 9ms/step - loss: 0.4102 - accuracy: 0.8304 - precision_8: 0.8242 - recall_8: 0.8530 - val_loss: 0.6965 - val_accuracy: 0.6760 - val_precision_8: 0.7306 - val_recall_8: 0.5970\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 4s 9ms/step - loss: 0.4036 - accuracy: 0.8316 - precision_8: 0.8226 - recall_8: 0.8586 - val_loss: 0.6607 - val_accuracy: 0.6924 - val_precision_8: 0.7053 - val_recall_8: 0.7014\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 3s 7ms/step - loss: 0.3915 - accuracy: 0.8392 - precision_8: 0.8309 - recall_8: 0.8643 - val_loss: 0.6683 - val_accuracy: 0.6955 - val_precision_8: 0.6938 - val_recall_8: 0.7417\n",
            "Accuracy  :  0.6762376427650452\n",
            "Precision :  0.7071348428726196\n",
            "Recall    :  0.6390951871871948\n",
            "F1- Score :  0.6713956228597647\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 5s 16ms/step - loss: 0.4736 - accuracy: 0.7831 - precision_9: 0.7787 - recall_9: 0.8097 - val_loss: 0.6367 - val_accuracy: 0.6836 - val_precision_9: 0.7142 - val_recall_9: 0.6527\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 2s 10ms/step - loss: 0.4581 - accuracy: 0.7958 - precision_9: 0.7911 - recall_9: 0.8207 - val_loss: 0.6547 - val_accuracy: 0.6905 - val_precision_9: 0.6775 - val_recall_9: 0.7722\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4504 - accuracy: 0.8032 - precision_9: 0.8044 - recall_9: 0.8173 - val_loss: 0.6516 - val_accuracy: 0.6745 - val_precision_9: 0.6699 - val_recall_9: 0.7374\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 3s 13ms/step - loss: 0.4388 - accuracy: 0.8109 - precision_9: 0.8100 - recall_9: 0.8275 - val_loss: 0.6627 - val_accuracy: 0.6900 - val_precision_9: 0.7172 - val_recall_9: 0.6666\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 3s 12ms/step - loss: 0.4285 - accuracy: 0.8143 - precision_9: 0.8117 - recall_9: 0.8334 - val_loss: 0.7086 - val_accuracy: 0.6612 - val_precision_9: 0.6265 - val_recall_9: 0.8627\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 3s 14ms/step - loss: 0.4193 - accuracy: 0.8218 - precision_9: 0.8175 - recall_9: 0.8427 - val_loss: 0.6753 - val_accuracy: 0.6784 - val_precision_9: 0.7230 - val_recall_9: 0.6183\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 3s 10ms/step - loss: 0.4070 - accuracy: 0.8309 - precision_9: 0.8292 - recall_9: 0.8467 - val_loss: 0.6859 - val_accuracy: 0.6932 - val_precision_9: 0.7071 - val_recall_9: 0.7000\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.4001 - accuracy: 0.8346 - precision_9: 0.8303 - recall_9: 0.8539 - val_loss: 0.6744 - val_accuracy: 0.6754 - val_precision_9: 0.6745 - val_recall_9: 0.7261\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.3880 - accuracy: 0.8431 - precision_9: 0.8396 - recall_9: 0.8602 - val_loss: 0.6857 - val_accuracy: 0.6901 - val_precision_9: 0.7167 - val_recall_9: 0.6680\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 2s 9ms/step - loss: 0.3781 - accuracy: 0.8475 - precision_9: 0.8430 - recall_9: 0.8655 - val_loss: 0.7293 - val_accuracy: 0.6779 - val_precision_9: 0.6560 - val_recall_9: 0.7998\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 4s 14ms/step - loss: 0.3692 - accuracy: 0.8517 - precision_9: 0.8485 - recall_9: 0.8673 - val_loss: 0.7219 - val_accuracy: 0.6732 - val_precision_9: 0.7397 - val_recall_9: 0.5730\n",
            "Accuracy  :  0.6785672903060913\n",
            "Precision :  0.7048302888870239\n",
            "Recall    :  0.6519243717193604\n",
            "F1- Score :  0.677345811432234\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 4s 16ms/step - loss: 0.4567 - accuracy: 0.7940 - precision_10: 0.7896 - recall_10: 0.8188 - val_loss: 0.6558 - val_accuracy: 0.6960 - val_precision_10: 0.7042 - val_recall_10: 0.7160\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.4405 - accuracy: 0.8095 - precision_10: 0.8065 - recall_10: 0.8298 - val_loss: 0.6631 - val_accuracy: 0.6833 - val_precision_10: 0.6828 - val_recall_10: 0.7300\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 1s 12ms/step - loss: 0.4296 - accuracy: 0.8157 - precision_10: 0.8131 - recall_10: 0.8345 - val_loss: 0.6548 - val_accuracy: 0.6855 - val_precision_10: 0.6990 - val_recall_10: 0.6940\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.4213 - accuracy: 0.8208 - precision_10: 0.8205 - recall_10: 0.8352 - val_loss: 0.6734 - val_accuracy: 0.6839 - val_precision_10: 0.7145 - val_recall_10: 0.6529\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.4097 - accuracy: 0.8298 - precision_10: 0.8297 - recall_10: 0.8432 - val_loss: 0.6838 - val_accuracy: 0.7006 - val_precision_10: 0.7057 - val_recall_10: 0.7276\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.4035 - accuracy: 0.8341 - precision_10: 0.8311 - recall_10: 0.8514 - val_loss: 0.6739 - val_accuracy: 0.6778 - val_precision_10: 0.7081 - val_recall_10: 0.6469\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 2s 19ms/step - loss: 0.3947 - accuracy: 0.8381 - precision_10: 0.8354 - recall_10: 0.8546 - val_loss: 0.7037 - val_accuracy: 0.6960 - val_precision_10: 0.7138 - val_recall_10: 0.6932\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.3859 - accuracy: 0.8420 - precision_10: 0.8405 - recall_10: 0.8562 - val_loss: 0.7029 - val_accuracy: 0.6712 - val_precision_10: 0.7026 - val_recall_10: 0.6373\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 1s 11ms/step - loss: 0.3788 - accuracy: 0.8487 - precision_10: 0.8450 - recall_10: 0.8654 - val_loss: 0.7194 - val_accuracy: 0.6889 - val_precision_10: 0.7023 - val_recall_10: 0.6971\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.3708 - accuracy: 0.8521 - precision_10: 0.8504 - recall_10: 0.8655 - val_loss: 0.6953 - val_accuracy: 0.6906 - val_precision_10: 0.6871 - val_recall_10: 0.7436\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.3625 - accuracy: 0.8577 - precision_10: 0.8561 - recall_10: 0.8705 - val_loss: 0.7079 - val_accuracy: 0.6611 - val_precision_10: 0.6931 - val_recall_10: 0.6246\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 2s 12ms/step - loss: 0.3495 - accuracy: 0.8657 - precision_10: 0.8608 - recall_10: 0.8823 - val_loss: 0.7338 - val_accuracy: 0.6903 - val_precision_10: 0.6833 - val_recall_10: 0.7535\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 2s 13ms/step - loss: 0.3476 - accuracy: 0.8655 - precision_10: 0.8620 - recall_10: 0.8802 - val_loss: 0.7164 - val_accuracy: 0.6784 - val_precision_10: 0.7037 - val_recall_10: 0.6589\n",
            "Accuracy  :  0.6812463402748108\n",
            "Precision :  0.6895479559898376\n",
            "Recall    :  0.6986270546913147\n",
            "F1- Score :  0.694057815268144\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 3s 27ms/step - loss: 0.4327 - accuracy: 0.8146 - precision_11: 0.8105 - recall_11: 0.8362 - val_loss: 0.6684 - val_accuracy: 0.6757 - val_precision_11: 0.7266 - val_recall_11: 0.6030\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.4113 - accuracy: 0.8259 - precision_11: 0.8242 - recall_11: 0.8420 - val_loss: 0.6955 - val_accuracy: 0.6710 - val_precision_11: 0.7404 - val_recall_11: 0.5655\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.4028 - accuracy: 0.8338 - precision_11: 0.8322 - recall_11: 0.8490 - val_loss: 0.7054 - val_accuracy: 0.6689 - val_precision_11: 0.6333 - val_recall_11: 0.8627\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.3955 - accuracy: 0.8379 - precision_11: 0.8341 - recall_11: 0.8560 - val_loss: 0.6752 - val_accuracy: 0.6874 - val_precision_11: 0.6907 - val_recall_11: 0.7220\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.3890 - accuracy: 0.8418 - precision_11: 0.8398 - recall_11: 0.8569 - val_loss: 0.6837 - val_accuracy: 0.6811 - val_precision_11: 0.6758 - val_recall_11: 0.7432\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3816 - accuracy: 0.8485 - precision_11: 0.8470 - recall_11: 0.8618 - val_loss: 0.6902 - val_accuracy: 0.6800 - val_precision_11: 0.7159 - val_recall_11: 0.6375\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3753 - accuracy: 0.8520 - precision_11: 0.8519 - recall_11: 0.8632 - val_loss: 0.7168 - val_accuracy: 0.6699 - val_precision_11: 0.6422 - val_recall_11: 0.8245\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3691 - accuracy: 0.8546 - precision_11: 0.8512 - recall_11: 0.8703 - val_loss: 0.7175 - val_accuracy: 0.6880 - val_precision_11: 0.7052 - val_recall_11: 0.6872\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 1s 17ms/step - loss: 0.3660 - accuracy: 0.8555 - precision_11: 0.8520 - recall_11: 0.8712 - val_loss: 0.7408 - val_accuracy: 0.6739 - val_precision_11: 0.7388 - val_recall_11: 0.5766\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 1s 18ms/step - loss: 0.3523 - accuracy: 0.8649 - precision_11: 0.8642 - recall_11: 0.8756 - val_loss: 0.7382 - val_accuracy: 0.6813 - val_precision_11: 0.7100 - val_recall_11: 0.6541\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.3497 - accuracy: 0.8662 - precision_11: 0.8649 - recall_11: 0.8777 - val_loss: 0.7336 - val_accuracy: 0.6839 - val_precision_11: 0.7019 - val_recall_11: 0.6815\n",
            "Accuracy  :  0.6661618947982788\n",
            "Precision :  0.7090402841567993\n",
            "Recall    :  0.601958155632019\n",
            "F1- Score :  0.651125994915116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM**"
      ],
      "metadata": {
        "id": "-ydlRbpEZgPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing the data and creating model\n",
        "batches = [64, 128, 256, 512]\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = split_data(x.values, y.values)\n",
        "model = create_model(x_train)"
      ],
      "metadata": {
        "id": "w-6VoWRhX3bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model and evaluating scores with different batch size and optimizers and iterations"
      ],
      "metadata": {
        "id": "HtZPfdh8tINm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adam\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-LCCdfYZiN3",
        "outputId": "a14c3605-871d-41bb-9c52-33a5419b16e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 18s 18ms/step - loss: 0.6744 - accuracy: 0.5867 - precision_12: 0.5767 - recall_12: 0.7472 - val_loss: 0.6178 - val_accuracy: 0.6699 - val_precision_12: 0.6716 - val_recall_12: 0.7144\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.6196 - accuracy: 0.6731 - precision_12: 0.6686 - recall_12: 0.7261 - val_loss: 0.6072 - val_accuracy: 0.6759 - val_precision_12: 0.6842 - val_recall_12: 0.6995\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.6111 - accuracy: 0.6770 - precision_12: 0.6669 - recall_12: 0.7469 - val_loss: 0.6099 - val_accuracy: 0.6714 - val_precision_12: 0.7149 - val_recall_12: 0.6121\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.6041 - accuracy: 0.6814 - precision_12: 0.6719 - recall_12: 0.7471 - val_loss: 0.6018 - val_accuracy: 0.6825 - val_precision_12: 0.6877 - val_recall_12: 0.7132\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.6028 - accuracy: 0.6804 - precision_12: 0.6675 - recall_12: 0.7581 - val_loss: 0.6023 - val_accuracy: 0.6789 - val_precision_12: 0.6876 - val_recall_12: 0.7007\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.5977 - accuracy: 0.6851 - precision_12: 0.6715 - recall_12: 0.7627 - val_loss: 0.6011 - val_accuracy: 0.6816 - val_precision_12: 0.6868 - val_recall_12: 0.7127\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5958 - accuracy: 0.6855 - precision_12: 0.6713 - recall_12: 0.7648 - val_loss: 0.6108 - val_accuracy: 0.6687 - val_precision_12: 0.6334 - val_recall_12: 0.8613\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5924 - accuracy: 0.6879 - precision_12: 0.6759 - recall_12: 0.7587 - val_loss: 0.5959 - val_accuracy: 0.6874 - val_precision_12: 0.6855 - val_recall_12: 0.7367\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.5878 - accuracy: 0.6958 - precision_12: 0.6854 - recall_12: 0.7583 - val_loss: 0.5953 - val_accuracy: 0.6881 - val_precision_12: 0.6899 - val_recall_12: 0.7268\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5813 - accuracy: 0.7008 - precision_12: 0.6874 - recall_12: 0.7703 - val_loss: 0.5924 - val_accuracy: 0.6871 - val_precision_12: 0.6942 - val_recall_12: 0.7117\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5765 - accuracy: 0.7051 - precision_12: 0.6989 - recall_12: 0.7524 - val_loss: 0.5927 - val_accuracy: 0.6881 - val_precision_12: 0.6751 - val_recall_12: 0.7715\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5688 - accuracy: 0.7110 - precision_12: 0.7029 - recall_12: 0.7617 - val_loss: 0.5930 - val_accuracy: 0.6937 - val_precision_12: 0.7054 - val_recall_12: 0.7057\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 10s 19ms/step - loss: 0.5592 - accuracy: 0.7199 - precision_12: 0.7152 - recall_12: 0.7595 - val_loss: 0.5941 - val_accuracy: 0.6935 - val_precision_12: 0.6864 - val_recall_12: 0.7556\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5554 - accuracy: 0.7231 - precision_12: 0.7166 - recall_12: 0.7663 - val_loss: 0.5974 - val_accuracy: 0.6956 - val_precision_12: 0.7090 - val_recall_12: 0.7031\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 11s 21ms/step - loss: 0.5448 - accuracy: 0.7324 - precision_12: 0.7248 - recall_12: 0.7756 - val_loss: 0.5880 - val_accuracy: 0.6934 - val_precision_12: 0.7049 - val_recall_12: 0.7057\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5366 - accuracy: 0.7420 - precision_12: 0.7353 - recall_12: 0.7809 - val_loss: 0.5924 - val_accuracy: 0.6916 - val_precision_12: 0.6841 - val_recall_12: 0.7559\n",
            "Epoch 17/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.5224 - accuracy: 0.7517 - precision_12: 0.7491 - recall_12: 0.7799 - val_loss: 0.5871 - val_accuracy: 0.6910 - val_precision_12: 0.6833 - val_recall_12: 0.7561\n",
            "Epoch 18/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.5146 - accuracy: 0.7584 - precision_12: 0.7551 - recall_12: 0.7867 - val_loss: 0.5938 - val_accuracy: 0.6961 - val_precision_12: 0.7075 - val_recall_12: 0.7084\n",
            "Epoch 19/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.5036 - accuracy: 0.7667 - precision_12: 0.7641 - recall_12: 0.7923 - val_loss: 0.6141 - val_accuracy: 0.6788 - val_precision_12: 0.6517 - val_recall_12: 0.8207\n",
            "Epoch 20/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.4940 - accuracy: 0.7717 - precision_12: 0.7695 - recall_12: 0.7959 - val_loss: 0.6016 - val_accuracy: 0.6986 - val_precision_12: 0.7118 - val_recall_12: 0.7062\n",
            "Epoch 21/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.4807 - accuracy: 0.7827 - precision_12: 0.7796 - recall_12: 0.8067 - val_loss: 0.6207 - val_accuracy: 0.6899 - val_precision_12: 0.6915 - val_recall_12: 0.7285\n",
            "Epoch 22/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.4674 - accuracy: 0.7930 - precision_12: 0.7905 - recall_12: 0.8147 - val_loss: 0.6258 - val_accuracy: 0.6976 - val_precision_12: 0.7080 - val_recall_12: 0.7120\n",
            "Epoch 23/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.4570 - accuracy: 0.7973 - precision_12: 0.7956 - recall_12: 0.8170 - val_loss: 0.6294 - val_accuracy: 0.6977 - val_precision_12: 0.6868 - val_recall_12: 0.7696\n",
            "Epoch 24/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.4455 - accuracy: 0.8059 - precision_12: 0.8049 - recall_12: 0.8233 - val_loss: 0.6490 - val_accuracy: 0.6960 - val_precision_12: 0.7176 - val_recall_12: 0.6848\n",
            "Epoch 25/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.4329 - accuracy: 0.8164 - precision_12: 0.8126 - recall_12: 0.8372 - val_loss: 0.6345 - val_accuracy: 0.6969 - val_precision_12: 0.6921 - val_recall_12: 0.7511\n",
            "Epoch 26/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.4265 - accuracy: 0.8154 - precision_12: 0.8143 - recall_12: 0.8318 - val_loss: 0.6305 - val_accuracy: 0.6946 - val_precision_12: 0.7038 - val_recall_12: 0.7124\n",
            "Epoch 27/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.4071 - accuracy: 0.8267 - precision_12: 0.8217 - recall_12: 0.8480 - val_loss: 0.6393 - val_accuracy: 0.6946 - val_precision_12: 0.6973 - val_recall_12: 0.7292\n",
            "Accuracy  :  0.6910890936851501\n",
            "Precision :  0.6792792677879333\n",
            "Recall    :  0.7636731863021851\n",
            "F1- Score :  0.7190082547075086\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 14s 27ms/step - loss: 0.5054 - accuracy: 0.7648 - precision_13: 0.7615 - recall_13: 0.7922 - val_loss: 0.5964 - val_accuracy: 0.6908 - val_precision_13: 0.6876 - val_recall_13: 0.7427\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.4964 - accuracy: 0.7736 - precision_13: 0.7709 - recall_13: 0.7983 - val_loss: 0.6170 - val_accuracy: 0.6880 - val_precision_13: 0.6859 - val_recall_13: 0.7376\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 6s 25ms/step - loss: 0.4914 - accuracy: 0.7766 - precision_13: 0.7717 - recall_13: 0.8052 - val_loss: 0.6106 - val_accuracy: 0.6839 - val_precision_13: 0.6825 - val_recall_13: 0.7331\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.4831 - accuracy: 0.7814 - precision_13: 0.7766 - recall_13: 0.8089 - val_loss: 0.6168 - val_accuracy: 0.6954 - val_precision_13: 0.6894 - val_recall_13: 0.7537\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.4720 - accuracy: 0.7899 - precision_13: 0.7852 - recall_13: 0.8158 - val_loss: 0.6250 - val_accuracy: 0.6853 - val_precision_13: 0.7242 - val_recall_13: 0.6373\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 6s 23ms/step - loss: 0.4647 - accuracy: 0.7957 - precision_13: 0.7917 - recall_13: 0.8197 - val_loss: 0.6103 - val_accuracy: 0.6941 - val_precision_13: 0.7167 - val_recall_13: 0.6807\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.4541 - accuracy: 0.8004 - precision_13: 0.7974 - recall_13: 0.8218 - val_loss: 0.6447 - val_accuracy: 0.6995 - val_precision_13: 0.7014 - val_recall_13: 0.7348\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.4406 - accuracy: 0.8111 - precision_13: 0.8081 - recall_13: 0.8312 - val_loss: 0.6293 - val_accuracy: 0.6979 - val_precision_13: 0.7155 - val_recall_13: 0.6954\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 6s 25ms/step - loss: 0.4365 - accuracy: 0.8114 - precision_13: 0.8070 - recall_13: 0.8337 - val_loss: 0.6345 - val_accuracy: 0.7002 - val_precision_13: 0.7097 - val_recall_13: 0.7165\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.4277 - accuracy: 0.8198 - precision_13: 0.8170 - recall_13: 0.8384 - val_loss: 0.6339 - val_accuracy: 0.6990 - val_precision_13: 0.7065 - val_recall_13: 0.7201\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 4s 15ms/step - loss: 0.4177 - accuracy: 0.8258 - precision_13: 0.8204 - recall_13: 0.8479 - val_loss: 0.6692 - val_accuracy: 0.6964 - val_precision_13: 0.7248 - val_recall_13: 0.6707\n",
            "Accuracy  :  0.6884682774543762\n",
            "Precision :  0.6847769021987915\n",
            "Recall    :  0.7375646829605103\n",
            "F1- Score :  0.7101912283783289\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 12s 42ms/step - loss: 0.4945 - accuracy: 0.7751 - precision_14: 0.7701 - recall_14: 0.8040 - val_loss: 0.6092 - val_accuracy: 0.6916 - val_precision_14: 0.6785 - val_recall_14: 0.7732\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.4874 - accuracy: 0.7793 - precision_14: 0.7744 - recall_14: 0.8072 - val_loss: 0.6115 - val_accuracy: 0.6908 - val_precision_14: 0.7052 - val_recall_14: 0.6964\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4816 - accuracy: 0.7822 - precision_14: 0.7770 - recall_14: 0.8103 - val_loss: 0.6087 - val_accuracy: 0.6900 - val_precision_14: 0.6970 - val_recall_14: 0.7141\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4722 - accuracy: 0.7903 - precision_14: 0.7889 - recall_14: 0.8102 - val_loss: 0.6059 - val_accuracy: 0.6932 - val_precision_14: 0.7162 - val_recall_14: 0.6791\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4671 - accuracy: 0.7915 - precision_14: 0.7885 - recall_14: 0.8142 - val_loss: 0.6196 - val_accuracy: 0.6885 - val_precision_14: 0.6967 - val_recall_14: 0.7100\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.4604 - accuracy: 0.7969 - precision_14: 0.7941 - recall_14: 0.8184 - val_loss: 0.6208 - val_accuracy: 0.6891 - val_precision_14: 0.6945 - val_recall_14: 0.7177\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4517 - accuracy: 0.8042 - precision_14: 0.8008 - recall_14: 0.8257 - val_loss: 0.6155 - val_accuracy: 0.6940 - val_precision_14: 0.7022 - val_recall_14: 0.7144\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 3s 20ms/step - loss: 0.4446 - accuracy: 0.8082 - precision_14: 0.8040 - recall_14: 0.8306 - val_loss: 0.6411 - val_accuracy: 0.6971 - val_precision_14: 0.7207 - val_recall_14: 0.6815\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 3s 21ms/step - loss: 0.4349 - accuracy: 0.8148 - precision_14: 0.8106 - recall_14: 0.8364 - val_loss: 0.6437 - val_accuracy: 0.6989 - val_precision_14: 0.7032 - val_recall_14: 0.7280\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 3s 26ms/step - loss: 0.4311 - accuracy: 0.8152 - precision_14: 0.8111 - recall_14: 0.8366 - val_loss: 0.6500 - val_accuracy: 0.6880 - val_precision_14: 0.6649 - val_recall_14: 0.8063\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.4274 - accuracy: 0.8182 - precision_14: 0.8121 - recall_14: 0.8426 - val_loss: 0.6359 - val_accuracy: 0.6966 - val_precision_14: 0.7099 - val_recall_14: 0.7043\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 3s 21ms/step - loss: 0.4178 - accuracy: 0.8233 - precision_14: 0.8184 - recall_14: 0.8450 - val_loss: 0.6630 - val_accuracy: 0.6967 - val_precision_14: 0.7004 - val_recall_14: 0.7283\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.4091 - accuracy: 0.8284 - precision_14: 0.8247 - recall_14: 0.8475 - val_loss: 0.6806 - val_accuracy: 0.7021 - val_precision_14: 0.6923 - val_recall_14: 0.7686\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4063 - accuracy: 0.8311 - precision_14: 0.8283 - recall_14: 0.8485 - val_loss: 0.6589 - val_accuracy: 0.6996 - val_precision_14: 0.6945 - val_recall_14: 0.7537\n",
            "Accuracy  :  0.6902154684066772\n",
            "Precision :  0.7114404439926147\n",
            "Recall    :  0.6753320097923279\n",
            "F1- Score :  0.6929161357045343\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 11s 53ms/step - loss: 0.4636 - accuracy: 0.7967 - precision_15: 0.7930 - recall_15: 0.8198 - val_loss: 0.6202 - val_accuracy: 0.6931 - val_precision_15: 0.6915 - val_recall_15: 0.7398\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 0.4566 - accuracy: 0.8023 - precision_15: 0.8003 - recall_15: 0.8218 - val_loss: 0.6233 - val_accuracy: 0.6921 - val_precision_15: 0.6917 - val_recall_15: 0.7357\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 39ms/step - loss: 0.4515 - accuracy: 0.8031 - precision_15: 0.7993 - recall_15: 0.8255 - val_loss: 0.6181 - val_accuracy: 0.6901 - val_precision_15: 0.6989 - val_recall_15: 0.7098\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4444 - accuracy: 0.8093 - precision_15: 0.8081 - recall_15: 0.8266 - val_loss: 0.6392 - val_accuracy: 0.6939 - val_precision_15: 0.6949 - val_recall_15: 0.7331\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4374 - accuracy: 0.8112 - precision_15: 0.8070 - recall_15: 0.8332 - val_loss: 0.6246 - val_accuracy: 0.6950 - val_precision_15: 0.7028 - val_recall_15: 0.7163\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4321 - accuracy: 0.8150 - precision_15: 0.8113 - recall_15: 0.8356 - val_loss: 0.6338 - val_accuracy: 0.6937 - val_precision_15: 0.7040 - val_recall_15: 0.7091\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4301 - accuracy: 0.8173 - precision_15: 0.8126 - recall_15: 0.8395 - val_loss: 0.6447 - val_accuracy: 0.6975 - val_precision_15: 0.7045 - val_recall_15: 0.7204\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.4262 - accuracy: 0.8205 - precision_15: 0.8163 - recall_15: 0.8413 - val_loss: 0.6380 - val_accuracy: 0.6951 - val_precision_15: 0.7158 - val_recall_15: 0.6860\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 0.4217 - accuracy: 0.8244 - precision_15: 0.8202 - recall_15: 0.8447 - val_loss: 0.6460 - val_accuracy: 0.6939 - val_precision_15: 0.7069 - val_recall_15: 0.7024\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4140 - accuracy: 0.8289 - precision_15: 0.8279 - recall_15: 0.8436 - val_loss: 0.6602 - val_accuracy: 0.6959 - val_precision_15: 0.7030 - val_recall_15: 0.7187\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4063 - accuracy: 0.8331 - precision_15: 0.8275 - recall_15: 0.8546 - val_loss: 0.6563 - val_accuracy: 0.6980 - val_precision_15: 0.7094 - val_recall_15: 0.7100\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4026 - accuracy: 0.8342 - precision_15: 0.8315 - recall_15: 0.8509 - val_loss: 0.6573 - val_accuracy: 0.6947 - val_precision_15: 0.6982 - val_recall_15: 0.7271\n",
            "Epoch 13/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.3986 - accuracy: 0.8360 - precision_15: 0.8315 - recall_15: 0.8556 - val_loss: 0.6523 - val_accuracy: 0.6899 - val_precision_15: 0.6974 - val_recall_15: 0.7127\n",
            "Accuracy  :  0.685556173324585\n",
            "Precision :  0.6913201212882996\n",
            "Recall    :  0.7089804410934448\n",
            "F1- Score :  0.7000389169223721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adadelta\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jB4i5k0Zizn",
        "outputId": "a11142cd-4aef-46c4-ca01-89ddbc6b3e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 17s 20ms/step - loss: 0.4446 - accuracy: 0.8097 - precision_16: 0.8091 - recall_16: 0.8260 - val_loss: 0.6189 - val_accuracy: 0.6914 - val_precision_16: 0.7000 - val_recall_16: 0.7112\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.4442 - accuracy: 0.8093 - precision_16: 0.8069 - recall_16: 0.8286 - val_loss: 0.6197 - val_accuracy: 0.6929 - val_precision_16: 0.7008 - val_recall_16: 0.7141\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 8s 17ms/step - loss: 0.4447 - accuracy: 0.8109 - precision_16: 0.8096 - recall_16: 0.8281 - val_loss: 0.6205 - val_accuracy: 0.6934 - val_precision_16: 0.7014 - val_recall_16: 0.7144\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.4447 - accuracy: 0.8093 - precision_16: 0.8071 - recall_16: 0.8283 - val_loss: 0.6213 - val_accuracy: 0.6944 - val_precision_16: 0.7021 - val_recall_16: 0.7158\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 9s 17ms/step - loss: 0.4400 - accuracy: 0.8134 - precision_16: 0.8110 - recall_16: 0.8321 - val_loss: 0.6220 - val_accuracy: 0.6951 - val_precision_16: 0.7029 - val_recall_16: 0.7163\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.4393 - accuracy: 0.8132 - precision_16: 0.8114 - recall_16: 0.8310 - val_loss: 0.6227 - val_accuracy: 0.6954 - val_precision_16: 0.7031 - val_recall_16: 0.7168\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.4395 - accuracy: 0.8132 - precision_16: 0.8097 - recall_16: 0.8340 - val_loss: 0.6233 - val_accuracy: 0.6962 - val_precision_16: 0.7041 - val_recall_16: 0.7172\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.4397 - accuracy: 0.8148 - precision_16: 0.8123 - recall_16: 0.8335 - val_loss: 0.6239 - val_accuracy: 0.6961 - val_precision_16: 0.7041 - val_recall_16: 0.7168\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.4387 - accuracy: 0.8160 - precision_16: 0.8129 - recall_16: 0.8357 - val_loss: 0.6241 - val_accuracy: 0.6967 - val_precision_16: 0.7041 - val_recall_16: 0.7187\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 9s 17ms/step - loss: 0.4394 - accuracy: 0.8145 - precision_16: 0.8115 - recall_16: 0.8341 - val_loss: 0.6244 - val_accuracy: 0.6967 - val_precision_16: 0.7041 - val_recall_16: 0.7187\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.4399 - accuracy: 0.8137 - precision_16: 0.8110 - recall_16: 0.8329 - val_loss: 0.6248 - val_accuracy: 0.6974 - val_precision_16: 0.7045 - val_recall_16: 0.7199\n",
            "Accuracy  :  0.686779260635376\n",
            "Precision :  0.6929593086242676\n",
            "Recall    :  0.7088679075241089\n",
            "F1- Score :  0.7008233389183177\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 13s 24ms/step - loss: 0.4414 - accuracy: 0.8128 - precision_17: 0.8117 - recall_17: 0.8295 - val_loss: 0.6196 - val_accuracy: 0.6920 - val_precision_17: 0.7008 - val_recall_17: 0.7112\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 6s 23ms/step - loss: 0.4414 - accuracy: 0.8124 - precision_17: 0.8121 - recall_17: 0.8278 - val_loss: 0.6202 - val_accuracy: 0.6925 - val_precision_17: 0.7007 - val_recall_17: 0.7132\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.4409 - accuracy: 0.8107 - precision_17: 0.8090 - recall_17: 0.8288 - val_loss: 0.6208 - val_accuracy: 0.6944 - val_precision_17: 0.7023 - val_recall_17: 0.7153\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 6s 23ms/step - loss: 0.4409 - accuracy: 0.8114 - precision_17: 0.8092 - recall_17: 0.8301 - val_loss: 0.6213 - val_accuracy: 0.6947 - val_precision_17: 0.7031 - val_recall_17: 0.7146\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 5s 19ms/step - loss: 0.4431 - accuracy: 0.8103 - precision_17: 0.8084 - recall_17: 0.8286 - val_loss: 0.6218 - val_accuracy: 0.6946 - val_precision_17: 0.7032 - val_recall_17: 0.7139\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 5s 19ms/step - loss: 0.4406 - accuracy: 0.8112 - precision_17: 0.8099 - recall_17: 0.8285 - val_loss: 0.6222 - val_accuracy: 0.6957 - val_precision_17: 0.7040 - val_recall_17: 0.7158\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 6s 24ms/step - loss: 0.4395 - accuracy: 0.8143 - precision_17: 0.8124 - recall_17: 0.8323 - val_loss: 0.6227 - val_accuracy: 0.6955 - val_precision_17: 0.7030 - val_recall_17: 0.7175\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.4403 - accuracy: 0.8132 - precision_17: 0.8097 - recall_17: 0.8340 - val_loss: 0.6231 - val_accuracy: 0.6960 - val_precision_17: 0.7034 - val_recall_17: 0.7180\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.4416 - accuracy: 0.8099 - precision_17: 0.8074 - recall_17: 0.8292 - val_loss: 0.6234 - val_accuracy: 0.6962 - val_precision_17: 0.7036 - val_recall_17: 0.7184\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 7s 26ms/step - loss: 0.4398 - accuracy: 0.8148 - precision_17: 0.8127 - recall_17: 0.8331 - val_loss: 0.6238 - val_accuracy: 0.6964 - val_precision_17: 0.7038 - val_recall_17: 0.7182\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.4403 - accuracy: 0.8142 - precision_17: 0.8109 - recall_17: 0.8344 - val_loss: 0.6241 - val_accuracy: 0.6964 - val_precision_17: 0.7038 - val_recall_17: 0.7182\n",
            "Accuracy  :  0.6875364184379578\n",
            "Precision :  0.6941656470298767\n",
            "Recall    :  0.7083051800727844\n",
            "F1- Score :  0.701164137061721\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 13s 34ms/step - loss: 0.4429 - accuracy: 0.8121 - precision_18: 0.8101 - recall_18: 0.8304 - val_loss: 0.6200 - val_accuracy: 0.6924 - val_precision_18: 0.7015 - val_recall_18: 0.7108\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4433 - accuracy: 0.8126 - precision_18: 0.8105 - recall_18: 0.8311 - val_loss: 0.6204 - val_accuracy: 0.6934 - val_precision_18: 0.7023 - val_recall_18: 0.7120\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.4436 - accuracy: 0.8109 - precision_18: 0.8091 - recall_18: 0.8291 - val_loss: 0.6208 - val_accuracy: 0.6944 - val_precision_18: 0.7029 - val_recall_18: 0.7139\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 3s 25ms/step - loss: 0.4412 - accuracy: 0.8111 - precision_18: 0.8087 - recall_18: 0.8301 - val_loss: 0.6211 - val_accuracy: 0.6946 - val_precision_18: 0.7032 - val_recall_18: 0.7139\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4404 - accuracy: 0.8124 - precision_18: 0.8119 - recall_18: 0.8282 - val_loss: 0.6215 - val_accuracy: 0.6946 - val_precision_18: 0.7033 - val_recall_18: 0.7136\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.4406 - accuracy: 0.8117 - precision_18: 0.8100 - recall_18: 0.8294 - val_loss: 0.6218 - val_accuracy: 0.6949 - val_precision_18: 0.7039 - val_recall_18: 0.7132\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 4s 33ms/step - loss: 0.4418 - accuracy: 0.8134 - precision_18: 0.8120 - recall_18: 0.8305 - val_loss: 0.6221 - val_accuracy: 0.6954 - val_precision_18: 0.7038 - val_recall_18: 0.7151\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.4417 - accuracy: 0.8124 - precision_18: 0.8109 - recall_18: 0.8299 - val_loss: 0.6224 - val_accuracy: 0.6957 - val_precision_18: 0.7040 - val_recall_18: 0.7158\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.4412 - accuracy: 0.8118 - precision_18: 0.8094 - recall_18: 0.8309 - val_loss: 0.6226 - val_accuracy: 0.6959 - val_precision_18: 0.7040 - val_recall_18: 0.7160\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.4389 - accuracy: 0.8125 - precision_18: 0.8112 - recall_18: 0.8295 - val_loss: 0.6229 - val_accuracy: 0.6957 - val_precision_18: 0.7041 - val_recall_18: 0.7156\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 4s 29ms/step - loss: 0.4399 - accuracy: 0.8141 - precision_18: 0.8135 - recall_18: 0.8298 - val_loss: 0.6231 - val_accuracy: 0.6957 - val_precision_18: 0.7037 - val_recall_18: 0.7165\n",
            "Accuracy  :  0.6886429786682129\n",
            "Precision :  0.6957098841667175\n",
            "Recall    :  0.7080801129341125\n",
            "F1- Score :  0.7018404951845008\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 15s 64ms/step - loss: 0.4419 - accuracy: 0.8102 - precision_19: 0.8098 - recall_19: 0.8260 - val_loss: 0.6202 - val_accuracy: 0.6927 - val_precision_19: 0.7017 - val_recall_19: 0.7115\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.4433 - accuracy: 0.8106 - precision_19: 0.8097 - recall_19: 0.8273 - val_loss: 0.6205 - val_accuracy: 0.6937 - val_precision_19: 0.7024 - val_recall_19: 0.7132\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4417 - accuracy: 0.8119 - precision_19: 0.8105 - recall_19: 0.8294 - val_loss: 0.6208 - val_accuracy: 0.6945 - val_precision_19: 0.7030 - val_recall_19: 0.7141\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 0.4421 - accuracy: 0.8112 - precision_19: 0.8101 - recall_19: 0.8280 - val_loss: 0.6210 - val_accuracy: 0.6950 - val_precision_19: 0.7037 - val_recall_19: 0.7139\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 0.4402 - accuracy: 0.8116 - precision_19: 0.8104 - recall_19: 0.8286 - val_loss: 0.6212 - val_accuracy: 0.6945 - val_precision_19: 0.7031 - val_recall_19: 0.7139\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.4424 - accuracy: 0.8106 - precision_19: 0.8096 - recall_19: 0.8274 - val_loss: 0.6215 - val_accuracy: 0.6950 - val_precision_19: 0.7034 - val_recall_19: 0.7146\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4400 - accuracy: 0.8112 - precision_19: 0.8086 - recall_19: 0.8307 - val_loss: 0.6217 - val_accuracy: 0.6954 - val_precision_19: 0.7039 - val_recall_19: 0.7148\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.4398 - accuracy: 0.8129 - precision_19: 0.8114 - recall_19: 0.8305 - val_loss: 0.6219 - val_accuracy: 0.6950 - val_precision_19: 0.7036 - val_recall_19: 0.7141\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4440 - accuracy: 0.8114 - precision_19: 0.8099 - recall_19: 0.8291 - val_loss: 0.6221 - val_accuracy: 0.6956 - val_precision_19: 0.7040 - val_recall_19: 0.7153\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 0.4406 - accuracy: 0.8126 - precision_19: 0.8109 - recall_19: 0.8302 - val_loss: 0.6223 - val_accuracy: 0.6959 - val_precision_19: 0.7040 - val_recall_19: 0.7160\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 0.4402 - accuracy: 0.8162 - precision_19: 0.8146 - recall_19: 0.8335 - val_loss: 0.6225 - val_accuracy: 0.6956 - val_precision_19: 0.7033 - val_recall_19: 0.7170\n",
            "Accuracy  :  0.688759446144104\n",
            "Precision :  0.6956473588943481\n",
            "Recall    :  0.7086427807807922\n",
            "F1- Score :  0.7020849394609353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"rmsprop\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxw3dXCIZkje",
        "outputId": "ab512a59-d55d-4c54-f5be-172f42f015a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 15s 18ms/step - loss: 0.4663 - accuracy: 0.7915 - precision_20: 0.7879 - recall_20: 0.8152 - val_loss: 0.6342 - val_accuracy: 0.6980 - val_precision_20: 0.7161 - val_recall_20: 0.6944\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.4596 - accuracy: 0.7987 - precision_20: 0.7950 - recall_20: 0.8217 - val_loss: 0.6337 - val_accuracy: 0.6854 - val_precision_20: 0.6586 - val_recall_20: 0.8200\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 7s 14ms/step - loss: 0.4550 - accuracy: 0.7992 - precision_20: 0.7961 - recall_20: 0.8211 - val_loss: 0.6264 - val_accuracy: 0.6947 - val_precision_20: 0.6931 - val_recall_20: 0.7410\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.4451 - accuracy: 0.8074 - precision_20: 0.8041 - recall_20: 0.8284 - val_loss: 0.6366 - val_accuracy: 0.6919 - val_precision_20: 0.7042 - val_recall_20: 0.7024\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.4431 - accuracy: 0.8089 - precision_20: 0.8066 - recall_20: 0.8282 - val_loss: 0.6297 - val_accuracy: 0.6816 - val_precision_20: 0.6815 - val_recall_20: 0.7278\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 8s 15ms/step - loss: 0.4363 - accuracy: 0.8153 - precision_20: 0.8107 - recall_20: 0.8373 - val_loss: 0.6485 - val_accuracy: 0.6869 - val_precision_20: 0.6745 - val_recall_20: 0.7688\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 7s 13ms/step - loss: 0.4310 - accuracy: 0.8152 - precision_20: 0.8115 - recall_20: 0.8360 - val_loss: 0.6324 - val_accuracy: 0.6954 - val_precision_20: 0.7080 - val_recall_20: 0.7048\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.4215 - accuracy: 0.8220 - precision_20: 0.8169 - recall_20: 0.8441 - val_loss: 0.6461 - val_accuracy: 0.6999 - val_precision_20: 0.6940 - val_recall_20: 0.7561\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.4184 - accuracy: 0.8201 - precision_20: 0.8159 - recall_20: 0.8409 - val_loss: 0.6759 - val_accuracy: 0.7011 - val_precision_20: 0.7188 - val_recall_20: 0.6983\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 7s 15ms/step - loss: 0.4099 - accuracy: 0.8263 - precision_20: 0.8194 - recall_20: 0.8507 - val_loss: 0.6568 - val_accuracy: 0.7000 - val_precision_20: 0.6969 - val_recall_20: 0.7484\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 6s 13ms/step - loss: 0.4034 - accuracy: 0.8284 - precision_20: 0.8200 - recall_20: 0.8549 - val_loss: 0.6711 - val_accuracy: 0.7014 - val_precision_20: 0.7217 - val_recall_20: 0.6928\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 8s 16ms/step - loss: 0.3978 - accuracy: 0.8348 - precision_20: 0.8264 - recall_20: 0.8603 - val_loss: 0.6783 - val_accuracy: 0.7055 - val_precision_20: 0.6979 - val_recall_20: 0.7645\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 6s 12ms/step - loss: 0.3930 - accuracy: 0.8363 - precision_20: 0.8305 - recall_20: 0.8576 - val_loss: 0.6619 - val_accuracy: 0.6949 - val_precision_20: 0.6905 - val_recall_20: 0.7487\n",
            "Accuracy  :  0.6936517357826233\n",
            "Precision :  0.6897237300872803\n",
            "Recall    :  0.7417285442352295\n",
            "F1- Score :  0.714781466932608\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 14s 27ms/step - loss: 0.4438 - accuracy: 0.8087 - precision_21: 0.8045 - recall_21: 0.8311 - val_loss: 0.6582 - val_accuracy: 0.7004 - val_precision_21: 0.7124 - val_recall_21: 0.7105\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 5s 21ms/step - loss: 0.4345 - accuracy: 0.8155 - precision_21: 0.8105 - recall_21: 0.8384 - val_loss: 0.6983 - val_accuracy: 0.6637 - val_precision_21: 0.7555 - val_recall_21: 0.5221\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.4297 - accuracy: 0.8163 - precision_21: 0.8126 - recall_21: 0.8367 - val_loss: 0.7034 - val_accuracy: 0.6869 - val_precision_21: 0.7477 - val_recall_21: 0.6003\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 5s 18ms/step - loss: 0.4254 - accuracy: 0.8198 - precision_21: 0.8155 - recall_21: 0.8410 - val_loss: 0.6491 - val_accuracy: 0.6785 - val_precision_21: 0.7164 - val_recall_21: 0.6318\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 5s 21ms/step - loss: 0.4150 - accuracy: 0.8260 - precision_21: 0.8212 - recall_21: 0.8471 - val_loss: 0.6511 - val_accuracy: 0.6890 - val_precision_21: 0.6749 - val_recall_21: 0.7753\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.4115 - accuracy: 0.8268 - precision_21: 0.8215 - recall_21: 0.8487 - val_loss: 0.6997 - val_accuracy: 0.6859 - val_precision_21: 0.7340 - val_recall_21: 0.6207\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.4113 - accuracy: 0.8303 - precision_21: 0.8257 - recall_21: 0.8505 - val_loss: 0.6511 - val_accuracy: 0.6944 - val_precision_21: 0.7025 - val_recall_21: 0.7148\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 6s 24ms/step - loss: 0.4035 - accuracy: 0.8330 - precision_21: 0.8285 - recall_21: 0.8529 - val_loss: 0.6943 - val_accuracy: 0.6957 - val_precision_21: 0.6671 - val_recall_21: 0.8281\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.4012 - accuracy: 0.8323 - precision_21: 0.8275 - recall_21: 0.8526 - val_loss: 0.6778 - val_accuracy: 0.7021 - val_precision_21: 0.7122 - val_recall_21: 0.7165\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 4s 17ms/step - loss: 0.3928 - accuracy: 0.8364 - precision_21: 0.8316 - recall_21: 0.8563 - val_loss: 0.6834 - val_accuracy: 0.6911 - val_precision_21: 0.6862 - val_recall_21: 0.7480\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 6s 24ms/step - loss: 0.3890 - accuracy: 0.8399 - precision_21: 0.8321 - recall_21: 0.8641 - val_loss: 0.6901 - val_accuracy: 0.7037 - val_precision_21: 0.7101 - val_recall_21: 0.7268\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 4s 16ms/step - loss: 0.3849 - accuracy: 0.8424 - precision_21: 0.8338 - recall_21: 0.8673 - val_loss: 0.6766 - val_accuracy: 0.6915 - val_precision_21: 0.7109 - val_recall_21: 0.6853\n",
            "Epoch 13/100\n",
            "251/251 [==============================] - 5s 19ms/step - loss: 0.3731 - accuracy: 0.8482 - precision_21: 0.8426 - recall_21: 0.8678 - val_loss: 0.6631 - val_accuracy: 0.6954 - val_precision_21: 0.6806 - val_recall_21: 0.7801\n",
            "Epoch 14/100\n",
            "251/251 [==============================] - 5s 22ms/step - loss: 0.3727 - accuracy: 0.8502 - precision_21: 0.8434 - recall_21: 0.8715 - val_loss: 0.7402 - val_accuracy: 0.6798 - val_precision_21: 0.7596 - val_recall_21: 0.5619\n",
            "Accuracy  :  0.6762376427650452\n",
            "Precision :  0.7134060263633728\n",
            "Recall    :  0.6258158683776855\n",
            "F1- Score :  0.666746584188414\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 12s 42ms/step - loss: 0.4149 - accuracy: 0.8254 - precision_22: 0.8223 - recall_22: 0.8440 - val_loss: 0.6578 - val_accuracy: 0.6996 - val_precision_22: 0.7198 - val_recall_22: 0.6913\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.4076 - accuracy: 0.8280 - precision_22: 0.8220 - recall_22: 0.8507 - val_loss: 0.6830 - val_accuracy: 0.6969 - val_precision_22: 0.7286 - val_recall_22: 0.6644\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.4053 - accuracy: 0.8324 - precision_22: 0.8257 - recall_22: 0.8556 - val_loss: 0.6855 - val_accuracy: 0.6937 - val_precision_22: 0.6735 - val_recall_22: 0.7976\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.4017 - accuracy: 0.8339 - precision_22: 0.8290 - recall_22: 0.8541 - val_loss: 0.7067 - val_accuracy: 0.7034 - val_precision_22: 0.7150 - val_recall_22: 0.7141\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 3s 27ms/step - loss: 0.3983 - accuracy: 0.8355 - precision_22: 0.8316 - recall_22: 0.8540 - val_loss: 0.6733 - val_accuracy: 0.6991 - val_precision_22: 0.7008 - val_recall_22: 0.7350\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.3962 - accuracy: 0.8367 - precision_22: 0.8315 - recall_22: 0.8571 - val_loss: 0.6777 - val_accuracy: 0.7039 - val_precision_22: 0.6984 - val_recall_22: 0.7576\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 3s 22ms/step - loss: 0.3914 - accuracy: 0.8394 - precision_22: 0.8342 - recall_22: 0.8594 - val_loss: 0.6686 - val_accuracy: 0.6980 - val_precision_22: 0.6962 - val_recall_22: 0.7436\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 3s 21ms/step - loss: 0.3859 - accuracy: 0.8422 - precision_22: 0.8356 - recall_22: 0.8643 - val_loss: 0.7011 - val_accuracy: 0.6757 - val_precision_22: 0.6471 - val_recall_22: 0.8272\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 4s 30ms/step - loss: 0.3855 - accuracy: 0.8416 - precision_22: 0.8349 - recall_22: 0.8636 - val_loss: 0.6901 - val_accuracy: 0.6675 - val_precision_22: 0.7034 - val_recall_22: 0.6234\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 3s 23ms/step - loss: 0.3779 - accuracy: 0.8465 - precision_22: 0.8411 - recall_22: 0.8661 - val_loss: 0.6695 - val_accuracy: 0.6982 - val_precision_22: 0.6961 - val_recall_22: 0.7446\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 3s 21ms/step - loss: 0.3774 - accuracy: 0.8472 - precision_22: 0.8396 - recall_22: 0.8700 - val_loss: 0.7261 - val_accuracy: 0.7070 - val_precision_22: 0.6998 - val_recall_22: 0.7643\n",
            "Accuracy  :  0.6877111196517944\n",
            "Precision :  0.7026218771934509\n",
            "Recall    :  0.687598466873169\n",
            "F1- Score :  0.6950289968229864\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 10s 61ms/step - loss: 0.4072 - accuracy: 0.8302 - precision_23: 0.8236 - recall_23: 0.8536 - val_loss: 0.6520 - val_accuracy: 0.6946 - val_precision_23: 0.7081 - val_recall_23: 0.7021\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.4027 - accuracy: 0.8344 - precision_23: 0.8297 - recall_23: 0.8543 - val_loss: 0.6548 - val_accuracy: 0.7012 - val_precision_23: 0.7087 - val_recall_23: 0.7223\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 3s 47ms/step - loss: 0.3973 - accuracy: 0.8374 - precision_23: 0.8324 - recall_23: 0.8575 - val_loss: 0.6692 - val_accuracy: 0.6834 - val_precision_23: 0.7164 - val_recall_23: 0.6471\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.3947 - accuracy: 0.8392 - precision_23: 0.8334 - recall_23: 0.8604 - val_loss: 0.6792 - val_accuracy: 0.6851 - val_precision_23: 0.6594 - val_recall_23: 0.8159\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3952 - accuracy: 0.8389 - precision_23: 0.8332 - recall_23: 0.8598 - val_loss: 0.6819 - val_accuracy: 0.6977 - val_precision_23: 0.7311 - val_recall_23: 0.6623\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.3899 - accuracy: 0.8404 - precision_23: 0.8348 - recall_23: 0.8611 - val_loss: 0.6743 - val_accuracy: 0.7042 - val_precision_23: 0.7132 - val_recall_23: 0.7211\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.3895 - accuracy: 0.8413 - precision_23: 0.8351 - recall_23: 0.8628 - val_loss: 0.6639 - val_accuracy: 0.6942 - val_precision_23: 0.7007 - val_recall_23: 0.7189\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.3850 - accuracy: 0.8429 - precision_23: 0.8378 - recall_23: 0.8624 - val_loss: 0.6686 - val_accuracy: 0.6982 - val_precision_23: 0.6898 - val_recall_23: 0.7624\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 0.3820 - accuracy: 0.8447 - precision_23: 0.8388 - recall_23: 0.8652 - val_loss: 0.6756 - val_accuracy: 0.7017 - val_precision_23: 0.7283 - val_recall_23: 0.6800\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 0.3809 - accuracy: 0.8463 - precision_23: 0.8429 - recall_23: 0.8628 - val_loss: 0.6735 - val_accuracy: 0.6906 - val_precision_23: 0.6822 - val_recall_23: 0.7580\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.3787 - accuracy: 0.8472 - precision_23: 0.8408 - recall_23: 0.8681 - val_loss: 0.7172 - val_accuracy: 0.6985 - val_precision_23: 0.7396 - val_recall_23: 0.6483\n",
            "Accuracy  :  0.6907396912574768\n",
            "Precision :  0.702951192855835\n",
            "Recall    :  0.6969389915466309\n",
            "F1- Score :  0.6999321817011861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BiLSTM**"
      ],
      "metadata": {
        "id": "GcavtDqUtici"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model_BiLSTM(x_train) # creating bi directional model"
      ],
      "metadata": {
        "id": "AvDuDxvhZpF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training model and evaluating scores with different batch size and optimizers and iterations"
      ],
      "metadata": {
        "id": "cvg15zi6ttiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adam\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Mv0Fa7yF7x",
        "outputId": "86db0ccf-f27b-42be-e6b7-299a46b0be61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 35s 29ms/step - loss: 0.6383 - accuracy: 0.6291 - precision_24: 0.6164 - recall_24: 0.7441 - val_loss: 0.6071 - val_accuracy: 0.6753 - val_precision_24: 0.6600 - val_recall_24: 0.7741\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 11s 21ms/step - loss: 0.6055 - accuracy: 0.6762 - precision_24: 0.6700 - recall_24: 0.7337 - val_loss: 0.6019 - val_accuracy: 0.6759 - val_precision_24: 0.6595 - val_recall_24: 0.7784\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.5979 - accuracy: 0.6801 - precision_24: 0.6738 - recall_24: 0.7361 - val_loss: 0.5992 - val_accuracy: 0.6773 - val_precision_24: 0.6566 - val_recall_24: 0.7952\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.5933 - accuracy: 0.6814 - precision_24: 0.6710 - recall_24: 0.7504 - val_loss: 0.5972 - val_accuracy: 0.6813 - val_precision_24: 0.6782 - val_recall_24: 0.7362\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.5900 - accuracy: 0.6863 - precision_24: 0.6750 - recall_24: 0.7554 - val_loss: 0.5973 - val_accuracy: 0.6854 - val_precision_24: 0.6957 - val_recall_24: 0.7019\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.5843 - accuracy: 0.6876 - precision_24: 0.6747 - recall_24: 0.7618 - val_loss: 0.6046 - val_accuracy: 0.6836 - val_precision_24: 0.7000 - val_recall_24: 0.6851\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 13s 25ms/step - loss: 0.5798 - accuracy: 0.6918 - precision_24: 0.6769 - recall_24: 0.7703 - val_loss: 0.5964 - val_accuracy: 0.6853 - val_precision_24: 0.6969 - val_recall_24: 0.6983\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 13s 26ms/step - loss: 0.5728 - accuracy: 0.6986 - precision_24: 0.6873 - recall_24: 0.7628 - val_loss: 0.5923 - val_accuracy: 0.6861 - val_precision_24: 0.6724 - val_recall_24: 0.7727\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.5632 - accuracy: 0.7062 - precision_24: 0.6946 - recall_24: 0.7683 - val_loss: 0.5873 - val_accuracy: 0.6936 - val_precision_24: 0.7027 - val_recall_24: 0.7120\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 11s 22ms/step - loss: 0.5522 - accuracy: 0.7160 - precision_24: 0.7048 - recall_24: 0.7732 - val_loss: 0.5965 - val_accuracy: 0.6896 - val_precision_24: 0.6679 - val_recall_24: 0.8015\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.5403 - accuracy: 0.7260 - precision_24: 0.7151 - recall_24: 0.7795 - val_loss: 0.5946 - val_accuracy: 0.6949 - val_precision_24: 0.6884 - val_recall_24: 0.7547\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.5268 - accuracy: 0.7352 - precision_24: 0.7235 - recall_24: 0.7875 - val_loss: 0.5865 - val_accuracy: 0.6970 - val_precision_24: 0.6919 - val_recall_24: 0.7520\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.5078 - accuracy: 0.7494 - precision_24: 0.7368 - recall_24: 0.7998 - val_loss: 0.6078 - val_accuracy: 0.6981 - val_precision_24: 0.7111 - val_recall_24: 0.7062\n",
            "Epoch 14/100\n",
            "501/501 [==============================] - 13s 25ms/step - loss: 0.4906 - accuracy: 0.7586 - precision_24: 0.7460 - recall_24: 0.8066 - val_loss: 0.5879 - val_accuracy: 0.7044 - val_precision_24: 0.6972 - val_recall_24: 0.7626\n",
            "Epoch 15/100\n",
            "501/501 [==============================] - 14s 27ms/step - loss: 0.4731 - accuracy: 0.7708 - precision_24: 0.7607 - recall_24: 0.8105 - val_loss: 0.6200 - val_accuracy: 0.7000 - val_precision_24: 0.7082 - val_recall_24: 0.7194\n",
            "Epoch 16/100\n",
            "501/501 [==============================] - 13s 27ms/step - loss: 0.4486 - accuracy: 0.7866 - precision_24: 0.7791 - recall_24: 0.8183 - val_loss: 0.6369 - val_accuracy: 0.6971 - val_precision_24: 0.7308 - val_recall_24: 0.6608\n",
            "Epoch 17/100\n",
            "501/501 [==============================] - 11s 23ms/step - loss: 0.4245 - accuracy: 0.8024 - precision_24: 0.7942 - recall_24: 0.8327 - val_loss: 0.6397 - val_accuracy: 0.6873 - val_precision_24: 0.6555 - val_recall_24: 0.8399\n",
            "Epoch 18/100\n",
            "501/501 [==============================] - 10s 20ms/step - loss: 0.4048 - accuracy: 0.8161 - precision_24: 0.8108 - recall_24: 0.8393 - val_loss: 0.6553 - val_accuracy: 0.7051 - val_precision_24: 0.7105 - val_recall_24: 0.7304\n",
            "Epoch 19/100\n",
            "501/501 [==============================] - 13s 25ms/step - loss: 0.3781 - accuracy: 0.8281 - precision_24: 0.8233 - recall_24: 0.8489 - val_loss: 0.7160 - val_accuracy: 0.6980 - val_precision_24: 0.7198 - val_recall_24: 0.6863\n",
            "Epoch 20/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.3604 - accuracy: 0.8387 - precision_24: 0.8354 - recall_24: 0.8558 - val_loss: 0.7094 - val_accuracy: 0.6886 - val_precision_24: 0.7095 - val_recall_24: 0.6793\n",
            "Epoch 21/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.3368 - accuracy: 0.8502 - precision_24: 0.8462 - recall_24: 0.8672 - val_loss: 0.7295 - val_accuracy: 0.6805 - val_precision_24: 0.7474 - val_recall_24: 0.5823\n",
            "Epoch 22/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.3145 - accuracy: 0.8605 - precision_24: 0.8588 - recall_24: 0.8731 - val_loss: 0.8143 - val_accuracy: 0.7072 - val_precision_24: 0.7150 - val_recall_24: 0.7264\n",
            "Accuracy  :  0.6965637803077698\n",
            "Precision :  0.6897584199905396\n",
            "Recall    :  0.7518568634986877\n",
            "F1- Score :  0.7194701778836586\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 29s 51ms/step - loss: 0.5000 - accuracy: 0.7550 - precision_25: 0.7419 - recall_25: 0.8051 - val_loss: 0.5976 - val_accuracy: 0.6941 - val_precision_25: 0.6828 - val_recall_25: 0.7688\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 10s 40ms/step - loss: 0.4867 - accuracy: 0.7617 - precision_25: 0.7493 - recall_25: 0.8086 - val_loss: 0.6255 - val_accuracy: 0.6880 - val_precision_25: 0.7231 - val_recall_25: 0.6481\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 8s 33ms/step - loss: 0.4712 - accuracy: 0.7736 - precision_25: 0.7619 - recall_25: 0.8162 - val_loss: 0.6343 - val_accuracy: 0.6940 - val_precision_25: 0.7217 - val_recall_25: 0.6697\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 9s 36ms/step - loss: 0.4541 - accuracy: 0.7844 - precision_25: 0.7759 - recall_25: 0.8185 - val_loss: 0.6252 - val_accuracy: 0.7009 - val_precision_25: 0.6968 - val_recall_25: 0.7518\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 10s 39ms/step - loss: 0.4343 - accuracy: 0.7986 - precision_25: 0.7885 - recall_25: 0.8331 - val_loss: 0.6667 - val_accuracy: 0.6965 - val_precision_25: 0.6918 - val_recall_25: 0.7506\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 8s 32ms/step - loss: 0.4194 - accuracy: 0.8081 - precision_25: 0.8030 - recall_25: 0.8322 - val_loss: 0.6320 - val_accuracy: 0.6925 - val_precision_25: 0.6857 - val_recall_25: 0.7542\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 10s 40ms/step - loss: 0.4028 - accuracy: 0.8154 - precision_25: 0.8091 - recall_25: 0.8406 - val_loss: 0.6663 - val_accuracy: 0.7007 - val_precision_25: 0.6908 - val_recall_25: 0.7681\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 11s 45ms/step - loss: 0.3812 - accuracy: 0.8261 - precision_25: 0.8234 - recall_25: 0.8439 - val_loss: 0.6957 - val_accuracy: 0.6894 - val_precision_25: 0.7360 - val_recall_25: 0.6277\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 8s 31ms/step - loss: 0.3651 - accuracy: 0.8354 - precision_25: 0.8331 - recall_25: 0.8514 - val_loss: 0.7219 - val_accuracy: 0.6954 - val_precision_25: 0.7322 - val_recall_25: 0.6529\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 10s 39ms/step - loss: 0.3459 - accuracy: 0.8460 - precision_25: 0.8455 - recall_25: 0.8584 - val_loss: 0.7245 - val_accuracy: 0.7062 - val_precision_25: 0.6934 - val_recall_25: 0.7796\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 10s 41ms/step - loss: 0.3318 - accuracy: 0.8532 - precision_25: 0.8521 - recall_25: 0.8657 - val_loss: 0.7403 - val_accuracy: 0.7016 - val_precision_25: 0.7070 - val_recall_25: 0.7276\n",
            "Accuracy  :  0.6934769749641418\n",
            "Precision :  0.6806982755661011\n",
            "Recall    :  0.7679495811462402\n",
            "F1- Score :  0.7216963780201229\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 21s 62ms/step - loss: 0.4802 - accuracy: 0.7683 - precision_26: 0.7551 - recall_26: 0.8152 - val_loss: 0.5896 - val_accuracy: 0.6964 - val_precision_26: 0.7077 - val_recall_26: 0.7086\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 7s 52ms/step - loss: 0.4685 - accuracy: 0.7760 - precision_26: 0.7648 - recall_26: 0.8170 - val_loss: 0.6090 - val_accuracy: 0.6990 - val_precision_26: 0.7058 - val_recall_26: 0.7220\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.4534 - accuracy: 0.7853 - precision_26: 0.7739 - recall_26: 0.8247 - val_loss: 0.6278 - val_accuracy: 0.6960 - val_precision_26: 0.7166 - val_recall_26: 0.6870\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 8s 60ms/step - loss: 0.4397 - accuracy: 0.7928 - precision_26: 0.7840 - recall_26: 0.8257 - val_loss: 0.6528 - val_accuracy: 0.6994 - val_precision_26: 0.6782 - val_recall_26: 0.8027\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.4306 - accuracy: 0.7994 - precision_26: 0.7911 - recall_26: 0.8303 - val_loss: 0.6246 - val_accuracy: 0.6894 - val_precision_26: 0.7073 - val_recall_26: 0.6867\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.4151 - accuracy: 0.8095 - precision_26: 0.8024 - recall_26: 0.8366 - val_loss: 0.6420 - val_accuracy: 0.6972 - val_precision_26: 0.7032 - val_recall_26: 0.7228\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 6s 49ms/step - loss: 0.3974 - accuracy: 0.8182 - precision_26: 0.8100 - recall_26: 0.8461 - val_loss: 0.6374 - val_accuracy: 0.6966 - val_precision_26: 0.7134 - val_recall_26: 0.6961\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.3809 - accuracy: 0.8271 - precision_26: 0.8237 - recall_26: 0.8458 - val_loss: 0.6695 - val_accuracy: 0.6981 - val_precision_26: 0.6981 - val_recall_26: 0.7388\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 7s 54ms/step - loss: 0.3745 - accuracy: 0.8315 - precision_26: 0.8270 - recall_26: 0.8515 - val_loss: 0.6934 - val_accuracy: 0.6899 - val_precision_26: 0.7315 - val_recall_26: 0.6375\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 4s 36ms/step - loss: 0.3549 - accuracy: 0.8433 - precision_26: 0.8393 - recall_26: 0.8611 - val_loss: 0.7215 - val_accuracy: 0.6999 - val_precision_26: 0.6822 - val_recall_26: 0.7914\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.3415 - accuracy: 0.8490 - precision_26: 0.8455 - recall_26: 0.8655 - val_loss: 0.7601 - val_accuracy: 0.6966 - val_precision_26: 0.7187 - val_recall_26: 0.6843\n",
            "Accuracy  :  0.691962718963623\n",
            "Precision :  0.7020559310913086\n",
            "Recall    :  0.7032410502433777\n",
            "F1- Score :  0.7026479909482719\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 21s 111ms/step - loss: 0.4648 - accuracy: 0.7772 - precision_27: 0.7640 - recall_27: 0.8219 - val_loss: 0.6279 - val_accuracy: 0.6966 - val_precision_27: 0.6942 - val_recall_27: 0.7444\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.4531 - accuracy: 0.7850 - precision_27: 0.7746 - recall_27: 0.8226 - val_loss: 0.6271 - val_accuracy: 0.6969 - val_precision_27: 0.7132 - val_recall_27: 0.6973\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.4424 - accuracy: 0.7925 - precision_27: 0.7842 - recall_27: 0.8246 - val_loss: 0.6327 - val_accuracy: 0.6999 - val_precision_27: 0.6972 - val_recall_27: 0.7472\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.4311 - accuracy: 0.7992 - precision_27: 0.7887 - recall_27: 0.8342 - val_loss: 0.6468 - val_accuracy: 0.7004 - val_precision_27: 0.6976 - val_recall_27: 0.7480\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 5s 87ms/step - loss: 0.4231 - accuracy: 0.8048 - precision_27: 0.7962 - recall_27: 0.8354 - val_loss: 0.6470 - val_accuracy: 0.6936 - val_precision_27: 0.7272 - val_recall_27: 0.6572\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.4129 - accuracy: 0.8097 - precision_27: 0.8042 - recall_27: 0.8343 - val_loss: 0.6498 - val_accuracy: 0.6980 - val_precision_27: 0.7010 - val_recall_27: 0.7309\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.4041 - accuracy: 0.8152 - precision_27: 0.8084 - recall_27: 0.8409 - val_loss: 0.6533 - val_accuracy: 0.6898 - val_precision_27: 0.7276 - val_recall_27: 0.6445\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.3923 - accuracy: 0.8240 - precision_27: 0.8189 - recall_27: 0.8458 - val_loss: 0.6537 - val_accuracy: 0.6951 - val_precision_27: 0.6905 - val_recall_27: 0.7496\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3772 - accuracy: 0.8307 - precision_27: 0.8263 - recall_27: 0.8507 - val_loss: 0.6796 - val_accuracy: 0.6960 - val_precision_27: 0.7184 - val_recall_27: 0.6829\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.3682 - accuracy: 0.8364 - precision_27: 0.8321 - recall_27: 0.8555 - val_loss: 0.6750 - val_accuracy: 0.6926 - val_precision_27: 0.7064 - val_recall_27: 0.6995\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.3577 - accuracy: 0.8422 - precision_27: 0.8374 - recall_27: 0.8614 - val_loss: 0.7038 - val_accuracy: 0.6984 - val_precision_27: 0.7198 - val_recall_27: 0.6875\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 5s 72ms/step - loss: 0.3418 - accuracy: 0.8506 - precision_27: 0.8461 - recall_27: 0.8683 - val_loss: 0.7284 - val_accuracy: 0.7009 - val_precision_27: 0.7066 - val_recall_27: 0.7261\n",
            "Accuracy  :  0.6917880177497864\n",
            "Precision :  0.7082753777503967\n",
            "Recall    :  0.6877110004425049\n",
            "F1- Score :  0.6978417214243203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"adadelta\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVSF9FQGyJQs",
        "outputId": "7e96435c-c7e3-4652-95a4-ce235e4057a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 30s 33ms/step - loss: 0.4399 - accuracy: 0.7949 - precision_28: 0.7963 - recall_28: 0.8094 - val_loss: 0.6233 - val_accuracy: 0.6997 - val_precision_28: 0.7058 - val_recall_28: 0.7244\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 13s 26ms/step - loss: 0.4386 - accuracy: 0.7957 - precision_28: 0.7890 - recall_28: 0.8244 - val_loss: 0.6225 - val_accuracy: 0.6994 - val_precision_28: 0.7021 - val_recall_28: 0.7326\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 14s 28ms/step - loss: 0.4381 - accuracy: 0.7975 - precision_28: 0.7891 - recall_28: 0.8291 - val_loss: 0.6224 - val_accuracy: 0.6999 - val_precision_28: 0.7010 - val_recall_28: 0.7372\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 13s 26ms/step - loss: 0.4385 - accuracy: 0.7959 - precision_28: 0.7838 - recall_28: 0.8346 - val_loss: 0.6226 - val_accuracy: 0.6999 - val_precision_28: 0.7007 - val_recall_28: 0.7379\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 14s 28ms/step - loss: 0.4382 - accuracy: 0.7962 - precision_28: 0.7840 - recall_28: 0.8350 - val_loss: 0.6227 - val_accuracy: 0.6997 - val_precision_28: 0.6998 - val_recall_28: 0.7398\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 14s 28ms/step - loss: 0.4358 - accuracy: 0.7959 - precision_28: 0.7835 - recall_28: 0.8352 - val_loss: 0.6229 - val_accuracy: 0.6995 - val_precision_28: 0.6993 - val_recall_28: 0.7403\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 14s 28ms/step - loss: 0.4373 - accuracy: 0.7964 - precision_28: 0.7837 - recall_28: 0.8359 - val_loss: 0.6230 - val_accuracy: 0.6999 - val_precision_28: 0.6998 - val_recall_28: 0.7403\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 14s 27ms/step - loss: 0.4362 - accuracy: 0.7967 - precision_28: 0.7839 - recall_28: 0.8364 - val_loss: 0.6232 - val_accuracy: 0.7000 - val_precision_28: 0.7001 - val_recall_28: 0.7398\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 13s 27ms/step - loss: 0.4356 - accuracy: 0.7953 - precision_28: 0.7838 - recall_28: 0.8329 - val_loss: 0.6235 - val_accuracy: 0.6999 - val_precision_28: 0.7001 - val_recall_28: 0.7396\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 14s 28ms/step - loss: 0.4364 - accuracy: 0.7970 - precision_28: 0.7847 - recall_28: 0.8358 - val_loss: 0.6237 - val_accuracy: 0.6997 - val_precision_28: 0.6998 - val_recall_28: 0.7398\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 13s 26ms/step - loss: 0.4342 - accuracy: 0.7976 - precision_28: 0.7852 - recall_28: 0.8366 - val_loss: 0.6238 - val_accuracy: 0.6994 - val_precision_28: 0.6993 - val_recall_28: 0.7398\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 13s 25ms/step - loss: 0.4357 - accuracy: 0.7982 - precision_28: 0.7856 - recall_28: 0.8372 - val_loss: 0.6241 - val_accuracy: 0.6992 - val_precision_28: 0.6993 - val_recall_28: 0.7396\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 13s 25ms/step - loss: 0.4347 - accuracy: 0.7979 - precision_28: 0.7846 - recall_28: 0.8384 - val_loss: 0.6242 - val_accuracy: 0.6997 - val_precision_28: 0.6998 - val_recall_28: 0.7398\n",
            "Accuracy  :  0.6952242255210876\n",
            "Precision :  0.6954103112220764\n",
            "Recall    :  0.7314877510070801\n",
            "F1- Score :  0.7129929432916656\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 26s 53ms/step - loss: 0.4366 - accuracy: 0.7971 - precision_29: 0.7850 - recall_29: 0.8353 - val_loss: 0.6224 - val_accuracy: 0.7001 - val_precision_29: 0.7010 - val_recall_29: 0.7379\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 10s 39ms/step - loss: 0.4391 - accuracy: 0.7970 - precision_29: 0.7861 - recall_29: 0.8332 - val_loss: 0.6223 - val_accuracy: 0.7000 - val_precision_29: 0.7005 - val_recall_29: 0.7388\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 9s 34ms/step - loss: 0.4371 - accuracy: 0.7967 - precision_29: 0.7839 - recall_29: 0.8363 - val_loss: 0.6223 - val_accuracy: 0.6995 - val_precision_29: 0.6994 - val_recall_29: 0.7400\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 8s 32ms/step - loss: 0.4381 - accuracy: 0.7940 - precision_29: 0.7825 - recall_29: 0.8320 - val_loss: 0.6224 - val_accuracy: 0.6997 - val_precision_29: 0.6995 - val_recall_29: 0.7408\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 9s 37ms/step - loss: 0.4361 - accuracy: 0.7962 - precision_29: 0.7844 - recall_29: 0.8341 - val_loss: 0.6225 - val_accuracy: 0.7001 - val_precision_29: 0.6996 - val_recall_29: 0.7417\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 7s 30ms/step - loss: 0.4361 - accuracy: 0.7975 - precision_29: 0.7842 - recall_29: 0.8379 - val_loss: 0.6227 - val_accuracy: 0.6999 - val_precision_29: 0.6997 - val_recall_29: 0.7405\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 10s 38ms/step - loss: 0.4374 - accuracy: 0.7944 - precision_29: 0.7820 - recall_29: 0.8339 - val_loss: 0.6229 - val_accuracy: 0.7000 - val_precision_29: 0.7000 - val_recall_29: 0.7403\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 10s 38ms/step - loss: 0.4368 - accuracy: 0.7953 - precision_29: 0.7829 - recall_29: 0.8346 - val_loss: 0.6230 - val_accuracy: 0.7000 - val_precision_29: 0.7000 - val_recall_29: 0.7403\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 7s 30ms/step - loss: 0.4361 - accuracy: 0.7977 - precision_29: 0.7845 - recall_29: 0.8381 - val_loss: 0.6231 - val_accuracy: 0.7000 - val_precision_29: 0.7001 - val_recall_29: 0.7398\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 10s 38ms/step - loss: 0.4359 - accuracy: 0.7962 - precision_29: 0.7849 - recall_29: 0.8334 - val_loss: 0.6231 - val_accuracy: 0.6995 - val_precision_29: 0.6995 - val_recall_29: 0.7398\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 8s 32ms/step - loss: 0.4348 - accuracy: 0.7982 - precision_29: 0.7855 - recall_29: 0.8375 - val_loss: 0.6233 - val_accuracy: 0.6994 - val_precision_29: 0.6993 - val_recall_29: 0.7398\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 9s 36ms/step - loss: 0.4356 - accuracy: 0.7980 - precision_29: 0.7854 - recall_29: 0.8373 - val_loss: 0.6234 - val_accuracy: 0.6994 - val_precision_29: 0.6993 - val_recall_29: 0.7400\n",
            "Accuracy  :  0.6951077580451965\n",
            "Precision :  0.6945125460624695\n",
            "Recall    :  0.7335134148597717\n",
            "F1- Score :  0.713480403390196\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 22s 69ms/step - loss: 0.4381 - accuracy: 0.7960 - precision_30: 0.7849 - recall_30: 0.8327 - val_loss: 0.6223 - val_accuracy: 0.6997 - val_precision_30: 0.6997 - val_recall_30: 0.7400\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 6s 44ms/step - loss: 0.4378 - accuracy: 0.7985 - precision_30: 0.7865 - recall_30: 0.8363 - val_loss: 0.6223 - val_accuracy: 0.6995 - val_precision_30: 0.6993 - val_recall_30: 0.7403\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.4364 - accuracy: 0.7967 - precision_30: 0.7840 - recall_30: 0.8365 - val_loss: 0.6224 - val_accuracy: 0.6996 - val_precision_30: 0.6996 - val_recall_30: 0.7400\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 7s 53ms/step - loss: 0.4379 - accuracy: 0.7946 - precision_30: 0.7820 - recall_30: 0.8344 - val_loss: 0.6224 - val_accuracy: 0.6997 - val_precision_30: 0.6996 - val_recall_30: 0.7403\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 5s 40ms/step - loss: 0.4354 - accuracy: 0.7971 - precision_30: 0.7847 - recall_30: 0.8361 - val_loss: 0.6225 - val_accuracy: 0.6996 - val_precision_30: 0.6995 - val_recall_30: 0.7403\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 6s 46ms/step - loss: 0.4370 - accuracy: 0.7946 - precision_30: 0.7826 - recall_30: 0.8334 - val_loss: 0.6225 - val_accuracy: 0.6997 - val_precision_30: 0.6997 - val_recall_30: 0.7400\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 6s 44ms/step - loss: 0.4369 - accuracy: 0.7977 - precision_30: 0.7854 - recall_30: 0.8363 - val_loss: 0.6226 - val_accuracy: 0.6997 - val_precision_30: 0.6995 - val_recall_30: 0.7405\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.4382 - accuracy: 0.7965 - precision_30: 0.7849 - recall_30: 0.8341 - val_loss: 0.6226 - val_accuracy: 0.6994 - val_precision_30: 0.6991 - val_recall_30: 0.7405\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 7s 52ms/step - loss: 0.4370 - accuracy: 0.7965 - precision_30: 0.7843 - recall_30: 0.8353 - val_loss: 0.6227 - val_accuracy: 0.6999 - val_precision_30: 0.6998 - val_recall_30: 0.7403\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 5s 39ms/step - loss: 0.4365 - accuracy: 0.7986 - precision_30: 0.7869 - recall_30: 0.8359 - val_loss: 0.6227 - val_accuracy: 0.6996 - val_precision_30: 0.6995 - val_recall_30: 0.7403\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 5s 42ms/step - loss: 0.4352 - accuracy: 0.7990 - precision_30: 0.7860 - recall_30: 0.8386 - val_loss: 0.6228 - val_accuracy: 0.6995 - val_precision_30: 0.6991 - val_recall_30: 0.7408\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 6s 49ms/step - loss: 0.4367 - accuracy: 0.7959 - precision_30: 0.7826 - recall_30: 0.8369 - val_loss: 0.6229 - val_accuracy: 0.6996 - val_precision_30: 0.6992 - val_recall_30: 0.7410\n",
            "Accuracy  :  0.6951077580451965\n",
            "Precision :  0.6940576434135437\n",
            "Recall    :  0.734751284122467\n",
            "F1- Score :  0.713824969770511\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 22s 127ms/step - loss: 0.4371 - accuracy: 0.7980 - precision_31: 0.7850 - recall_31: 0.8380 - val_loss: 0.6223 - val_accuracy: 0.6996 - val_precision_31: 0.6995 - val_recall_31: 0.7403\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.4387 - accuracy: 0.7975 - precision_31: 0.7852 - recall_31: 0.8361 - val_loss: 0.6223 - val_accuracy: 0.6996 - val_precision_31: 0.6995 - val_recall_31: 0.7403\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.4363 - accuracy: 0.7968 - precision_31: 0.7852 - recall_31: 0.8343 - val_loss: 0.6224 - val_accuracy: 0.6995 - val_precision_31: 0.6993 - val_recall_31: 0.7403\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.4356 - accuracy: 0.7968 - precision_31: 0.7840 - recall_31: 0.8365 - val_loss: 0.6225 - val_accuracy: 0.6997 - val_precision_31: 0.6996 - val_recall_31: 0.7403\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.4371 - accuracy: 0.7971 - precision_31: 0.7845 - recall_31: 0.8364 - val_loss: 0.6225 - val_accuracy: 0.6994 - val_precision_31: 0.6992 - val_recall_31: 0.7403\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.4358 - accuracy: 0.7957 - precision_31: 0.7830 - recall_31: 0.8355 - val_loss: 0.6226 - val_accuracy: 0.6997 - val_precision_31: 0.6997 - val_recall_31: 0.7400\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.4365 - accuracy: 0.7974 - precision_31: 0.7854 - recall_31: 0.8355 - val_loss: 0.6226 - val_accuracy: 0.6997 - val_precision_31: 0.6996 - val_recall_31: 0.7403\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.4353 - accuracy: 0.7972 - precision_31: 0.7848 - recall_31: 0.8363 - val_loss: 0.6227 - val_accuracy: 0.6997 - val_precision_31: 0.6996 - val_recall_31: 0.7403\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.4363 - accuracy: 0.7972 - precision_31: 0.7847 - recall_31: 0.8365 - val_loss: 0.6227 - val_accuracy: 0.6996 - val_precision_31: 0.6996 - val_recall_31: 0.7400\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.4347 - accuracy: 0.7964 - precision_31: 0.7845 - recall_31: 0.8346 - val_loss: 0.6227 - val_accuracy: 0.6995 - val_precision_31: 0.6994 - val_recall_31: 0.7400\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.4378 - accuracy: 0.7971 - precision_31: 0.7847 - recall_31: 0.8360 - val_loss: 0.6227 - val_accuracy: 0.6992 - val_precision_31: 0.6990 - val_recall_31: 0.7403\n",
            "Accuracy  :  0.6951077580451965\n",
            "Precision :  0.6940576434135437\n",
            "Recall    :  0.734751284122467\n",
            "F1- Score :  0.713824969770511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in batches:\n",
        "  print(\"Batch size = \", batch)\n",
        "  eval_met = list(train_model(model, \"rmsprop\", x_train, y_train, x_val, y_val, x_test, y_test, 100, batch))\n",
        "  print_score(eval_met)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNRhXq-PyKLH",
        "outputId": "86518758-112e-4781-b810-6d433a652661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size =  64\n",
            "Epoch 1/100\n",
            "501/501 [==============================] - 27s 30ms/step - loss: 0.4676 - accuracy: 0.7766 - precision_32: 0.7659 - recall_32: 0.8165 - val_loss: 0.6746 - val_accuracy: 0.6870 - val_precision_32: 0.7344 - val_recall_32: 0.6234\n",
            "Epoch 2/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.4592 - accuracy: 0.7828 - precision_32: 0.7736 - recall_32: 0.8186 - val_loss: 0.6299 - val_accuracy: 0.6909 - val_precision_32: 0.6616 - val_recall_32: 0.8301\n",
            "Epoch 3/100\n",
            "501/501 [==============================] - 13s 26ms/step - loss: 0.4519 - accuracy: 0.7872 - precision_32: 0.7772 - recall_32: 0.8236 - val_loss: 0.6138 - val_accuracy: 0.6929 - val_precision_32: 0.6836 - val_recall_32: 0.7619\n",
            "Epoch 4/100\n",
            "501/501 [==============================] - 11s 21ms/step - loss: 0.4393 - accuracy: 0.7935 - precision_32: 0.7847 - recall_32: 0.8264 - val_loss: 0.6240 - val_accuracy: 0.6954 - val_precision_32: 0.6741 - val_recall_32: 0.8015\n",
            "Epoch 5/100\n",
            "501/501 [==============================] - 11s 22ms/step - loss: 0.4312 - accuracy: 0.7982 - precision_32: 0.7890 - recall_32: 0.8311 - val_loss: 0.6402 - val_accuracy: 0.6960 - val_precision_32: 0.6799 - val_recall_32: 0.7847\n",
            "Epoch 6/100\n",
            "501/501 [==============================] - 13s 25ms/step - loss: 0.4200 - accuracy: 0.8068 - precision_32: 0.7995 - recall_32: 0.8347 - val_loss: 0.6481 - val_accuracy: 0.6970 - val_precision_32: 0.7025 - val_recall_32: 0.7237\n",
            "Epoch 7/100\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.4091 - accuracy: 0.8121 - precision_32: 0.8079 - recall_32: 0.8342 - val_loss: 0.6724 - val_accuracy: 0.6990 - val_precision_32: 0.7218 - val_recall_32: 0.6851\n",
            "Epoch 8/100\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.4045 - accuracy: 0.8151 - precision_32: 0.8107 - recall_32: 0.8370 - val_loss: 0.6625 - val_accuracy: 0.6999 - val_precision_32: 0.7157 - val_recall_32: 0.7014\n",
            "Epoch 9/100\n",
            "501/501 [==============================] - 12s 25ms/step - loss: 0.3910 - accuracy: 0.8238 - precision_32: 0.8207 - recall_32: 0.8426 - val_loss: 0.6810 - val_accuracy: 0.6947 - val_precision_32: 0.6867 - val_recall_32: 0.7592\n",
            "Epoch 10/100\n",
            "501/501 [==============================] - 11s 22ms/step - loss: 0.3801 - accuracy: 0.8293 - precision_32: 0.8262 - recall_32: 0.8473 - val_loss: 0.6953 - val_accuracy: 0.6930 - val_precision_32: 0.6825 - val_recall_32: 0.7657\n",
            "Epoch 11/100\n",
            "501/501 [==============================] - 10s 20ms/step - loss: 0.3712 - accuracy: 0.8324 - precision_32: 0.8311 - recall_32: 0.8472 - val_loss: 0.6610 - val_accuracy: 0.6959 - val_precision_32: 0.7080 - val_recall_32: 0.7064\n",
            "Epoch 12/100\n",
            "501/501 [==============================] - 12s 23ms/step - loss: 0.3620 - accuracy: 0.8387 - precision_32: 0.8370 - recall_32: 0.8536 - val_loss: 0.7183 - val_accuracy: 0.7009 - val_precision_32: 0.7244 - val_recall_32: 0.6853\n",
            "Epoch 13/100\n",
            "501/501 [==============================] - 12s 24ms/step - loss: 0.3506 - accuracy: 0.8443 - precision_32: 0.8427 - recall_32: 0.8585 - val_loss: 0.7310 - val_accuracy: 0.6977 - val_precision_32: 0.7302 - val_recall_32: 0.6639\n",
            "Accuracy  :  0.6853232383728027\n",
            "Precision :  0.6758913397789001\n",
            "Recall    :  0.7530947327613831\n",
            "F1- Score :  0.7124075142337329\n",
            "Batch size =  128\n",
            "Epoch 1/100\n",
            "251/251 [==============================] - 23s 41ms/step - loss: 0.4327 - accuracy: 0.7962 - precision_33: 0.7874 - recall_33: 0.8288 - val_loss: 0.6409 - val_accuracy: 0.6941 - val_precision_33: 0.6728 - val_recall_33: 0.8015\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 7s 27ms/step - loss: 0.4203 - accuracy: 0.8047 - precision_33: 0.7977 - recall_33: 0.8325 - val_loss: 0.6586 - val_accuracy: 0.6965 - val_precision_33: 0.7078 - val_recall_33: 0.7088\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 8s 33ms/step - loss: 0.4128 - accuracy: 0.8089 - precision_33: 0.8042 - recall_33: 0.8321 - val_loss: 0.6820 - val_accuracy: 0.6986 - val_precision_33: 0.7205 - val_recall_33: 0.6867\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 6s 26ms/step - loss: 0.4063 - accuracy: 0.8128 - precision_33: 0.8091 - recall_33: 0.8339 - val_loss: 0.6785 - val_accuracy: 0.6931 - val_precision_33: 0.7412 - val_recall_33: 0.6296\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 9s 35ms/step - loss: 0.3948 - accuracy: 0.8195 - precision_33: 0.8156 - recall_33: 0.8399 - val_loss: 0.7626 - val_accuracy: 0.6818 - val_precision_33: 0.6414 - val_recall_33: 0.8797\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 7s 27ms/step - loss: 0.3898 - accuracy: 0.8229 - precision_33: 0.8180 - recall_33: 0.8446 - val_loss: 0.6863 - val_accuracy: 0.6830 - val_precision_33: 0.7383 - val_recall_33: 0.6047\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 9s 35ms/step - loss: 0.3810 - accuracy: 0.8280 - precision_33: 0.8238 - recall_33: 0.8480 - val_loss: 0.7121 - val_accuracy: 0.6908 - val_precision_33: 0.6547 - val_recall_33: 0.8572\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 8s 33ms/step - loss: 0.3739 - accuracy: 0.8325 - precision_33: 0.8313 - recall_33: 0.8471 - val_loss: 0.7225 - val_accuracy: 0.6987 - val_precision_33: 0.6798 - val_recall_33: 0.7950\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 7s 28ms/step - loss: 0.3657 - accuracy: 0.8375 - precision_33: 0.8357 - recall_33: 0.8526 - val_loss: 0.7872 - val_accuracy: 0.6789 - val_precision_33: 0.7559 - val_recall_33: 0.5648\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 8s 34ms/step - loss: 0.3577 - accuracy: 0.8416 - precision_33: 0.8420 - recall_33: 0.8528 - val_loss: 0.7234 - val_accuracy: 0.7002 - val_precision_33: 0.7214 - val_recall_33: 0.6899\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 7s 26ms/step - loss: 0.3494 - accuracy: 0.8455 - precision_33: 0.8441 - recall_33: 0.8591 - val_loss: 0.7283 - val_accuracy: 0.6929 - val_precision_33: 0.6905 - val_recall_33: 0.7417\n",
            "Accuracy  :  0.689982533454895\n",
            "Precision :  0.6681771278381348\n",
            "Recall    :  0.7965338826179504\n",
            "F1- Score :  0.7267313731023219\n",
            "Batch size =  256\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 21s 74ms/step - loss: 0.4174 - accuracy: 0.8060 - precision_34: 0.7995 - recall_34: 0.8327 - val_loss: 0.6743 - val_accuracy: 0.6967 - val_precision_34: 0.6684 - val_recall_34: 0.8269\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.4114 - accuracy: 0.8088 - precision_34: 0.8040 - recall_34: 0.8323 - val_loss: 0.6765 - val_accuracy: 0.6886 - val_precision_34: 0.7480 - val_recall_34: 0.6049\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 7s 52ms/step - loss: 0.4064 - accuracy: 0.8125 - precision_34: 0.8081 - recall_34: 0.8346 - val_loss: 0.6440 - val_accuracy: 0.6931 - val_precision_34: 0.6999 - val_recall_34: 0.7172\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 5s 37ms/step - loss: 0.3969 - accuracy: 0.8168 - precision_34: 0.8104 - recall_34: 0.8418 - val_loss: 0.6745 - val_accuracy: 0.6999 - val_precision_34: 0.6955 - val_recall_34: 0.7518\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 5s 43ms/step - loss: 0.3919 - accuracy: 0.8202 - precision_34: 0.8149 - recall_34: 0.8427 - val_loss: 0.7171 - val_accuracy: 0.7075 - val_precision_34: 0.7178 - val_recall_34: 0.7206\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 5s 41ms/step - loss: 0.3857 - accuracy: 0.8248 - precision_34: 0.8186 - recall_34: 0.8484 - val_loss: 0.7316 - val_accuracy: 0.6957 - val_precision_34: 0.7283 - val_recall_34: 0.6615\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 4s 34ms/step - loss: 0.3825 - accuracy: 0.8260 - precision_34: 0.8218 - recall_34: 0.8461 - val_loss: 0.6836 - val_accuracy: 0.7026 - val_precision_34: 0.6980 - val_recall_34: 0.7544\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 6s 50ms/step - loss: 0.3761 - accuracy: 0.8300 - precision_34: 0.8255 - recall_34: 0.8501 - val_loss: 0.7976 - val_accuracy: 0.6734 - val_precision_34: 0.6308 - val_recall_34: 0.8965\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.3703 - accuracy: 0.8334 - precision_34: 0.8295 - recall_34: 0.8522 - val_loss: 0.7859 - val_accuracy: 0.6528 - val_precision_34: 0.7707 - val_recall_34: 0.4729\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 5s 38ms/step - loss: 0.3643 - accuracy: 0.8365 - precision_34: 0.8352 - recall_34: 0.8509 - val_loss: 0.7466 - val_accuracy: 0.6901 - val_precision_34: 0.6548 - val_recall_34: 0.8543\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 6s 50ms/step - loss: 0.3588 - accuracy: 0.8397 - precision_34: 0.8352 - recall_34: 0.8586 - val_loss: 0.8162 - val_accuracy: 0.6821 - val_precision_34: 0.6408 - val_recall_34: 0.8845\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.3530 - accuracy: 0.8440 - precision_34: 0.8394 - recall_34: 0.8626 - val_loss: 0.7490 - val_accuracy: 0.6893 - val_precision_34: 0.6573 - val_recall_34: 0.8406\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 4s 35ms/step - loss: 0.3436 - accuracy: 0.8455 - precision_34: 0.8438 - recall_34: 0.8595 - val_loss: 0.7083 - val_accuracy: 0.6934 - val_precision_34: 0.7217 - val_recall_34: 0.6678\n",
            "Accuracy  :  0.6856144666671753\n",
            "Precision :  0.6911861300468445\n",
            "Recall    :  0.7095431089401245\n",
            "F1- Score :  0.70024433262265\n",
            "Batch size =  512\n",
            "Epoch 1/100\n",
            "63/63 [==============================] - 22s 96ms/step - loss: 0.4007 - accuracy: 0.8161 - precision_35: 0.8084 - recall_35: 0.8435 - val_loss: 0.6755 - val_accuracy: 0.6915 - val_precision_35: 0.6654 - val_recall_35: 0.8181\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.3913 - accuracy: 0.8216 - precision_35: 0.8167 - recall_35: 0.8435 - val_loss: 0.6670 - val_accuracy: 0.7010 - val_precision_35: 0.6835 - val_recall_35: 0.7912\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.3896 - accuracy: 0.8188 - precision_35: 0.8137 - recall_35: 0.8415 - val_loss: 0.6725 - val_accuracy: 0.7049 - val_precision_35: 0.6920 - val_recall_35: 0.7792\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.3801 - accuracy: 0.8274 - precision_35: 0.8226 - recall_35: 0.8484 - val_loss: 0.6765 - val_accuracy: 0.6977 - val_precision_35: 0.6875 - val_recall_35: 0.7674\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.3769 - accuracy: 0.8292 - precision_35: 0.8242 - recall_35: 0.8502 - val_loss: 0.7188 - val_accuracy: 0.6991 - val_precision_35: 0.7249 - val_recall_35: 0.6788\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.3760 - accuracy: 0.8276 - precision_35: 0.8241 - recall_35: 0.8465 - val_loss: 0.6887 - val_accuracy: 0.6883 - val_precision_35: 0.7215 - val_recall_35: 0.6522\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 4s 66ms/step - loss: 0.3723 - accuracy: 0.8312 - precision_35: 0.8269 - recall_35: 0.8510 - val_loss: 0.7176 - val_accuracy: 0.7026 - val_precision_35: 0.7260 - val_recall_35: 0.6875\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 3s 51ms/step - loss: 0.3666 - accuracy: 0.8368 - precision_35: 0.8320 - recall_35: 0.8567 - val_loss: 0.6958 - val_accuracy: 0.7026 - val_precision_35: 0.7045 - val_recall_35: 0.7372\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.3654 - accuracy: 0.8353 - precision_35: 0.8334 - recall_35: 0.8508 - val_loss: 0.7482 - val_accuracy: 0.6738 - val_precision_35: 0.7648 - val_recall_35: 0.5379\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.3576 - accuracy: 0.8404 - precision_35: 0.8392 - recall_35: 0.8543 - val_loss: 0.7142 - val_accuracy: 0.7012 - val_precision_35: 0.6901 - val_recall_35: 0.7720\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.3582 - accuracy: 0.8403 - precision_35: 0.8400 - recall_35: 0.8529 - val_loss: 0.7232 - val_accuracy: 0.6989 - val_precision_35: 0.6735 - val_recall_35: 0.8169\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.3503 - accuracy: 0.8424 - precision_35: 0.8397 - recall_35: 0.8584 - val_loss: 0.7118 - val_accuracy: 0.7024 - val_precision_35: 0.6969 - val_recall_35: 0.7566\n",
            "Accuracy  :  0.694059431552887\n",
            "Precision :  0.6761027574539185\n",
            "Recall    :  0.7848300933837891\n",
            "F1- Score :  0.7264205058642252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGWpGGKQPHtV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}