{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsyDBkYPsiDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe87c35a-a414-4ed1-aa5e-6ceef19eee10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.83\n"
          ]
        }
      ],
      "source": [
        "# installing necessary libraries\n",
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from Bio.SeqUtils import ProtParam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, make_scorer, precision_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics as mt\n",
        "\n",
        "import warnings\n",
        "import sys\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "metadata": {
        "id": "LJ8R5ha1s_qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "df = pd.read_csv('/content/phospho_dataset.csv')"
      ],
      "metadata": {
        "id": "87q21Dh-2IWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df # displaying the dataset"
      ],
      "metadata": {
        "id": "4qZ8P67q22GC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "20ad0aa1-f47a-4f0d-f101-7ad21160fc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Extracted_Sequence  Target\n",
              "0        kfledmsyltlkanc       0\n",
              "1        snpsyrtstqevkle       0\n",
              "2        plvdpsvygygvqkr       0\n",
              "3        kinllihvgcalerm       1\n",
              "4        rirpqdsycphcgyy       1\n",
              "...                  ...     ...\n",
              "57230    talyftfssltsvgf       1\n",
              "57231    lhfirfpscamhrfi       0\n",
              "57232    rvlnrkssiiivnrn       0\n",
              "57233    pdqappsrrrrsdwa       1\n",
              "57234    feegistsrmgldpd       1\n",
              "\n",
              "[57235 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdba8826-16c4-4b0a-929b-8cc05667c680\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Extracted_Sequence</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kfledmsyltlkanc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>snpsyrtstqevkle</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plvdpsvygygvqkr</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kinllihvgcalerm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rirpqdsycphcgyy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57230</th>\n",
              "      <td>talyftfssltsvgf</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57231</th>\n",
              "      <td>lhfirfpscamhrfi</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57232</th>\n",
              "      <td>rvlnrkssiiivnrn</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57233</th>\n",
              "      <td>pdqappsrrrrsdwa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57234</th>\n",
              "      <td>feegistsrmgldpd</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57235 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdba8826-16c4-4b0a-929b-8cc05667c680')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cdba8826-16c4-4b0a-929b-8cc05667c680 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cdba8826-16c4-4b0a-929b-8cc05667c680');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38c3cabb-4e8e-4b4a-845c-1c9aa6d84aae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38c3cabb-4e8e-4b4a-845c-1c9aa6d84aae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38c3cabb-4e8e-4b4a-845c-1c9aa6d84aae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 57235,\n  \"fields\": [\n    {\n      \"column\": \"Extracted_Sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49302,\n        \"samples\": [\n          \"gryeimlslqsiltg\",\n          \"idvdaltrdieevmt\",\n          \"gscklrnsldssdsd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['length'] = df['Extracted_Sequence'].apply(len) # calculating the length of the sequence"
      ],
      "metadata": {
        "id": "2mm-ypagXYKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling dataset with replacement\n",
        "data1 = df.sample(frac=0.2, replace=True)\n",
        "data2 = df.sample(frac=0.2, replace=True)\n",
        "data3 = df.sample(frac=0.2, replace=True)\n",
        "data4 = df.sample(frac=0.2, replace=True)\n",
        "data5 = df.sample(frac=0.2, replace=True)\n",
        "data6 = df.sample(frac=0.2, replace=True)"
      ],
      "metadata": {
        "id": "P3a9F0J1xa0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to compute amiono acid composition\n",
        "def compute_aa_composition_features(data):\n",
        "    features = []\n",
        "    for seq in data['Extracted_Sequence']:\n",
        "\n",
        "        aa_comp = ProtParam.ProteinAnalysis(str(seq)).get_amino_acids_percent()\n",
        "\n",
        "        features.append(list(aa_comp.values()))\n",
        "\n",
        "    return np.array(features)\n",
        "\n"
      ],
      "metadata": {
        "id": "b_W7ht4xXgcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to extract features using protparam (approach1)\n",
        "def extract_feature(df):\n",
        "  df_aa = compute_aa_composition_features(df)\n",
        "  vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2,2)) # convert sequence to bigram\n",
        "  df_vectorized = vectorizer.fit_transform(df['Extracted_Sequence'])\n",
        "  df_vectorized = np.hstack([df_vectorized.toarray(), df['length'].values.reshape(-1,1), df_aa])\n",
        "  df_target = df['Target']\n",
        "  return df_vectorized, df_target"
      ],
      "metadata": {
        "id": "UVJakFVKHzuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML**"
      ],
      "metadata": {
        "id": "nQLbHeWJQo7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to print evaluation metrices i.e. precision, recall, f1 score, accuracy with k-fold cross validation\n",
        "def print_metrics(clf, x, y, cv):\n",
        "  print(\"\\nCross validation results by\"+ str(cv)+\"\\n\")\n",
        "  scoring = {\n",
        "      'precision': make_scorer(precision_score),\n",
        "      'recall': make_scorer(recall_score),\n",
        "      'f1_score': make_scorer(f1_score)\n",
        "  }\n",
        "  cross_val_results = cross_validate(clf, x, y, cv=cv, scoring = scoring)\n",
        "  accuracy = cross_val_score(clf, x, y, cv=cv, scoring = 'f1_macro')\n",
        "  print(\"Average Precision:\", cross_val_results['test_precision'].mean())\n",
        "  print(\"Average Recall:\", cross_val_results['test_recall'].mean())\n",
        "  print(\"Average F1 Score:\", cross_val_results['test_f1_score'].mean())\n",
        "  print(\"Average Accuracy Score:\", accuracy.mean())"
      ],
      "metadata": {
        "id": "7C4j0MA26OiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to print evaluation metrices i.e. precision, recall, f1 score, accuracy, confusion matrix and the classification report with test train split cross validation\n",
        "def metric_calculation(y_test,y_pred):\n",
        "  print(\"train_test split cross validation\\n\")\n",
        "  print(\"Accuracy  :  \",mt.accuracy_score(y_test,y_pred))\n",
        "  print(\"Precision :  \",mt.precision_score(y_test,y_pred))\n",
        "  print(\"Recall    :  \",mt.recall_score(y_test,y_pred))\n",
        "  print(\"F1-score  :  \",mt.f1_score(y_test,y_pred))\n",
        "  print(\"Confusion matrix      : \\n \",mt.confusion_matrix(y_test,y_pred))\n",
        "  print(\"Classification report : \\n\",mt.classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "tyfas2-96PlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train_model(data, target, model):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "  model.fit(x_train,y_train)\n",
        "  y_pred = model.predict(x_test)\n",
        "  metric_calculation(y_test,y_pred)\n",
        "  # num_folds = 10\n",
        "  # kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "  # str_kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "  # print_metrics(model, df_vectorized, df['Target'], kf)\n",
        "  # print_metrics(model, df_vectorized, df['Target'], str_kf)"
      ],
      "metadata": {
        "id": "XfrnNIBXXiWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# objects of different classifiers\n",
        "rf = RandomForestClassifier()\n",
        "nb = MultinomialNB()\n",
        "mlp = MLPClassifier()\n",
        "sgd = SGDClassifier(loss=\"log\")\n",
        "svc = SVC(probability=True)\n",
        "lr = LogisticRegression()"
      ],
      "metadata": {
        "id": "d6bZoQoqszj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features and target using protparam approach1\n",
        "data, target = extract_feature(df)\n",
        "data = pd.DataFrame(data)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xjez1_RarZP9",
        "outputId": "96c275ea-34b3-4c8d-ae0c-488fab8e5ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0    1    2    3    4    5    6    7    8         9    ...       415  \\\n",
              "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.066667   \n",
              "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
              "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
              "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.210399  ...  0.066667   \n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...       ...   \n",
              "57230  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.243195  ...  0.000000   \n",
              "57231  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.066667   \n",
              "57232  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
              "57233  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
              "57234  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.066667   \n",
              "\n",
              "            416       417       418       419       420       421       422  \\\n",
              "0      0.066667  0.000000  0.000000  0.000000  0.066667  0.066667  0.000000   \n",
              "1      0.066667  0.066667  0.066667  0.066667  0.200000  0.133333  0.066667   \n",
              "2      0.000000  0.133333  0.066667  0.066667  0.066667  0.000000  0.200000   \n",
              "3      0.066667  0.000000  0.000000  0.066667  0.000000  0.000000  0.066667   \n",
              "4      0.000000  0.133333  0.066667  0.133333  0.066667  0.000000  0.000000   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "57230  0.000000  0.000000  0.000000  0.000000  0.200000  0.200000  0.066667   \n",
              "57231  0.000000  0.066667  0.000000  0.133333  0.066667  0.000000  0.000000   \n",
              "57232  0.200000  0.000000  0.000000  0.200000  0.133333  0.000000  0.133333   \n",
              "57233  0.000000  0.200000  0.066667  0.266667  0.133333  0.000000  0.000000   \n",
              "57234  0.000000  0.066667  0.000000  0.066667  0.133333  0.066667  0.000000   \n",
              "\n",
              "            423       424  \n",
              "0      0.000000  0.066667  \n",
              "1      0.000000  0.066667  \n",
              "2      0.000000  0.133333  \n",
              "3      0.000000  0.000000  \n",
              "4      0.000000  0.200000  \n",
              "...         ...       ...  \n",
              "57230  0.000000  0.066667  \n",
              "57231  0.000000  0.000000  \n",
              "57232  0.000000  0.000000  \n",
              "57233  0.066667  0.000000  \n",
              "57234  0.000000  0.000000  \n",
              "\n",
              "[57235 rows x 425 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-781a8c5b-efeb-45b3-9ff8-342a6ef9772a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>415</th>\n",
              "      <th>416</th>\n",
              "      <th>417</th>\n",
              "      <th>418</th>\n",
              "      <th>419</th>\n",
              "      <th>420</th>\n",
              "      <th>421</th>\n",
              "      <th>422</th>\n",
              "      <th>423</th>\n",
              "      <th>424</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.210399</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57230</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.243195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57231</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57232</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57233</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57234</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57235 rows × 425 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-781a8c5b-efeb-45b3-9ff8-342a6ef9772a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-781a8c5b-efeb-45b3-9ff8-342a6ef9772a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-781a8c5b-efeb-45b3-9ff8-342a6ef9772a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cdb8e570-e942-4019-b3e7-67e7b37764d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdb8e570-e942-4019-b3e7-67e7b37764d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cdb8e570-e942-4019-b3e7-67e7b37764d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving dataset\n",
        "protparam_dataset_1 = pd.concat([data,target], axis=1)\n",
        "protparam_dataset_1.to_csv('protparam_features_dataset_1.csv')"
      ],
      "metadata": {
        "id": "qi8VqVfxmUFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from first approach and training with random forest\n",
        "data, target = extract_feature(data1)\n",
        "data = pd.DataFrame(data)\n",
        "train_model(data,target, rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WIEAWONzKAe",
        "outputId": "b3afa38c-c5dd-4ef0-8576-ed4bc31ff7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.7480349344978166\n",
            "Precision :   0.7437137330754352\n",
            "Recall    :   0.7113783533765032\n",
            "F1-score  :   0.7271867612293145\n",
            "Confusion matrix      : \n",
            "  [[944 265]\n",
            " [312 769]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.78      0.77      1209\n",
            "           1       0.74      0.71      0.73      1081\n",
            "\n",
            "    accuracy                           0.75      2290\n",
            "   macro avg       0.75      0.75      0.75      2290\n",
            "weighted avg       0.75      0.75      0.75      2290\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from first approach and training with naive bayes\n",
        "data, target = extract_feature(data2)\n",
        "train_model(data,target, nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bgUQKOAuI06",
        "outputId": "1458cc26-8db7-4c22-d212-d7f9b5968d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.6576419213973799\n",
            "Precision :   0.625\n",
            "Recall    :   0.6044487427466151\n",
            "F1-score  :   0.6145526057030483\n",
            "Confusion matrix      : \n",
            "  [[881 375]\n",
            " [409 625]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.70      0.69      1256\n",
            "           1       0.62      0.60      0.61      1034\n",
            "\n",
            "    accuracy                           0.66      2290\n",
            "   macro avg       0.65      0.65      0.65      2290\n",
            "weighted avg       0.66      0.66      0.66      2290\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from first approach and training with MLP\n",
        "data, target = extract_feature(data3)\n",
        "train_model(data,target, mlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUoEwtXjuv2G",
        "outputId": "e90de2ac-d38d-47e6-b041-6dbcda933f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.6877729257641921\n",
            "Precision :   0.6859099804305284\n",
            "Recall    :   0.6401826484018265\n",
            "F1-score  :   0.6622579121398205\n",
            "Confusion matrix      : \n",
            "  [[874 321]\n",
            " [394 701]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.73      0.71      1195\n",
            "           1       0.69      0.64      0.66      1095\n",
            "\n",
            "    accuracy                           0.69      2290\n",
            "   macro avg       0.69      0.69      0.69      2290\n",
            "weighted avg       0.69      0.69      0.69      2290\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from first approach and training with SGD\n",
        "data, target = extract_feature(data4)\n",
        "train_model(data,target, sgd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC9X417Bu2nL",
        "outputId": "2a4e33f3-b6ed-40af-acb0-2250f134d328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.5899563318777292\n",
            "Precision :   0.5386638611257233\n",
            "Recall    :   0.9429097605893186\n",
            "F1-score  :   0.6856377636424507\n",
            "Confusion matrix      : \n",
            "  [[ 327  877]\n",
            " [  62 1024]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.27      0.41      1204\n",
            "           1       0.54      0.94      0.69      1086\n",
            "\n",
            "    accuracy                           0.59      2290\n",
            "   macro avg       0.69      0.61      0.55      2290\n",
            "weighted avg       0.70      0.59      0.54      2290\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from first approach and training with SVM\n",
        "data, target = extract_feature(data5)\n",
        "train_model(data,target, svc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3q2ZA1iwihQ",
        "outputId": "51f25213-e739-4180-fa2e-028db5cc3774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.5580786026200873\n",
            "Precision :   0.7180327868852459\n",
            "Recall    :   0.19126637554585152\n",
            "F1-score  :   0.3020689655172414\n",
            "Confusion matrix      : \n",
            "  [[1059   86]\n",
            " [ 926  219]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.92      0.68      1145\n",
            "           1       0.72      0.19      0.30      1145\n",
            "\n",
            "    accuracy                           0.56      2290\n",
            "   macro avg       0.63      0.56      0.49      2290\n",
            "weighted avg       0.63      0.56      0.49      2290\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from first approach and training with Logistic Regression\n",
        "data, target = extract_feature(data6)\n",
        "train_model(data,target, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1IzBVOo97uA",
        "outputId": "e87b7eab-921a-41d7-d927-1d9437b625a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.6777292576419214\n",
            "Precision :   0.6932849364791288\n",
            "Recall    :   0.6563573883161512\n",
            "F1-score  :   0.6743159752868491\n",
            "Confusion matrix      : \n",
            "  [[788 338]\n",
            " [400 764]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.70      0.68      1126\n",
            "           1       0.69      0.66      0.67      1164\n",
            "\n",
            "    accuracy                           0.68      2290\n",
            "   macro avg       0.68      0.68      0.68      2290\n",
            "weighted avg       0.68      0.68      0.68      2290\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier  # importing voting classifier"
      ],
      "metadata": {
        "id": "WOH09V0FApbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining base estimators\n",
        "estimator = []\n",
        "estimator.append(('rf',  rf))\n",
        "estimator.append(('svc', svc))\n",
        "estimator.append(('mlp', mlp))\n",
        "estimator.append(('sgd', sgd))\n",
        "estimator.append(('lr', lr))\n",
        "estimator.append(('nb', nb))"
      ],
      "metadata": {
        "id": "M4NqThWvSjw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the complete dataset using voting classifier\n",
        "vc= VotingClassifier(estimators = estimator, voting ='soft')\n",
        "train_model(data,target, vc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yUrSjd3TYN_",
        "outputId": "be3ca43d-01bd-400b-c65e-af3866c5e254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.7362445414847162\n",
            "Precision :   0.7417962003454232\n",
            "Recall    :   0.7379725085910653\n",
            "F1-score  :   0.7398794142980188\n",
            "Confusion matrix      : \n",
            "  [[827 299]\n",
            " [305 859]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.73      0.73      1126\n",
            "           1       0.74      0.74      0.74      1164\n",
            "\n",
            "    accuracy                           0.74      2290\n",
            "   macro avg       0.74      0.74      0.74      2290\n",
            "weighted avg       0.74      0.74      0.74      2290\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DL**"
      ],
      "metadata": {
        "id": "-cUKq7wYQfeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries for DL\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn import decomposition as decom\n",
        "from keras.metrics import Precision, Recall"
      ],
      "metadata": {
        "id": "GjcgUUYlTsIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train DL model and print the evaluation metrics\n",
        "def train_model_dl(data, target, opt, epoch, batch):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(256, input_shape=(x_train.shape[1],), activation='relu'))\n",
        "  model.add(Dense(128, activation='tanh'))\n",
        "  model.add(Dense(64, activation='tanh'))\n",
        "  model.add(Dense(32, activation='tanh'))\n",
        "  model.add(Dense(16, activation='tanh'))\n",
        "  model.add(Dense(8, activation='tanh'))\n",
        "  model.add(Dense(4, activation='tanh'))\n",
        "  model.add(Dense(2, activation='tanh'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', Precision(), Recall()])\n",
        "  model.fit(x_train, y_train, epochs=epoch, batch_size=batch)\n",
        "  _, accuracy,precision,recall = model.evaluate(x_test, y_test, verbose=0)\n",
        "  try:\n",
        "    f1_score = (2*precision*recall)/(precision+recall)\n",
        "  except:\n",
        "    f1_score = (2*precision*recall)\n",
        "  print(\"Accuracy  : \", accuracy)\n",
        "  print(\"Precision : \", precision)\n",
        "  print(\"Recall    : \", recall)\n",
        "  print(\"F1-Score  : \", f1_score)"
      ],
      "metadata": {
        "id": "lPksEWMTTaDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features from first approach and training with DL model\n",
        "data, target = extract_feature(df)\n",
        "train_model_dl(data, target, \"adadelta\", 200, 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPtNuC8nYJCJ",
        "outputId": "d1a7f7fe-aed7-45fc-fd22-1c19e108c2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 3s 12ms/step - loss: 0.6989 - accuracy: 0.4748 - precision_9: 0.4748 - recall_9: 1.0000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6959 - accuracy: 0.4748 - precision_9: 0.4748 - recall_9: 1.0000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6941 - accuracy: 0.4760 - precision_9: 0.4741 - recall_9: 0.9467\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6930 - accuracy: 0.5072 - precision_9: 0.4779 - recall_9: 0.4115\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6924 - accuracy: 0.5275 - precision_9: 0.5330 - recall_9: 0.0394\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6921 - accuracy: 0.5254 - precision_9: 0.5797 - recall_9: 0.0018\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6919 - accuracy: 0.5252 - precision_9: 0.7500 - recall_9: 1.3799e-04\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6919 - accuracy: 0.5252 - precision_9: 1.0000 - recall_9: 4.5998e-05\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6918 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6918 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6918 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6918 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6917 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6917 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6917 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6917 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6917 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6917 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6916 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6916 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6916 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6915 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6915 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6915 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6915 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6915 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6915 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6914 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6914 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6914 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6914 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6913 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6913 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6913 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6913 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6912 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6912 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6912 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6912 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6912 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 51/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6912 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 52/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6911 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 53/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6911 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 54/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6911 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 55/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6911 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 56/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6911 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 57/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6911 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 58/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 59/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 60/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 61/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 62/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6910 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 63/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6910 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 64/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6909 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 65/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6909 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 66/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6909 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 67/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6909 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 68/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6909 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 69/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6909 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 70/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6908 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 71/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6908 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 72/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6908 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 73/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6908 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 74/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6908 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 75/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6907 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 76/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6907 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 77/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6907 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 78/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6907 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 79/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6907 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 80/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 81/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 82/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 83/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6906 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 84/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6906 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 85/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6905 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 86/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6905 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 87/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6905 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 88/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6905 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 89/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6905 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 90/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6904 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 91/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6904 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 92/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6904 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 93/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6904 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 94/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6903 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 95/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6903 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 96/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6903 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 97/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6903 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 98/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6902 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 99/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6902 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 100/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6902 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 101/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6902 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 102/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6901 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 103/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6901 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 104/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6901 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 105/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6901 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 106/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6900 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 107/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6900 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 108/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6900 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 109/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6900 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 110/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6899 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 4.5998e-05\n",
            "Epoch 111/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6899 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 112/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6899 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 113/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6898 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 4.5998e-05\n",
            "Epoch 114/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6898 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 115/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6898 - accuracy: 0.5252 - precision_9: 0.0000e+00 - recall_9: 0.0000e+00\n",
            "Epoch 116/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6898 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 9.1996e-05\n",
            "Epoch 117/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 4.5998e-05\n",
            "Epoch 118/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6897 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 4.5998e-05\n",
            "Epoch 119/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6897 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 4.5998e-05\n",
            "Epoch 120/200\n",
            "90/90 [==============================] - 2s 17ms/step - loss: 0.6896 - accuracy: 0.5252 - precision_9: 0.6667 - recall_9: 9.1996e-05\n",
            "Epoch 121/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6896 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 4.5998e-05\n",
            "Epoch 122/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6896 - accuracy: 0.5252 - precision_9: 0.6667 - recall_9: 9.1996e-05\n",
            "Epoch 123/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6895 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 1.3799e-04\n",
            "Epoch 124/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6895 - accuracy: 0.5252 - precision_9: 0.4286 - recall_9: 1.3799e-04\n",
            "Epoch 125/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6895 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 1.3799e-04\n",
            "Epoch 126/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6894 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 1.3799e-04\n",
            "Epoch 127/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6894 - accuracy: 0.5253 - precision_9: 0.7143 - recall_9: 2.2999e-04\n",
            "Epoch 128/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6894 - accuracy: 0.5252 - precision_9: 0.5455 - recall_9: 2.7599e-04\n",
            "Epoch 129/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6893 - accuracy: 0.5252 - precision_9: 0.5714 - recall_9: 1.8399e-04\n",
            "Epoch 130/200\n",
            "90/90 [==============================] - 2s 19ms/step - loss: 0.6893 - accuracy: 0.5252 - precision_9: 0.5714 - recall_9: 1.8399e-04\n",
            "Epoch 131/200\n",
            "90/90 [==============================] - 1s 15ms/step - loss: 0.6893 - accuracy: 0.5252 - precision_9: 0.6000 - recall_9: 2.7599e-04\n",
            "Epoch 132/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6892 - accuracy: 0.5252 - precision_9: 0.5000 - recall_9: 1.8399e-04\n",
            "Epoch 133/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6892 - accuracy: 0.5253 - precision_9: 0.6667 - recall_9: 2.7599e-04\n",
            "Epoch 134/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6891 - accuracy: 0.5252 - precision_9: 0.5833 - recall_9: 3.2199e-04\n",
            "Epoch 135/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6891 - accuracy: 0.5254 - precision_9: 0.7083 - recall_9: 7.8197e-04\n",
            "Epoch 136/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6891 - accuracy: 0.5252 - precision_9: 0.5333 - recall_9: 3.6799e-04\n",
            "Epoch 137/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6890 - accuracy: 0.5254 - precision_9: 0.6800 - recall_9: 7.8197e-04\n",
            "Epoch 138/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6890 - accuracy: 0.5254 - precision_9: 0.6522 - recall_9: 6.8997e-04\n",
            "Epoch 139/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6889 - accuracy: 0.5253 - precision_9: 0.6154 - recall_9: 3.6799e-04\n",
            "Epoch 140/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6889 - accuracy: 0.5253 - precision_9: 0.5938 - recall_9: 8.7397e-04\n",
            "Epoch 141/200\n",
            "90/90 [==============================] - 2s 18ms/step - loss: 0.6889 - accuracy: 0.5254 - precision_9: 0.6061 - recall_9: 9.1996e-04\n",
            "Epoch 142/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6888 - accuracy: 0.5254 - precision_9: 0.6452 - recall_9: 9.1996e-04\n",
            "Epoch 143/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6888 - accuracy: 0.5254 - precision_9: 0.6061 - recall_9: 9.1996e-04\n",
            "Epoch 144/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6887 - accuracy: 0.5253 - precision_9: 0.5758 - recall_9: 8.7397e-04\n",
            "Epoch 145/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6887 - accuracy: 0.5252 - precision_9: 0.5135 - recall_9: 0.0017\n",
            "Epoch 146/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6887 - accuracy: 0.5254 - precision_9: 0.6250 - recall_9: 0.0011\n",
            "Epoch 147/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6886 - accuracy: 0.5254 - precision_9: 0.6364 - recall_9: 9.6596e-04\n",
            "Epoch 148/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6886 - accuracy: 0.5255 - precision_9: 0.6056 - recall_9: 0.0020\n",
            "Epoch 149/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6885 - accuracy: 0.5253 - precision_9: 0.5417 - recall_9: 0.0018\n",
            "Epoch 150/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6885 - accuracy: 0.5255 - precision_9: 0.5714 - recall_9: 0.0022\n",
            "Epoch 151/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6884 - accuracy: 0.5256 - precision_9: 0.5667 - recall_9: 0.0031\n",
            "Epoch 152/200\n",
            "90/90 [==============================] - 2s 19ms/step - loss: 0.6884 - accuracy: 0.5253 - precision_9: 0.5301 - recall_9: 0.0020\n",
            "Epoch 153/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6884 - accuracy: 0.5257 - precision_9: 0.5932 - recall_9: 0.0032\n",
            "Epoch 154/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6883 - accuracy: 0.5254 - precision_9: 0.5567 - recall_9: 0.0025\n",
            "Epoch 155/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6883 - accuracy: 0.5256 - precision_9: 0.5664 - recall_9: 0.0037\n",
            "Epoch 156/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6882 - accuracy: 0.5258 - precision_9: 0.5759 - recall_9: 0.0051\n",
            "Epoch 157/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6882 - accuracy: 0.5255 - precision_9: 0.5497 - recall_9: 0.0038\n",
            "Epoch 158/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6881 - accuracy: 0.5255 - precision_9: 0.5591 - recall_9: 0.0033\n",
            "Epoch 159/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6881 - accuracy: 0.5257 - precision_9: 0.5840 - recall_9: 0.0034\n",
            "Epoch 160/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6880 - accuracy: 0.5258 - precision_9: 0.5747 - recall_9: 0.0046\n",
            "Epoch 161/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6880 - accuracy: 0.5261 - precision_9: 0.5921 - recall_9: 0.0062\n",
            "Epoch 162/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6879 - accuracy: 0.5261 - precision_9: 0.5676 - recall_9: 0.0077\n",
            "Epoch 163/200\n",
            "90/90 [==============================] - 2s 19ms/step - loss: 0.6879 - accuracy: 0.5259 - precision_9: 0.5615 - recall_9: 0.0063\n",
            "Epoch 164/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6878 - accuracy: 0.5259 - precision_9: 0.5552 - recall_9: 0.0072\n",
            "Epoch 165/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6878 - accuracy: 0.5263 - precision_9: 0.5699 - recall_9: 0.0096\n",
            "Epoch 166/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6877 - accuracy: 0.5259 - precision_9: 0.5641 - recall_9: 0.0061\n",
            "Epoch 167/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6877 - accuracy: 0.5264 - precision_9: 0.5914 - recall_9: 0.0082\n",
            "Epoch 168/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6876 - accuracy: 0.5263 - precision_9: 0.5820 - recall_9: 0.0083\n",
            "Epoch 169/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6876 - accuracy: 0.5269 - precision_9: 0.5946 - recall_9: 0.0111\n",
            "Epoch 170/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6875 - accuracy: 0.5273 - precision_9: 0.6174 - recall_9: 0.0117\n",
            "Epoch 171/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6875 - accuracy: 0.5272 - precision_9: 0.6051 - recall_9: 0.0121\n",
            "Epoch 172/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6874 - accuracy: 0.5272 - precision_9: 0.6042 - recall_9: 0.0120\n",
            "Epoch 173/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6874 - accuracy: 0.5270 - precision_9: 0.5985 - recall_9: 0.0112\n",
            "Epoch 174/200\n",
            "90/90 [==============================] - 2s 19ms/step - loss: 0.6873 - accuracy: 0.5294 - precision_9: 0.6361 - recall_9: 0.0204\n",
            "Epoch 175/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6872 - accuracy: 0.5281 - precision_9: 0.6214 - recall_9: 0.0158\n",
            "Epoch 176/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6872 - accuracy: 0.5276 - precision_9: 0.6050 - recall_9: 0.0146\n",
            "Epoch 177/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6871 - accuracy: 0.5277 - precision_9: 0.6088 - recall_9: 0.0147\n",
            "Epoch 178/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6871 - accuracy: 0.5294 - precision_9: 0.6448 - recall_9: 0.0199\n",
            "Epoch 179/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6870 - accuracy: 0.5299 - precision_9: 0.6431 - recall_9: 0.0222\n",
            "Epoch 180/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6870 - accuracy: 0.5291 - precision_9: 0.6313 - recall_9: 0.0197\n",
            "Epoch 181/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6869 - accuracy: 0.5299 - precision_9: 0.6381 - recall_9: 0.0226\n",
            "Epoch 182/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6868 - accuracy: 0.5323 - precision_9: 0.6433 - recall_9: 0.0333\n",
            "Epoch 183/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6868 - accuracy: 0.5280 - precision_9: 0.6226 - recall_9: 0.0152\n",
            "Epoch 184/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6867 - accuracy: 0.5307 - precision_9: 0.6416 - recall_9: 0.0263\n",
            "Epoch 185/200\n",
            "90/90 [==============================] - 2s 19ms/step - loss: 0.6866 - accuracy: 0.5302 - precision_9: 0.6402 - recall_9: 0.0241\n",
            "Epoch 186/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6866 - accuracy: 0.5324 - precision_9: 0.6523 - recall_9: 0.0326\n",
            "Epoch 187/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6865 - accuracy: 0.5323 - precision_9: 0.6491 - recall_9: 0.0323\n",
            "Epoch 188/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6865 - accuracy: 0.5314 - precision_9: 0.6369 - recall_9: 0.0305\n",
            "Epoch 189/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.6864 - accuracy: 0.5348 - precision_9: 0.6567 - recall_9: 0.0424\n",
            "Epoch 190/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6863 - accuracy: 0.5346 - precision_9: 0.6503 - recall_9: 0.0428\n",
            "Epoch 191/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6863 - accuracy: 0.5320 - precision_9: 0.6538 - recall_9: 0.0303\n",
            "Epoch 192/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6862 - accuracy: 0.5346 - precision_9: 0.6548 - recall_9: 0.0416\n",
            "Epoch 193/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6861 - accuracy: 0.5345 - precision_9: 0.6543 - recall_9: 0.0414\n",
            "Epoch 194/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6861 - accuracy: 0.5357 - precision_9: 0.6545 - recall_9: 0.0470\n",
            "Epoch 195/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6860 - accuracy: 0.5384 - precision_9: 0.6636 - recall_9: 0.0564\n",
            "Epoch 196/200\n",
            "90/90 [==============================] - 2s 20ms/step - loss: 0.6859 - accuracy: 0.5351 - precision_9: 0.6619 - recall_9: 0.0428\n",
            "Epoch 197/200\n",
            "90/90 [==============================] - 1s 16ms/step - loss: 0.6859 - accuracy: 0.5356 - precision_9: 0.6572 - recall_9: 0.0457\n",
            "Epoch 198/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6858 - accuracy: 0.5385 - precision_9: 0.6647 - recall_9: 0.0563\n",
            "Epoch 199/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6857 - accuracy: 0.5425 - precision_9: 0.6744 - recall_9: 0.0706\n",
            "Epoch 200/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.6857 - accuracy: 0.5359 - precision_9: 0.6603 - recall_9: 0.0462\n",
            "Accuracy  :  0.5331528186798096\n",
            "Precision :  0.6500993967056274\n",
            "Recall    :  0.05950864404439926\n",
            "F1-Score  :  0.1090363450536547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to split amino_acid_composition feature to multiple features\n",
        "def expand_amino_acid_composition(data):\n",
        "    return pd.Series(data['amino_acid_composition'])\n",
        "# function to split secondary_structure_fraction feature to multiple features\n",
        "def expand_secondary_structure_fraction(data):\n",
        "    return pd.Series(data['secondary_structure_fraction'])"
      ],
      "metadata": {
        "id": "engxgDbwdAd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to extract features using protparam (approach2)\n",
        "def get_features(data):\n",
        "  features = []\n",
        "  for seq in data['Extracted_Sequence']:\n",
        "    try:\n",
        "      # extracting features\n",
        "      aa_comp = ProtParam.ProteinAnalysis(str(seq)).get_amino_acids_percent()\n",
        "      mol_wt = ProtParam.ProteinAnalysis(str(seq)).molecular_weight()\n",
        "      aroma = ProtParam.ProteinAnalysis(str(seq)).aromaticity()\n",
        "      insta_ind = ProtParam.ProteinAnalysis(str(seq)).instability_index()\n",
        "      isoelec_pnt = ProtParam.ProteinAnalysis(str(seq)).isoelectric_point()\n",
        "      sec_struc_frac = ProtParam.ProteinAnalysis(str(seq)).secondary_structure_fraction()\n",
        "      feature = {\n",
        "          \"amino_acid_composition\": aa_comp,\n",
        "          \"molecular_weight\": mol_wt,\n",
        "          \"aromaticity\": aroma,\n",
        "          \"instability_index\": insta_ind,\n",
        "          \"isoelectric_point\": isoelec_pnt,\n",
        "          \"secondary_structure_fraction\": sec_struc_frac\n",
        "      }\n",
        "    except:\n",
        "      pass\n",
        "    features.append(feature)\n",
        "  features = pd.DataFrame(features)\n",
        "  amino_comp_df = features.apply(expand_amino_acid_composition, axis=1)\n",
        "  secondary_structure_fraction_df = features.apply(expand_secondary_structure_fraction, axis=1)\n",
        "  secondary_structure_fraction_df.columns = ['secondary_structure_fraction_x','secondary_structure_fraction_y','secondary_structure_fraction_z']\n",
        "  features = pd.concat([features, amino_comp_df, secondary_structure_fraction_df], axis=1)\n",
        "  features.drop(['amino_acid_composition', 'secondary_structure_fraction'], axis=1, inplace=True)\n",
        "  return features, data['Target']"
      ],
      "metadata": {
        "id": "-qNovBrH-p4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features and target using protparam approach2\n",
        "data, target  = get_features(df)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "FlbBeOTbb3u0",
        "outputId": "89049bbf-b89f-4ca6-80b5-2153ffbf122d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       molecular_weight  aromaticity  instability_index  isoelectric_point  \\\n",
              "0             1776.0817     0.133333          43.886667           6.061162   \n",
              "1             1738.8498     0.066667           9.213333           6.005972   \n",
              "2             1677.8972     0.133333          11.880000           8.902649   \n",
              "3             1710.1163     0.000000           6.240000           8.231146   \n",
              "4             1858.0646     0.200000          76.100000           8.042447   \n",
              "...                 ...          ...                ...                ...   \n",
              "57230         1640.8289     0.266667          24.740000           5.184876   \n",
              "57231         1875.2688     0.200000          88.020000          10.352349   \n",
              "57232         1782.0995     0.000000          24.740000          11.999968   \n",
              "57233         1794.9280     0.066667         189.500000          11.523289   \n",
              "57234         1653.7651     0.066667          33.220000           4.124203   \n",
              "\n",
              "              A         C         D         E         F         G  ...  \\\n",
              "0      0.066667  0.066667  0.066667  0.066667  0.066667  0.000000  ...   \n",
              "1      0.000000  0.000000  0.000000  0.133333  0.000000  0.000000  ...   \n",
              "2      0.000000  0.000000  0.066667  0.000000  0.000000  0.133333  ...   \n",
              "3      0.066667  0.066667  0.000000  0.066667  0.000000  0.066667  ...   \n",
              "4      0.000000  0.133333  0.066667  0.000000  0.000000  0.066667  ...   \n",
              "...         ...       ...       ...       ...       ...       ...  ...   \n",
              "57230  0.066667  0.000000  0.000000  0.000000  0.200000  0.066667  ...   \n",
              "57231  0.066667  0.066667  0.000000  0.000000  0.200000  0.000000  ...   \n",
              "57232  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  ...   \n",
              "57233  0.133333  0.000000  0.133333  0.000000  0.000000  0.000000  ...   \n",
              "57234  0.000000  0.000000  0.133333  0.133333  0.066667  0.133333  ...   \n",
              "\n",
              "              Q         R         S         T         V         W         Y  \\\n",
              "0      0.000000  0.000000  0.066667  0.066667  0.000000  0.000000  0.066667   \n",
              "1      0.066667  0.066667  0.200000  0.133333  0.066667  0.000000  0.066667   \n",
              "2      0.066667  0.066667  0.066667  0.000000  0.200000  0.000000  0.133333   \n",
              "3      0.000000  0.066667  0.000000  0.000000  0.066667  0.000000  0.000000   \n",
              "4      0.066667  0.133333  0.066667  0.000000  0.000000  0.000000  0.200000   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "57230  0.000000  0.000000  0.200000  0.200000  0.066667  0.000000  0.066667   \n",
              "57231  0.000000  0.133333  0.066667  0.000000  0.000000  0.000000  0.000000   \n",
              "57232  0.000000  0.200000  0.133333  0.000000  0.133333  0.000000  0.000000   \n",
              "57233  0.066667  0.266667  0.133333  0.000000  0.000000  0.066667  0.000000   \n",
              "57234  0.000000  0.066667  0.133333  0.066667  0.000000  0.000000  0.000000   \n",
              "\n",
              "       secondary_structure_fraction_x  secondary_structure_fraction_y  \\\n",
              "0                            0.533333                        0.200000   \n",
              "1                            0.266667                        0.333333   \n",
              "2                            0.133333                        0.400000   \n",
              "3                            0.466667                        0.133333   \n",
              "4                            0.000000                        0.333333   \n",
              "...                               ...                             ...   \n",
              "57230                        0.200000                        0.266667   \n",
              "57231                        0.200000                        0.133333   \n",
              "57232                        0.133333                        0.333333   \n",
              "57233                        0.133333                        0.466667   \n",
              "57234                        0.266667                        0.466667   \n",
              "\n",
              "       secondary_structure_fraction_z  \n",
              "0                            0.400000  \n",
              "1                            0.333333  \n",
              "2                            0.400000  \n",
              "3                            0.400000  \n",
              "4                            0.266667  \n",
              "...                               ...  \n",
              "57230                        0.666667  \n",
              "57231                        0.400000  \n",
              "57232                        0.400000  \n",
              "57233                        0.066667  \n",
              "57234                        0.266667  \n",
              "\n",
              "[57235 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3c31700-ff83-4f94-87e5-a1329f550d40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>molecular_weight</th>\n",
              "      <th>aromaticity</th>\n",
              "      <th>instability_index</th>\n",
              "      <th>isoelectric_point</th>\n",
              "      <th>A</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>...</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>Y</th>\n",
              "      <th>secondary_structure_fraction_x</th>\n",
              "      <th>secondary_structure_fraction_y</th>\n",
              "      <th>secondary_structure_fraction_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1776.0817</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>43.886667</td>\n",
              "      <td>6.061162</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1738.8498</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>9.213333</td>\n",
              "      <td>6.005972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1677.8972</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>11.880000</td>\n",
              "      <td>8.902649</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1710.1163</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.240000</td>\n",
              "      <td>8.231146</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1858.0646</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>76.100000</td>\n",
              "      <td>8.042447</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57230</th>\n",
              "      <td>1640.8289</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>24.740000</td>\n",
              "      <td>5.184876</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57231</th>\n",
              "      <td>1875.2688</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>88.020000</td>\n",
              "      <td>10.352349</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57232</th>\n",
              "      <td>1782.0995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.740000</td>\n",
              "      <td>11.999968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57233</th>\n",
              "      <td>1794.9280</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>189.500000</td>\n",
              "      <td>11.523289</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57234</th>\n",
              "      <td>1653.7651</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>33.220000</td>\n",
              "      <td>4.124203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57235 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3c31700-ff83-4f94-87e5-a1329f550d40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3c31700-ff83-4f94-87e5-a1329f550d40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3c31700-ff83-4f94-87e5-a1329f550d40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fa68d2f3-4652-4cfd-ab2d-c0ff3c70e016\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa68d2f3-4652-4cfd-ab2d-c0ff3c70e016')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fa68d2f3-4652-4cfd-ab2d-c0ff3c70e016 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving dataset\n",
        "protparam_dataset_2 = pd.concat([data,target], axis=1)\n",
        "protparam_dataset_2.to_csv('protparam_features_dataset_2.csv')"
      ],
      "metadata": {
        "id": "-TdqBZeFnftp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the dataset\n",
        "sc = StandardScaler()\n",
        "data = pd.DataFrame(sc.fit_transform(data))\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "HunC64IkRSdT",
        "outputId": "6da41b4a-5f94-4b8b-9d4b-862b954eebfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6   \\\n",
              "0      0.848501  0.972899 -0.202420 -0.448158 -0.028373  1.983244  0.242326   \n",
              "1      0.569682  0.030539 -1.026712 -0.469666 -0.935374 -0.346494 -0.834830   \n",
              "2      0.113224  0.972899 -0.963317  0.659175 -0.935374 -0.346494  0.242326   \n",
              "3      0.354504 -0.911822 -1.097398  0.397489 -0.028373  1.983244 -0.834830   \n",
              "4      1.462449  1.915260  0.563391  0.323953 -0.935374  4.312982  0.242326   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "57230 -0.164370  2.857620 -0.657595 -0.789649 -0.028373 -0.346494 -0.834830   \n",
              "57231  1.591286  1.915260  0.846766  1.224126 -0.028373  1.983244 -0.834830   \n",
              "57232  0.893567 -0.911822 -0.657595  1.866207 -0.935374 -0.346494 -0.834830   \n",
              "57233  0.989636  0.030539  3.259260  1.680444  0.878628 -0.346494  1.319482   \n",
              "57234 -0.067495  0.030539 -0.456000 -1.202996 -0.935374 -0.346494  1.319482   \n",
              "\n",
              "             7         8         9   ...        17        18        19  \\\n",
              "0     -0.003878  0.988494 -0.909672  ... -0.729270 -0.967121 -0.566084   \n",
              "1      0.893617 -0.602830 -0.909672  ...  0.540207 -0.002245  0.657754   \n",
              "2     -0.901372 -0.602830  0.826194  ...  0.540207 -0.002245 -0.566084   \n",
              "3     -0.003878 -0.602830 -0.041739  ... -0.729270 -0.002245 -1.178003   \n",
              "4     -0.901372 -0.602830 -0.041739  ...  0.540207  0.962631 -0.566084   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "57230 -0.901372  4.171143 -0.041739  ... -0.729270 -0.967121  0.657754   \n",
              "57231 -0.901372  4.171143 -0.909672  ... -0.729270  0.962631 -0.566084   \n",
              "57232 -0.901372 -0.602830 -0.909672  ... -0.729270  1.927507  0.045835   \n",
              "57233 -0.901372 -0.602830 -0.909672  ...  0.540207  2.892383  0.045835   \n",
              "57234  0.893617  0.988494  0.826194  ... -0.729270 -0.002245  0.045835   \n",
              "\n",
              "             20        21        22        23        24        25        26  \n",
              "0     -0.025716 -0.890686 -0.302629  0.669395  1.766328 -0.965916  0.735952  \n",
              "1      0.940067  0.218443 -0.302629  0.669395 -0.195765 -0.080520  0.226248  \n",
              "2     -0.991499  2.436699 -0.302629  1.990636 -1.176812  0.362178  0.735952  \n",
              "3     -0.991499  0.218443 -0.302629 -0.651847  1.275804 -1.408613  0.735952  \n",
              "4     -0.991499 -0.890686 -0.302629  3.311878 -2.157859 -0.080520 -0.283457  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "57230  1.905851  0.218443 -0.302629  0.669395 -0.686289 -0.523218  2.774769  \n",
              "57231 -0.991499 -0.890686 -0.302629 -0.651847 -0.686289 -1.408613  0.735952  \n",
              "57232 -0.991499  1.327571 -0.302629 -0.651847 -1.176812 -0.080520  0.735952  \n",
              "57233 -0.991499 -0.890686  2.869210 -0.651847 -1.176812  0.804876 -1.812569  \n",
              "57234 -0.025716 -0.890686 -0.302629 -0.651847 -0.195765  0.804876 -0.283457  \n",
              "\n",
              "[57235 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3165546a-303b-4b6a-814c-f4b4198d8e4f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.848501</td>\n",
              "      <td>0.972899</td>\n",
              "      <td>-0.202420</td>\n",
              "      <td>-0.448158</td>\n",
              "      <td>-0.028373</td>\n",
              "      <td>1.983244</td>\n",
              "      <td>0.242326</td>\n",
              "      <td>-0.003878</td>\n",
              "      <td>0.988494</td>\n",
              "      <td>-0.909672</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729270</td>\n",
              "      <td>-0.967121</td>\n",
              "      <td>-0.566084</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.890686</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>0.669395</td>\n",
              "      <td>1.766328</td>\n",
              "      <td>-0.965916</td>\n",
              "      <td>0.735952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.569682</td>\n",
              "      <td>0.030539</td>\n",
              "      <td>-1.026712</td>\n",
              "      <td>-0.469666</td>\n",
              "      <td>-0.935374</td>\n",
              "      <td>-0.346494</td>\n",
              "      <td>-0.834830</td>\n",
              "      <td>0.893617</td>\n",
              "      <td>-0.602830</td>\n",
              "      <td>-0.909672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.540207</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>0.657754</td>\n",
              "      <td>0.940067</td>\n",
              "      <td>0.218443</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>0.669395</td>\n",
              "      <td>-0.195765</td>\n",
              "      <td>-0.080520</td>\n",
              "      <td>0.226248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.113224</td>\n",
              "      <td>0.972899</td>\n",
              "      <td>-0.963317</td>\n",
              "      <td>0.659175</td>\n",
              "      <td>-0.935374</td>\n",
              "      <td>-0.346494</td>\n",
              "      <td>0.242326</td>\n",
              "      <td>-0.901372</td>\n",
              "      <td>-0.602830</td>\n",
              "      <td>0.826194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.540207</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>-0.566084</td>\n",
              "      <td>-0.991499</td>\n",
              "      <td>2.436699</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>1.990636</td>\n",
              "      <td>-1.176812</td>\n",
              "      <td>0.362178</td>\n",
              "      <td>0.735952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.354504</td>\n",
              "      <td>-0.911822</td>\n",
              "      <td>-1.097398</td>\n",
              "      <td>0.397489</td>\n",
              "      <td>-0.028373</td>\n",
              "      <td>1.983244</td>\n",
              "      <td>-0.834830</td>\n",
              "      <td>-0.003878</td>\n",
              "      <td>-0.602830</td>\n",
              "      <td>-0.041739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729270</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>-1.178003</td>\n",
              "      <td>-0.991499</td>\n",
              "      <td>0.218443</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>-0.651847</td>\n",
              "      <td>1.275804</td>\n",
              "      <td>-1.408613</td>\n",
              "      <td>0.735952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.462449</td>\n",
              "      <td>1.915260</td>\n",
              "      <td>0.563391</td>\n",
              "      <td>0.323953</td>\n",
              "      <td>-0.935374</td>\n",
              "      <td>4.312982</td>\n",
              "      <td>0.242326</td>\n",
              "      <td>-0.901372</td>\n",
              "      <td>-0.602830</td>\n",
              "      <td>-0.041739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.540207</td>\n",
              "      <td>0.962631</td>\n",
              "      <td>-0.566084</td>\n",
              "      <td>-0.991499</td>\n",
              "      <td>-0.890686</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>3.311878</td>\n",
              "      <td>-2.157859</td>\n",
              "      <td>-0.080520</td>\n",
              "      <td>-0.283457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57230</th>\n",
              "      <td>-0.164370</td>\n",
              "      <td>2.857620</td>\n",
              "      <td>-0.657595</td>\n",
              "      <td>-0.789649</td>\n",
              "      <td>-0.028373</td>\n",
              "      <td>-0.346494</td>\n",
              "      <td>-0.834830</td>\n",
              "      <td>-0.901372</td>\n",
              "      <td>4.171143</td>\n",
              "      <td>-0.041739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729270</td>\n",
              "      <td>-0.967121</td>\n",
              "      <td>0.657754</td>\n",
              "      <td>1.905851</td>\n",
              "      <td>0.218443</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>0.669395</td>\n",
              "      <td>-0.686289</td>\n",
              "      <td>-0.523218</td>\n",
              "      <td>2.774769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57231</th>\n",
              "      <td>1.591286</td>\n",
              "      <td>1.915260</td>\n",
              "      <td>0.846766</td>\n",
              "      <td>1.224126</td>\n",
              "      <td>-0.028373</td>\n",
              "      <td>1.983244</td>\n",
              "      <td>-0.834830</td>\n",
              "      <td>-0.901372</td>\n",
              "      <td>4.171143</td>\n",
              "      <td>-0.909672</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729270</td>\n",
              "      <td>0.962631</td>\n",
              "      <td>-0.566084</td>\n",
              "      <td>-0.991499</td>\n",
              "      <td>-0.890686</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>-0.651847</td>\n",
              "      <td>-0.686289</td>\n",
              "      <td>-1.408613</td>\n",
              "      <td>0.735952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57232</th>\n",
              "      <td>0.893567</td>\n",
              "      <td>-0.911822</td>\n",
              "      <td>-0.657595</td>\n",
              "      <td>1.866207</td>\n",
              "      <td>-0.935374</td>\n",
              "      <td>-0.346494</td>\n",
              "      <td>-0.834830</td>\n",
              "      <td>-0.901372</td>\n",
              "      <td>-0.602830</td>\n",
              "      <td>-0.909672</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729270</td>\n",
              "      <td>1.927507</td>\n",
              "      <td>0.045835</td>\n",
              "      <td>-0.991499</td>\n",
              "      <td>1.327571</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>-0.651847</td>\n",
              "      <td>-1.176812</td>\n",
              "      <td>-0.080520</td>\n",
              "      <td>0.735952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57233</th>\n",
              "      <td>0.989636</td>\n",
              "      <td>0.030539</td>\n",
              "      <td>3.259260</td>\n",
              "      <td>1.680444</td>\n",
              "      <td>0.878628</td>\n",
              "      <td>-0.346494</td>\n",
              "      <td>1.319482</td>\n",
              "      <td>-0.901372</td>\n",
              "      <td>-0.602830</td>\n",
              "      <td>-0.909672</td>\n",
              "      <td>...</td>\n",
              "      <td>0.540207</td>\n",
              "      <td>2.892383</td>\n",
              "      <td>0.045835</td>\n",
              "      <td>-0.991499</td>\n",
              "      <td>-0.890686</td>\n",
              "      <td>2.869210</td>\n",
              "      <td>-0.651847</td>\n",
              "      <td>-1.176812</td>\n",
              "      <td>0.804876</td>\n",
              "      <td>-1.812569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57234</th>\n",
              "      <td>-0.067495</td>\n",
              "      <td>0.030539</td>\n",
              "      <td>-0.456000</td>\n",
              "      <td>-1.202996</td>\n",
              "      <td>-0.935374</td>\n",
              "      <td>-0.346494</td>\n",
              "      <td>1.319482</td>\n",
              "      <td>0.893617</td>\n",
              "      <td>0.988494</td>\n",
              "      <td>0.826194</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.729270</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>0.045835</td>\n",
              "      <td>-0.025716</td>\n",
              "      <td>-0.890686</td>\n",
              "      <td>-0.302629</td>\n",
              "      <td>-0.651847</td>\n",
              "      <td>-0.195765</td>\n",
              "      <td>0.804876</td>\n",
              "      <td>-0.283457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57235 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3165546a-303b-4b6a-814c-f4b4198d8e4f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3165546a-303b-4b6a-814c-f4b4198d8e4f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3165546a-303b-4b6a-814c-f4b4198d8e4f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9cb5946e-b355-49a8-b818-65f9df743b7b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cb5946e-b355-49a8-b818-65f9df743b7b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9cb5946e-b355-49a8-b818-65f9df743b7b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taining random forest on features obtained from approach 2\n",
        "train_model(data,target, rf)"
      ],
      "metadata": {
        "id": "4o_BhqYJoMaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taining MLP on features obtained from approach 2\n",
        "train_model(data,target, mlp)"
      ],
      "metadata": {
        "id": "cm5_TpnGrI5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taining Logistic regression on features obtained from approach 2\n",
        "train_model(data,target, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcUuXgMcripc",
        "outputId": "4894c127-6914-448f-f237-a369eaa6bb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.6372848781340089\n",
            "Precision :   0.6249302325581395\n",
            "Recall    :   0.6112829845313922\n",
            "F1-score  :   0.61803127874885\n",
            "Confusion matrix      : \n",
            "  [[3936 2016]\n",
            " [2136 3359]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.66      0.65      5952\n",
            "           1       0.62      0.61      0.62      5495\n",
            "\n",
            "    accuracy                           0.64     11447\n",
            "   macro avg       0.64      0.64      0.64     11447\n",
            "weighted avg       0.64      0.64      0.64     11447\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taining SGD on features obtained from approach 2\n",
        "train_model(data,target, sgd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUuEVvL7rqqN",
        "outputId": "7c1afd4d-b674-48b7-b6f2-d862480a60b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test split cross validation\n",
            "\n",
            "Accuracy  :   0.6204245653883114\n",
            "Precision :   0.5984926344638575\n",
            "Recall    :   0.6358507734303913\n",
            "F1-score  :   0.6166063707756111\n",
            "Confusion matrix      : \n",
            "  [[3608 2344]\n",
            " [2001 3494]]\n",
            "Classification report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.61      0.62      5952\n",
            "           1       0.60      0.64      0.62      5495\n",
            "\n",
            "    accuracy                           0.62     11447\n",
            "   macro avg       0.62      0.62      0.62     11447\n",
            "weighted avg       0.62      0.62      0.62     11447\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training dl model with different optimizer with different batch sizes and for different no. of itterations"
      ],
      "metadata": {
        "id": "73rI8OelQAre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 200, 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5shiGfurzAC",
        "outputId": "65debbdc-15b3-4d07-a13a-157eedf95a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "90/90 [==============================] - 2s 7ms/step - loss: 0.6332 - accuracy: 0.6483 - precision: 0.6288 - recall: 0.6327\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6174 - accuracy: 0.6682 - precision: 0.6489 - recall: 0.6564\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6085 - accuracy: 0.6749 - precision: 0.6535 - recall: 0.6713\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6021 - accuracy: 0.6806 - precision: 0.6597 - recall: 0.6759\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5971 - accuracy: 0.6839 - precision: 0.6610 - recall: 0.6863\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5916 - accuracy: 0.6880 - precision: 0.6666 - recall: 0.6861\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5871 - accuracy: 0.6925 - precision: 0.6699 - recall: 0.6944\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5827 - accuracy: 0.6964 - precision: 0.6744 - recall: 0.6971\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.5782 - accuracy: 0.7005 - precision: 0.6792 - recall: 0.6998\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.5727 - accuracy: 0.7049 - precision: 0.6818 - recall: 0.7098\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.5687 - accuracy: 0.7087 - precision: 0.6865 - recall: 0.7114\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5617 - accuracy: 0.7139 - precision: 0.6934 - recall: 0.7126\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5564 - accuracy: 0.7188 - precision: 0.6982 - recall: 0.7182\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5514 - accuracy: 0.7230 - precision: 0.7009 - recall: 0.7266\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5469 - accuracy: 0.7274 - precision: 0.7049 - recall: 0.7324\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5414 - accuracy: 0.7305 - precision: 0.7096 - recall: 0.7319\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5363 - accuracy: 0.7362 - precision: 0.7158 - recall: 0.7371\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5310 - accuracy: 0.7396 - precision: 0.7181 - recall: 0.7435\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.7446 - precision: 0.7222 - recall: 0.7508\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5207 - accuracy: 0.7461 - precision: 0.7257 - recall: 0.7480\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5139 - accuracy: 0.7521 - precision: 0.7308 - recall: 0.7566\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.7573 - precision: 0.7371 - recall: 0.7598\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.5035 - accuracy: 0.7609 - precision: 0.7393 - recall: 0.7667\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4981 - accuracy: 0.7644 - precision: 0.7443 - recall: 0.7674\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4916 - accuracy: 0.7701 - precision: 0.7502 - recall: 0.7734\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4853 - accuracy: 0.7732 - precision: 0.7532 - recall: 0.7767\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.4802 - accuracy: 0.7769 - precision: 0.7578 - recall: 0.7792\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4756 - accuracy: 0.7798 - precision: 0.7606 - recall: 0.7824\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.4689 - accuracy: 0.7849 - precision: 0.7657 - recall: 0.7881\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.4620 - accuracy: 0.7895 - precision: 0.7697 - recall: 0.7943\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4554 - accuracy: 0.7960 - precision: 0.7773 - recall: 0.7994\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4520 - accuracy: 0.7969 - precision: 0.7795 - recall: 0.7979\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4453 - accuracy: 0.8007 - precision: 0.7833 - recall: 0.8021\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.8058 - precision: 0.7885 - recall: 0.8075\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4346 - accuracy: 0.8063 - precision: 0.7896 - recall: 0.8071\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4271 - accuracy: 0.8103 - precision: 0.7949 - recall: 0.8092\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4217 - accuracy: 0.8166 - precision: 0.8012 - recall: 0.8164\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4156 - accuracy: 0.8195 - precision: 0.8035 - recall: 0.8204\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4098 - accuracy: 0.8224 - precision: 0.8075 - recall: 0.8220\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.4033 - accuracy: 0.8266 - precision: 0.8117 - recall: 0.8266\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3976 - accuracy: 0.8297 - precision: 0.8149 - recall: 0.8299\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3924 - accuracy: 0.8313 - precision: 0.8156 - recall: 0.8330\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3865 - accuracy: 0.8367 - precision: 0.8228 - recall: 0.8361\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3816 - accuracy: 0.8395 - precision: 0.8261 - recall: 0.8385\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.3749 - accuracy: 0.8427 - precision: 0.8286 - recall: 0.8432\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.3700 - accuracy: 0.8451 - precision: 0.8335 - recall: 0.8420\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.3622 - accuracy: 0.8507 - precision: 0.8380 - recall: 0.8499\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.3565 - accuracy: 0.8531 - precision: 0.8406 - recall: 0.8523\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3516 - accuracy: 0.8556 - precision: 0.8438 - recall: 0.8540\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3464 - accuracy: 0.8585 - precision: 0.8456 - recall: 0.8587\n",
            "Epoch 51/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3395 - accuracy: 0.8627 - precision: 0.8522 - recall: 0.8598\n",
            "Epoch 52/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3340 - accuracy: 0.8660 - precision: 0.8562 - recall: 0.8626\n",
            "Epoch 53/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3303 - accuracy: 0.8673 - precision: 0.8569 - recall: 0.8649\n",
            "Epoch 54/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.3219 - accuracy: 0.8715 - precision: 0.8615 - recall: 0.8690\n",
            "Epoch 55/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3221 - accuracy: 0.8719 - precision: 0.8623 - recall: 0.8689\n",
            "Epoch 56/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3134 - accuracy: 0.8761 - precision: 0.8662 - recall: 0.8742\n",
            "Epoch 57/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3074 - accuracy: 0.8790 - precision: 0.8708 - recall: 0.8748\n",
            "Epoch 58/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.3013 - accuracy: 0.8819 - precision: 0.8728 - recall: 0.8795\n",
            "Epoch 59/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2982 - accuracy: 0.8843 - precision: 0.8771 - recall: 0.8797\n",
            "Epoch 60/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2933 - accuracy: 0.8873 - precision: 0.8791 - recall: 0.8843\n",
            "Epoch 61/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2881 - accuracy: 0.8890 - precision: 0.8815 - recall: 0.8852\n",
            "Epoch 62/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2838 - accuracy: 0.8911 - precision: 0.8843 - recall: 0.8866\n",
            "Epoch 63/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2786 - accuracy: 0.8941 - precision: 0.8864 - recall: 0.8913\n",
            "Epoch 64/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.2721 - accuracy: 0.8965 - precision: 0.8898 - recall: 0.8926\n",
            "Epoch 65/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.2703 - accuracy: 0.8980 - precision: 0.8918 - recall: 0.8935\n",
            "Epoch 66/200\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.2668 - accuracy: 0.8998 - precision: 0.8937 - recall: 0.8955\n",
            "Epoch 67/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2606 - accuracy: 0.9035 - precision: 0.8962 - recall: 0.9011\n",
            "Epoch 68/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2545 - accuracy: 0.9061 - precision: 0.9006 - recall: 0.9018\n",
            "Epoch 69/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2536 - accuracy: 0.9062 - precision: 0.9011 - recall: 0.9014\n",
            "Epoch 70/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2481 - accuracy: 0.9088 - precision: 0.9038 - recall: 0.9042\n",
            "Epoch 71/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2446 - accuracy: 0.9107 - precision: 0.9053 - recall: 0.9066\n",
            "Epoch 72/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2368 - accuracy: 0.9152 - precision: 0.9108 - recall: 0.9105\n",
            "Epoch 73/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2359 - accuracy: 0.9158 - precision: 0.9111 - recall: 0.9117\n",
            "Epoch 74/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2325 - accuracy: 0.9171 - precision: 0.9132 - recall: 0.9121\n",
            "Epoch 75/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2278 - accuracy: 0.9193 - precision: 0.9160 - recall: 0.9138\n",
            "Epoch 76/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2242 - accuracy: 0.9201 - precision: 0.9161 - recall: 0.9156\n",
            "Epoch 77/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2216 - accuracy: 0.9213 - precision: 0.9188 - recall: 0.9151\n",
            "Epoch 78/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2165 - accuracy: 0.9243 - precision: 0.9213 - recall: 0.9191\n",
            "Epoch 79/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2169 - accuracy: 0.9228 - precision: 0.9194 - recall: 0.9179\n",
            "Epoch 80/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.2106 - accuracy: 0.9270 - precision: 0.9242 - recall: 0.9218\n",
            "Epoch 81/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.2059 - accuracy: 0.9287 - precision: 0.9255 - recall: 0.9242\n",
            "Epoch 82/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.2039 - accuracy: 0.9295 - precision: 0.9276 - recall: 0.9236\n",
            "Epoch 83/200\n",
            "90/90 [==============================] - 1s 14ms/step - loss: 0.2014 - accuracy: 0.9319 - precision: 0.9303 - recall: 0.9259\n",
            "Epoch 84/200\n",
            "90/90 [==============================] - 1s 13ms/step - loss: 0.1999 - accuracy: 0.9315 - precision: 0.9306 - recall: 0.9247\n",
            "Epoch 85/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.1962 - accuracy: 0.9337 - precision: 0.9325 - recall: 0.9274\n",
            "Epoch 86/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1903 - accuracy: 0.9363 - precision: 0.9350 - recall: 0.9306\n",
            "Epoch 87/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1916 - accuracy: 0.9354 - precision: 0.9349 - recall: 0.9287\n",
            "Epoch 88/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1897 - accuracy: 0.9365 - precision: 0.9350 - recall: 0.9310\n",
            "Epoch 89/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1846 - accuracy: 0.9390 - precision: 0.9384 - recall: 0.9327\n",
            "Epoch 90/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1821 - accuracy: 0.9398 - precision: 0.9387 - recall: 0.9341\n",
            "Epoch 91/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.9415 - precision: 0.9419 - recall: 0.9345\n",
            "Epoch 92/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1799 - accuracy: 0.9402 - precision: 0.9394 - recall: 0.9343\n",
            "Epoch 93/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1744 - accuracy: 0.9433 - precision: 0.9435 - recall: 0.9366\n",
            "Epoch 94/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1711 - accuracy: 0.9442 - precision: 0.9453 - recall: 0.9368\n",
            "Epoch 95/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1725 - accuracy: 0.9438 - precision: 0.9438 - recall: 0.9376\n",
            "Epoch 96/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1701 - accuracy: 0.9448 - precision: 0.9447 - recall: 0.9386\n",
            "Epoch 97/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1670 - accuracy: 0.9465 - precision: 0.9469 - recall: 0.9402\n",
            "Epoch 98/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1625 - accuracy: 0.9483 - precision: 0.9497 - recall: 0.9409\n",
            "Epoch 99/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1641 - accuracy: 0.9473 - precision: 0.9477 - recall: 0.9409\n",
            "Epoch 100/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1589 - accuracy: 0.9503 - precision: 0.9516 - recall: 0.9433\n",
            "Epoch 101/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1587 - accuracy: 0.9496 - precision: 0.9503 - recall: 0.9432\n",
            "Epoch 102/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.1553 - accuracy: 0.9517 - precision: 0.9540 - recall: 0.9438\n",
            "Epoch 103/200\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1556 - accuracy: 0.9518 - precision: 0.9525 - recall: 0.9456\n",
            "Epoch 104/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1544 - accuracy: 0.9520 - precision: 0.9535 - recall: 0.9449\n",
            "Epoch 105/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1526 - accuracy: 0.9525 - precision: 0.9540 - recall: 0.9454\n",
            "Epoch 106/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1496 - accuracy: 0.9540 - precision: 0.9561 - recall: 0.9466\n",
            "Epoch 107/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1463 - accuracy: 0.9561 - precision: 0.9576 - recall: 0.9496\n",
            "Epoch 108/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1472 - accuracy: 0.9552 - precision: 0.9571 - recall: 0.9481\n",
            "Epoch 109/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1455 - accuracy: 0.9563 - precision: 0.9583 - recall: 0.9491\n",
            "Epoch 110/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1442 - accuracy: 0.9565 - precision: 0.9586 - recall: 0.9494\n",
            "Epoch 111/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1430 - accuracy: 0.9577 - precision: 0.9605 - recall: 0.9500\n",
            "Epoch 112/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1447 - accuracy: 0.9558 - precision: 0.9582 - recall: 0.9482\n",
            "Epoch 113/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1400 - accuracy: 0.9576 - precision: 0.9588 - recall: 0.9517\n",
            "Epoch 114/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1415 - accuracy: 0.9574 - precision: 0.9598 - recall: 0.9502\n",
            "Epoch 115/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1371 - accuracy: 0.9594 - precision: 0.9611 - recall: 0.9530\n",
            "Epoch 116/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1402 - accuracy: 0.9586 - precision: 0.9610 - recall: 0.9515\n",
            "Epoch 117/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1368 - accuracy: 0.9600 - precision: 0.9620 - recall: 0.9534\n",
            "Epoch 118/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1338 - accuracy: 0.9605 - precision: 0.9622 - recall: 0.9543\n",
            "Epoch 119/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.1345 - accuracy: 0.9601 - precision: 0.9612 - recall: 0.9545\n",
            "Epoch 120/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1347 - accuracy: 0.9600 - precision: 0.9628 - recall: 0.9525\n",
            "Epoch 121/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.1307 - accuracy: 0.9626 - precision: 0.9647 - recall: 0.9562\n",
            "Epoch 122/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1331 - accuracy: 0.9613 - precision: 0.9646 - recall: 0.9535\n",
            "Epoch 123/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1292 - accuracy: 0.9623 - precision: 0.9647 - recall: 0.9555\n",
            "Epoch 124/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1296 - accuracy: 0.9616 - precision: 0.9643 - recall: 0.9546\n",
            "Epoch 125/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1286 - accuracy: 0.9627 - precision: 0.9650 - recall: 0.9562\n",
            "Epoch 126/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1272 - accuracy: 0.9627 - precision: 0.9647 - recall: 0.9565\n",
            "Epoch 127/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1261 - accuracy: 0.9641 - precision: 0.9675 - recall: 0.9564\n",
            "Epoch 128/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1246 - accuracy: 0.9640 - precision: 0.9670 - recall: 0.9569\n",
            "Epoch 129/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1262 - accuracy: 0.9629 - precision: 0.9656 - recall: 0.9560\n",
            "Epoch 130/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1245 - accuracy: 0.9648 - precision: 0.9681 - recall: 0.9573\n",
            "Epoch 131/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1245 - accuracy: 0.9644 - precision: 0.9667 - recall: 0.9581\n",
            "Epoch 132/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1246 - accuracy: 0.9642 - precision: 0.9669 - recall: 0.9573\n",
            "Epoch 133/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1241 - accuracy: 0.9644 - precision: 0.9674 - recall: 0.9572\n",
            "Epoch 134/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1210 - accuracy: 0.9660 - precision: 0.9687 - recall: 0.9593\n",
            "Epoch 135/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1203 - accuracy: 0.9650 - precision: 0.9682 - recall: 0.9577\n",
            "Epoch 136/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.1173 - accuracy: 0.9675 - precision: 0.9705 - recall: 0.9607\n",
            "Epoch 137/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1189 - accuracy: 0.9664 - precision: 0.9691 - recall: 0.9599\n",
            "Epoch 138/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.1203 - accuracy: 0.9661 - precision: 0.9695 - recall: 0.9588\n",
            "Epoch 139/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1211 - accuracy: 0.9653 - precision: 0.9684 - recall: 0.9582\n",
            "Epoch 140/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.9667 - precision: 0.9696 - recall: 0.9599\n",
            "Epoch 141/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1156 - accuracy: 0.9683 - precision: 0.9712 - recall: 0.9616\n",
            "Epoch 142/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1157 - accuracy: 0.9679 - precision: 0.9708 - recall: 0.9613\n",
            "Epoch 143/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1195 - accuracy: 0.9662 - precision: 0.9694 - recall: 0.9592\n",
            "Epoch 144/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1139 - accuracy: 0.9689 - precision: 0.9718 - recall: 0.9625\n",
            "Epoch 145/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1138 - accuracy: 0.9682 - precision: 0.9710 - recall: 0.9618\n",
            "Epoch 146/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1158 - accuracy: 0.9671 - precision: 0.9704 - recall: 0.9599\n",
            "Epoch 147/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1135 - accuracy: 0.9690 - precision: 0.9719 - recall: 0.9626\n",
            "Epoch 148/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1132 - accuracy: 0.9692 - precision: 0.9727 - recall: 0.9622\n",
            "Epoch 149/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1140 - accuracy: 0.9685 - precision: 0.9715 - recall: 0.9619\n",
            "Epoch 150/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1123 - accuracy: 0.9688 - precision: 0.9714 - recall: 0.9626\n",
            "Epoch 151/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1114 - accuracy: 0.9697 - precision: 0.9730 - recall: 0.9628\n",
            "Epoch 152/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1129 - accuracy: 0.9691 - precision: 0.9729 - recall: 0.9617\n",
            "Epoch 153/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.1086 - accuracy: 0.9707 - precision: 0.9739 - recall: 0.9640\n",
            "Epoch 154/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1098 - accuracy: 0.9700 - precision: 0.9723 - recall: 0.9643\n",
            "Epoch 155/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1096 - accuracy: 0.9702 - precision: 0.9731 - recall: 0.9639\n",
            "Epoch 156/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.1096 - accuracy: 0.9698 - precision: 0.9728 - recall: 0.9633\n",
            "Epoch 157/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1092 - accuracy: 0.9698 - precision: 0.9723 - recall: 0.9638\n",
            "Epoch 158/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1081 - accuracy: 0.9707 - precision: 0.9738 - recall: 0.9643\n",
            "Epoch 159/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1078 - accuracy: 0.9706 - precision: 0.9742 - recall: 0.9635\n",
            "Epoch 160/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1088 - accuracy: 0.9700 - precision: 0.9731 - recall: 0.9635\n",
            "Epoch 161/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1065 - accuracy: 0.9712 - precision: 0.9739 - recall: 0.9652\n",
            "Epoch 162/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1067 - accuracy: 0.9715 - precision: 0.9746 - recall: 0.9650\n",
            "Epoch 163/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1057 - accuracy: 0.9712 - precision: 0.9740 - recall: 0.9651\n",
            "Epoch 164/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.1062 - accuracy: 0.9708 - precision: 0.9745 - recall: 0.9636\n",
            "Epoch 165/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1031 - accuracy: 0.9725 - precision: 0.9749 - recall: 0.9670\n",
            "Epoch 166/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1082 - accuracy: 0.9708 - precision: 0.9732 - recall: 0.9650\n",
            "Epoch 167/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1051 - accuracy: 0.9721 - precision: 0.9751 - recall: 0.9660\n",
            "Epoch 168/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1031 - accuracy: 0.9727 - precision: 0.9761 - recall: 0.9662\n",
            "Epoch 169/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1025 - accuracy: 0.9728 - precision: 0.9755 - recall: 0.9670\n",
            "Epoch 170/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.1041 - accuracy: 0.9720 - precision: 0.9747 - recall: 0.9661\n",
            "Epoch 171/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9732 - precision: 0.9762 - recall: 0.9672\n",
            "Epoch 172/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.1006 - accuracy: 0.9739 - precision: 0.9768 - recall: 0.9679\n",
            "Epoch 173/200\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.1028 - accuracy: 0.9719 - precision: 0.9744 - recall: 0.9662\n",
            "Epoch 174/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1051 - accuracy: 0.9717 - precision: 0.9742 - recall: 0.9660\n",
            "Epoch 175/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1013 - accuracy: 0.9731 - precision: 0.9764 - recall: 0.9668\n",
            "Epoch 176/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1011 - accuracy: 0.9731 - precision: 0.9756 - recall: 0.9675\n",
            "Epoch 177/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1002 - accuracy: 0.9732 - precision: 0.9766 - recall: 0.9668\n",
            "Epoch 178/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.1000 - accuracy: 0.9730 - precision: 0.9756 - recall: 0.9674\n",
            "Epoch 179/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0999 - accuracy: 0.9731 - precision: 0.9757 - recall: 0.9675\n",
            "Epoch 180/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0993 - accuracy: 0.9738 - precision: 0.9764 - recall: 0.9682\n",
            "Epoch 181/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0997 - accuracy: 0.9739 - precision: 0.9772 - recall: 0.9675\n",
            "Epoch 182/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0988 - accuracy: 0.9733 - precision: 0.9760 - recall: 0.9676\n",
            "Epoch 183/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0994 - accuracy: 0.9736 - precision: 0.9765 - recall: 0.9677\n",
            "Epoch 184/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0984 - accuracy: 0.9740 - precision: 0.9770 - recall: 0.9681\n",
            "Epoch 185/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0979 - accuracy: 0.9740 - precision: 0.9770 - recall: 0.9681\n",
            "Epoch 186/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0968 - accuracy: 0.9738 - precision: 0.9767 - recall: 0.9678\n",
            "Epoch 187/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.0960 - accuracy: 0.9741 - precision: 0.9772 - recall: 0.9681\n",
            "Epoch 188/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0991 - accuracy: 0.9737 - precision: 0.9761 - recall: 0.9684\n",
            "Epoch 189/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0981 - accuracy: 0.9742 - precision: 0.9770 - recall: 0.9685\n",
            "Epoch 190/200\n",
            "90/90 [==============================] - 1s 10ms/step - loss: 0.0975 - accuracy: 0.9746 - precision: 0.9774 - recall: 0.9689\n",
            "Epoch 191/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0980 - accuracy: 0.9742 - precision: 0.9766 - recall: 0.9688\n",
            "Epoch 192/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0959 - accuracy: 0.9749 - precision: 0.9779 - recall: 0.9692\n",
            "Epoch 193/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0965 - accuracy: 0.9752 - precision: 0.9780 - recall: 0.9695\n",
            "Epoch 194/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0960 - accuracy: 0.9751 - precision: 0.9779 - recall: 0.9694\n",
            "Epoch 195/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0969 - accuracy: 0.9746 - precision: 0.9775 - recall: 0.9689\n",
            "Epoch 196/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0938 - accuracy: 0.9762 - precision: 0.9785 - recall: 0.9713\n",
            "Epoch 197/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0940 - accuracy: 0.9753 - precision: 0.9787 - recall: 0.9691\n",
            "Epoch 198/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0942 - accuracy: 0.9753 - precision: 0.9777 - recall: 0.9702\n",
            "Epoch 199/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0962 - accuracy: 0.9742 - precision: 0.9765 - recall: 0.9689\n",
            "Epoch 200/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0948 - accuracy: 0.9747 - precision: 0.9776 - recall: 0.9690\n",
            "Accuracy  :  0.7076089978218079\n",
            "Precision :  0.6928879022598267\n",
            "Recall    :  0.7020928263664246\n",
            "F1-Score  :  0.6974599944929304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 200, 256)"
      ],
      "metadata": {
        "id": "myamsvabsEUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 200, 128)"
      ],
      "metadata": {
        "id": "9wlpvgzdRhMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 200, 64)"
      ],
      "metadata": {
        "id": "gwi8o7aCSUMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 100, 512)"
      ],
      "metadata": {
        "id": "EweabFtLScSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 100, 256)"
      ],
      "metadata": {
        "id": "LsGyPZ4VSfiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 100, 128)"
      ],
      "metadata": {
        "id": "bWxGloKbSif4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"rmsprop\", 100, 64)"
      ],
      "metadata": {
        "id": "8GH_HktjSmxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 200, 512)"
      ],
      "metadata": {
        "id": "xFIeeNqwcJut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 200, 256)"
      ],
      "metadata": {
        "id": "VIqDB9SZcgxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 200, 128)"
      ],
      "metadata": {
        "id": "J-yzWQgSckxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 200, 64)"
      ],
      "metadata": {
        "id": "EqXgd3qDcv2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 100, 512)"
      ],
      "metadata": {
        "id": "rDU4AE6YdMkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 100, 256)"
      ],
      "metadata": {
        "id": "xbGcPPeydNWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 100, 128)"
      ],
      "metadata": {
        "id": "10gKrj3sdOEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model_dl(data, target, \"adam\", 100, 64)"
      ],
      "metadata": {
        "id": "R56Q6Jr6dPDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWdscTHDdb0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}